<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Deep learning on MNIST - Numpy Tutorials</title><meta property="og:title" content="Deep learning on MNIST - Numpy Tutorials"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><meta name="image" content="/numpy-tutorials/build/tutorial-deep-learni-18c33a02a86a205d4dc00e618c78f2e1.png"/><meta property="og:image" content="/numpy-tutorials/build/tutorial-deep-learni-18c33a02a86a205d4dc00e618c78f2e1.png"/><link rel="stylesheet" href="/numpy-tutorials/build/_assets/app-MOQGDXHO.css"/><link rel="stylesheet" href="/numpy-tutorials/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/numpy-tutorials/favicon.ico"/><link rel="stylesheet" href="/numpy-tutorials/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="myst-skip-to-article fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="myst-skip-to-link block px-2 py-1 text-black underline">Skip to article content</a></div><dialog id="myst-no-css" style="position:fixed;left:0px;top:0px;width:100vw;height:100vh;font-size:4rem;padding:1rem;color:black;background:white"><strong>Site not loading correctly?</strong><p>This may be due to an incorrect <code>BASE_URL</code> configuration. See<!-- --> <a href="https://mystmd.org/guide/deployment#deploy-base-url">the MyST Documentation</a> <!-- -->for reference.</p><script>
    (() => {
            // Test for has-styling variable set by the MyST stylesheet
            const node = document.currentScript.parentNode;
            const hasCSS = window.getComputedStyle(node).getPropertyValue("--has-styling");
            if (hasCSS === ""){
                    node.showModal();
            }

    })()
</script></dialog><div class="myst-top-nav bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="myst-top-nav-bar flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="myst-top-nav-menu-button flex items-center justify-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100 w-10 h-10"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="myst-home-link flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/numpy-tutorials/"><div class="myst-home-link-logo mr-3 flex items-center dark:bg-white dark:rounded px-1"><img src="/numpy-tutorials/build/numpylogo-278cf34e28ed8e84d4b79121bf103557.svg" class="h-9" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5 sr-only">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R75cp:" data-state="closed" class="myst-search-bar flex items-center h-10 aspect-square sm:w-64 text-left text-gray-600 dark:text-gray-300 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 myst-search-bar-disabled hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="myst-search-text-placeholder hidden sm:block grow">Search</span><div aria-hidden="true" class="myst-search-shortcut items-center hidden mx-1 font-mono text-sm text-gray-600 dark:text-gray-300 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="myst-theme-button theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-10 h-10 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-moon-icon h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="myst-theme-sun-icon h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="myst-primary-sidebar fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="myst-primary-sidebar-pointer pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="myst-primary-sidebar-nav flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="myst-primary-sidebar-topnav overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="myst-primary-sidebar-toc flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="myst-toc w-full px-1 dark:text-white"><a title="Numpy Tutorials" class="block break-words focus:outline outline-blue-200 outline-2 rounded myst-toc-item p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/numpy-tutorials/">Numpy Tutorials</a><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 pl-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Applications" class="block break-words rounded py-2 grow cursor-pointer">Applications</div><button class="self-stretch flex items-center flex-none px-1 rounded-l-md group hover:bg-slate-300/30 focus-visible:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rmpsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rmpsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 pl-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Features" class="block break-words rounded py-2 grow cursor-pointer">Features</div><button class="self-stretch flex items-center flex-none px-1 rounded-l-md group hover:bg-slate-300/30 focus-visible:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rupsp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rupsp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="myst-toc-item flex flex-row w-full gap-2 pl-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><a title="Contributing" class="block break-words focus:outline outline-blue-200 outline-2 rounded py-2 grow" href="/numpy-tutorials/contributing">Contributing</a><button class="self-stretch flex items-center flex-none px-1 rounded-l-md group hover:bg-slate-300/30 focus-visible:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R16psp:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R16psp:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="myst-primary-sidebar-footer flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="myst-made-with-myst flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><main class="article-grid grid-gap"><article class="article-grid subgrid-gap col-screen article content"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="myst-fm-block mb-8 pt-9"><div class="myst-fm-block-header flex items-center mb-5 h-6 text-sm font-light"><div class="flex-grow"></div><div class="myst-fm-block-badges"><a href="https://github.com/numpy/numpy-tutorials" title="GitHub Repository: numpy/numpy-tutorials" target="_blank" rel="noopener noreferrer" class="myst-fm-github-link text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="myst-fm-github-icon inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a></div><a href="https://github.com/numpy/numpy-tutorials/edit/main/content/tutorial-deep-learning-on-mnist.md" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="myst-fm-edit-link text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="myst-fm-edit-icon inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="myst-fm-downloads-dropdown relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="myst-fm-downloads-button relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8ucp:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="myst-fm-downloads-icon"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="myst-fm-block-title mb-0">Deep learning on MNIST</h1><header class="myst-fm-authors-affiliations mt-4 not-prose"><div class="myst-fm-authors-list"><span class="myst-fm-author font-semibold text-sm myst-fm-author-item inline-block"><button class="myst-fm-author-popover focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R78ucp:" data-state="closed"><span class="myst-fm-author-name">Numpy Community</span></button></span></div></header></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><p>This tutorial demonstrates how to build a simple <a href="https://en.wikipedia.org/wiki/Feedforward_neural_network" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">feedforward neural network</a> (with one hidden layer) and train it from scratch with NumPy to recognize handwritten digit images.</p><p>Your deep learning model — one of the most basic artificial neural networks that resembles the original <a href="https://en.wikipedia.org/wiki/Multilayer_perceptron" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">multi-layer perceptron</a> — will learn to classify digits from 0 to 9 from the <a href="https://en.wikipedia.org/wiki/MNIST_database" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">MNIST</a> dataset. The dataset contains 60,000 training and 10,000 test images and corresponding labels. Each training and test image is of size 784 (or 28x28 pixels) — this will be your input for the neural network.</p><p>Based on the image inputs and their labels (<a href="https://en.wikipedia.org/wiki/Supervised_learning" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">supervised learning</a>), your neural network will be trained to learn their features using forward propagation and backpropagation (<a href="https://en.wikipedia.org/wiki/Automatic_differentiation#Reverse_accumulation" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">reverse-mode</a> differentiation). The final output of the network is a vector of 10 scores — one for each handwritten digit image. You will also evaluate how good your model is at classifying the images on the test set.</p><img id="flbOxZBY74" style="margin-left:auto;margin-right:auto" src="/numpy-tutorials/build/tutorial-deep-learni-18c33a02a86a205d4dc00e618c78f2e1.png" alt="Diagram showing operations detailed in this tutorial (The input imageis passed into a Hidden layer that creates a weighted sum of outputs.The weighted sum is passed to the Non-linearity, then regularization andinto the output layer. The output layer creates a prediction which canthen be compared to existing data. The errors are used to calculate theloss function and update weights in the hidden layer and outputlayer.)" data-canonical-url="_static/tutorial-deep-learning-on-mnist.png" class=""/><p>This tutorial was adapted from the work by <a target="_blank" rel="noreferrer" href="https://github.com/iamtrask/Grokking-Deep-Learning" class="link">Andrew Trask<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> (with the author’s permission).</p><h2 id="prerequisites" class="relative group"><span class="heading-text">Prerequisites</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#prerequisites" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>The reader should have some knowledge of Python, NumPy array manipulation, and linear algebra. In addition, you should be familiar with main concepts of <a href="https://en.wikipedia.org/wiki/Deep_learning" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">deep learning</a>.</p><p>To refresh the memory, you can take the <a target="_blank" rel="noreferrer" href="https://docs.python.org/dev/tutorial/index.html" class="link">Python<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> and <a class="link" href="/numpy-tutorials/tutorial-svd">Linear algebra on n-dimensional arrays</a> tutorials.</p><p>You are advised to read the <a target="_blank" rel="noreferrer" href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf" class="link">Deep learning<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> paper published in 2015 by Yann LeCun, Yoshua Bengio, and Geoffrey Hinton, who are regarded as some of the pioneers of the field. You should also consider reading Andrew Trask’s <a target="_blank" rel="noreferrer" href="https://www.manning.com/books/grokking-deep-learning" class="link">Grokking Deep Learning<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, which teaches deep learning with NumPy.</p><p>In addition to NumPy, you will be utilizing the following Python standard modules for data loading and processing:</p><ul><li><p><a target="_blank" rel="noreferrer" href="https://docs.python.org/3/library/urllib.html" class="link"><code>urllib</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> for URL handling</p></li><li><p><a target="_blank" rel="noreferrer" href="https://docs.python.org/3/library/urllib.request.html" class="link"><code>request</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> for URL opening</p></li><li><p><a target="_blank" rel="noreferrer" href="https://docs.python.org/3/library/gzip.html" class="link"><code>gzip</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> for gzip file decompression</p></li><li><p><a target="_blank" rel="noreferrer" href="https://docs.python.org/3/library/pickle.html" class="link"><code>pickle</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> to work with the pickle file format</p><p>as well as:</p></li><li><p><a target="_blank" rel="noreferrer" href="https://matplotlib.org/" class="link">Matplotlib<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> for data visualization</p></li></ul><p>This tutorial can be run locally in an isolated environment, such as <a target="_blank" rel="noreferrer" href="https://virtualenv.pypa.io/en/stable/" class="link">Virtualenv<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> or <a target="_blank" rel="noreferrer" href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html" class="link">conda<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>. You can use <a target="_blank" rel="noreferrer" href="https://jupyter.org/install" class="link">Jupyter Notebook or JupyterLab<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> to run each notebook cell. Don’t forget to <a target="_blank" rel="noreferrer" href="https://numpy.org/doc/stable/user/absolute_beginners.html#installing-numpy" class="link">set up NumPy<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> and <a target="_blank" rel="noreferrer" href="https://matplotlib.org/users/installing.html#installing-an-official-release" class="link">Matplotlib<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>.</p><h2 id="table-of-contents" class="relative group"><span class="heading-text">Table of contents</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#table-of-contents" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><ol start="1"><li><p>Load the MNIST dataset</p></li><li><p>Preprocess the dataset</p></li><li><p>Build and train a small neural network from scratch</p></li><li><p>Next steps</p></li></ol><hr class="py-2 my-5 translate-y-2"/><h2 id="id-1-load-the-mnist-dataset" class="relative group"><span class="heading-text">1. Load the MNIST dataset</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id-1-load-the-mnist-dataset" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>In this section, you will download the zipped MNIST dataset files originally developed by Yann LeCun’s research team. (More details of the MNIST dataset are available on <a target="_blank" rel="noreferrer" href="https://www.kaggle.com/datasets/hojjatk/mnist-dataset" class="link">Kaggle<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>.) Then, you will transform them into 4 files of NumPy array type using built-in Python modules. Finally, you will split the arrays into training and test sets.</p><p><strong>1.</strong> Define a variable to store the training/test image/label names of the MNIST dataset in a list:</p><div id="Yd3PqtD7qc" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">data_sources = {
    &quot;training_images&quot;: &quot;train-images-idx3-ubyte.gz&quot;,  # 60,000 training images.
    &quot;test_images&quot;: &quot;t10k-images-idx3-ubyte.gz&quot;,  # 10,000 test images.
    &quot;training_labels&quot;: &quot;train-labels-idx1-ubyte.gz&quot;,  # 60,000 training labels.
    &quot;test_labels&quot;: &quot;t10k-labels-idx1-ubyte.gz&quot;,  # 10,000 test labels.
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="DIyrl0itrPgO5VFflxx-U" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><p><strong>2.</strong> Load the data. First check if the data is stored locally; if not, then
download it.</p><div id="AGDWVCdmhi" class="myst-jp-nb-block relative group/block hidden"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Use responsibly! When running notebooks locally, be sure to keep local
# copies of the datasets to prevent unnecessary server requests
headers = {
    &quot;User-Agent&quot;: &quot;Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0&quot;
}
request_opts = {
    &quot;headers&quot;: headers,
    &quot;params&quot;: {&quot;raw&quot;: &quot;true&quot;},
}</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="zooZSWFO_QqYthA1pGpGx" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="rsmjFpml7N" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import requests
import os

data_dir = &quot;../_data&quot;
os.makedirs(data_dir, exist_ok=True)

base_url = &quot;https://ossci-datasets.s3.amazonaws.com/mnist/&quot;

for fname in data_sources.values():
    fpath = os.path.join(data_dir, fname)
    if not os.path.exists(fpath):
        print(&quot;Downloading file: &quot; + fname)
        resp = requests.get(base_url + fname, stream=True, **request_opts)
        resp.raise_for_status()  # Ensure download was succesful
        with open(fpath, &quot;wb&quot;) as fh:
            for chunk in resp.iter_content(chunk_size=128):
                fh.write(chunk)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="Ab52FiXPC_lF0xKUr1oA_" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Downloading file: train-images-idx3-ubyte.gz
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Downloading file: t10k-images-idx3-ubyte.gz
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Downloading file: train-labels-idx1-ubyte.gz
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Downloading file: t10k-labels-idx1-ubyte.gz
</span></code></pre></div></div></div></div><p><strong>3.</strong> Decompress the 4 files and create 4 <a target="_blank" rel="noreferrer" href="https://numpy.org/doc/stable/reference/arrays.ndarray.html" class="link"><code>ndarrays</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, saving them into a dictionary. Each original image is of size 28x28 and neural networks normally expect a 1D vector input; therefore, you also need to reshape the images by multiplying 28 by 28 (784).</p><div id="cYI8iDCcNX" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import gzip
import numpy as np

mnist_dataset = {}

# Images
for key in (&quot;training_images&quot;, &quot;test_images&quot;):
    with gzip.open(os.path.join(data_dir, data_sources[key]), &quot;rb&quot;) as mnist_file:
        mnist_dataset[key] = np.frombuffer(
            mnist_file.read(), np.uint8, offset=16
        ).reshape(-1, 28 * 28)
# Labels
for key in (&quot;training_labels&quot;, &quot;test_labels&quot;):
    with gzip.open(os.path.join(data_dir, data_sources[key]), &quot;rb&quot;) as mnist_file:
        mnist_dataset[key] = np.frombuffer(mnist_file.read(), np.uint8, offset=8)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="drMzKZwTQDHp-6fbVPLxp" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><p><strong>4.</strong> Split the data into training and test sets using the standard notation of <code>x</code> for data and <code>y</code> for labels, calling the training and test set images <code>x_train</code> and <code>x_test</code>, and the labels <code>y_train</code> and <code>y_test</code>:</p><div id="ZmeDSL5n04" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">x_train, y_train, x_test, y_test = (
    mnist_dataset[&quot;training_images&quot;],
    mnist_dataset[&quot;training_labels&quot;],
    mnist_dataset[&quot;test_images&quot;],
    mnist_dataset[&quot;test_labels&quot;],
)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="1UvYQW9iYtCs9eIpJK8bj" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><p><strong>5.</strong> You can confirm that the shape of the image arrays is <code>(60000, 784)</code> and <code>(10000, 784)</code> for training and test sets, respectively, and the labels — <code>(60000,)</code> and <code>(10000,)</code>:</p><div id="UzMwBks9cS" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print(
    &quot;The shape of training images: {} and training labels: {}&quot;.format(
        x_train.shape, y_train.shape
    )
)
print(
    &quot;The shape of test images: {} and test labels: {}&quot;.format(
        x_test.shape, y_test.shape
    )
)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="UHBe-UpNbos7TOeL6u-8x" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>The shape of training images: (60000, 784) and training labels: (60000,)
The shape of test images: (10000, 784) and test labels: (10000,)
</span></code></pre></div></div></div></div><p><strong>6.</strong> And you can inspect some images using Matplotlib:</p><div id="ZOLIJb6hBN" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import matplotlib.pyplot as plt

# Take the 60,000th image (indexed at 59,999) from the training set,
# reshape from (784, ) to (28, 28) to have a valid shape for displaying purposes.
mnist_image = x_train[59999, :].reshape(28, 28)
# Set the color mapping to grayscale to have a black background.
plt.imshow(mnist_image, cmap=&quot;gray&quot;)
# Display the image.
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="46sSghmFcMu0TPlUzy0sn" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/numpy-tutorials/build/e018622a0b32aae6fc08527a27232984.png" alt="&lt;Figure size 640x480 with 1 Axes&gt;"/></div></div></div><div id="N8U2U5uZRL" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Display 5 random images from the training set.
num_examples = 5
seed = 147197952744
rng = np.random.default_rng(seed)

fig, axes = plt.subplots(1, num_examples)
for sample, ax in zip(rng.choice(x_train, size=num_examples, replace=False), axes):
    ax.imshow(sample.reshape(28, 28), cmap=&quot;gray&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="6DJofSZSadklAUDKskeLr" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/numpy-tutorials/build/b38af87a5e32f7a78feb44788a3ac955.png" alt="&lt;Figure size 640x480 with 5 Axes&gt;"/></div></div></div><p><em>Above are five images taken from the MNIST training set. Various hand-drawn
Arabic numerals are shown, with exact values chosen randomly with each run of the code.</em></p><blockquote><p><strong>Note:</strong> You can also visualize a sample image as an array by printing <code>x_train[59999]</code>. Here, <code>59999</code> is your 60,000th training image sample (<code>0</code> would be your first). Your output will be quite long and should contain an array of 8-bit integers:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">...
         0,   0,  38,  48,  48,  22,   0,   0,   0,   0,   0,   0,   0,
         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         0,  62,  97, 198, 243, 254, 254, 212,  27,   0,   0,   0,   0,
...</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></blockquote><div id="v7m4uRq4R5" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Display the label of the 60,000th image (indexed at 59,999) from the training set.
y_train[59999]</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="JMrM1eMNxGWQPi3pCL9Vi" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-text" class="font-mono text-sm whitespace-pre-wrap myst-jp-safe-output-text"><code><span>np.uint8(8)</span></code></div></div></div><h2 id="id-2-preprocess-the-data" class="relative group"><span class="heading-text">2. Preprocess the data</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id-2-preprocess-the-data" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Neural networks can work with inputs that are in a form of tensors (multidimensional arrays) of floating-point type. When preprocessing the data, you should consider the following processes: <a href="https://en.wikipedia.org/wiki/Vectorization_%28mathematics%29" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">vectorization</a> and <a href="https://en.wikipedia.org/wiki/Floating-point_arithmetic#Floating-point_numbers" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">conversion to a floating-point format</a>.</p><p>Since the MNIST data is already vectorized and the arrays are of <code>dtype</code> <code>uint8</code>, your next challenge is to convert them to a floating-point format, such as <code>float64</code> (<a href="https://en.wikipedia.org/wiki/Double-precision_floating-point_format" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">double-precision</a>):</p><ul><li><p><em>Normalizing</em> the image data: a <a href="https://en.wikipedia.org/wiki/Feature_scaling#Application" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">feature scaling</a> procedure that can speed up the neural network training process by standardizing the <a target="_blank" rel="noreferrer" href="https://arxiv.org/pdf/1502.03167.pdf" class="link">distribution of your input data<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>.</p></li><li><p><em><a href="https://en.wikipedia.org/wiki/One-hot" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">One-hot/categorical encoding</a></em> of the image labels.</p></li></ul><p>In practice, you can use different types of floating-point precision depending on your goals and you can find more information about that in the <a target="_blank" rel="noreferrer" href="https://blogs.nvidia.com/blog/2019/11/15/whats-the-difference-between-single-double-multi-and-mixed-precision-computing/" class="link">Nvidia<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> and <a target="_blank" rel="noreferrer" href="https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus" class="link">Google Cloud<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> blog posts.</p><h3 id="convert-the-image-data-to-the-floating-point-format" class="relative group"><span class="heading-text">Convert the image data to the floating-point format</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#convert-the-image-data-to-the-floating-point-format" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>The images data contain 8-bit integers encoded in the [0, 255] interval with color values between 0 and 255.</p><p>You will normalize them into floating-point arrays in the [0, 1] interval by dividing them by 255.</p><p><strong>1.</strong> Check that the vectorized image data has type <code>uint8</code>:</p><div id="Eb1K6Hl4Pq" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print(&quot;The data type of training images: {}&quot;.format(x_train.dtype))
print(&quot;The data type of test images: {}&quot;.format(x_test.dtype))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="1qvOwriuypIOpC7SgylZs" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>The data type of training images: uint8
The data type of test images: uint8
</span></code></pre></div></div></div></div><p><strong>2.</strong> Normalize the arrays by dividing them by 255 (and thus promoting the data type from <code>uint8</code> to <code>float64</code>) and then assign the train and test image data variables — <code>x_train</code> and <code>x_test</code> — to <code>training_images</code> and <code>train_labels</code>, respectively.
To reduce the model training and evaluation time in this example, only a subset
of the training and test images will be used.
Both <code>training_images</code> and <code>test_images</code> will contain only 1,000 samples each out
of the complete datasets of 60,000 and 10,000 images, respectively.
These values can be controlled by changing the  <code>training_sample</code> and
<code>test_sample</code> below, up to their maximum values of 60,000 and 10,000.</p><div id="Y6F8O4Ncw3" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">training_sample, test_sample = 1000, 1000
training_images = x_train[0:training_sample] / 255
test_images = x_test[0:test_sample] / 255</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="iJ3MjN5i3kiwsRd8auJFd" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><p><strong>3.</strong> Confirm that the image data has changed to the floating-point format:</p><div id="TKh7ZGWDR8" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print(&quot;The data type of training images: {}&quot;.format(training_images.dtype))
print(&quot;The data type of test images: {}&quot;.format(test_images.dtype))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="UD0D4mWo92bD6dqADZZDU" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>The data type of training images: float64
The data type of test images: float64
</span></code></pre></div></div></div></div><blockquote><p><strong>Note:</strong> You can also check that normalization was successful by printing <code>training_images[0]</code> in a notebook cell. Your long output should contain an array of floating-point numbers:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">...
       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,
       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,
       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,
...</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div></blockquote><h3 id="convert-the-labels-to-floating-point-through-categorical-one-hot-encoding" class="relative group"><span class="heading-text">Convert the labels to floating point through categorical/one-hot encoding</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#convert-the-labels-to-floating-point-through-categorical-one-hot-encoding" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>You will use one-hot encoding to embed each digit label as an all-zero vector with <code>np.zeros()</code> and place <code>1</code> for a label index. As a result, your label data will be arrays with <code>1.0</code> (or <code>1.</code>) in the position of each image label.</p><p>Since there are 10 labels (from 0 to 9) in total, your arrays will look similar to this:</p><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-stone-200/10"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-text" style="white-space:pre">array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><p><strong>1.</strong> Confirm that the image label data are integers with <code>dtype</code> <code>uint8</code>:</p><div id="cDt24acBLd" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print(&quot;The data type of training labels: {}&quot;.format(y_train.dtype))
print(&quot;The data type of test labels: {}&quot;.format(y_test.dtype))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="7iAywViV7gvuHcD3Ulbox" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>The data type of training labels: uint8
The data type of test labels: uint8
</span></code></pre></div></div></div></div><p><strong>2.</strong> Define a function that performs one-hot encoding on arrays:</p><div id="KfBkCgSbcd" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">def one_hot_encoding(labels, dimension=10):
    # Define a one-hot variable for an all-zero vector
    # with 10 dimensions (number labels from 0 to 9).
    one_hot_labels = labels[..., None] == np.arange(dimension)[None]
    # Return one-hot encoded labels.
    return one_hot_labels.astype(np.float64)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="tJo3xmPGbmqPFtgY-Wlpo" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><p><strong>3.</strong> Encode the labels and assign the values to new variables:</p><div id="eo0GbxLu83" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">training_labels = one_hot_encoding(y_train[:training_sample])
test_labels = one_hot_encoding(y_test[:test_sample])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="2XYWLDW2f92kYQWJTQW8P" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><p><strong>4.</strong> Check that the data type has changed to floating point:</p><div id="Wxsa9Uz9AW" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print(&quot;The data type of training labels: {}&quot;.format(training_labels.dtype))
print(&quot;The data type of test labels: {}&quot;.format(test_labels.dtype))</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="2x2yk5D4WSOCEj0lSmk8I" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>The data type of training labels: float64
The data type of test labels: float64
</span></code></pre></div></div></div></div><p><strong>5.</strong> Examine a few encoded labels:</p><div id="lzynfcJaKD" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print(training_labels[0])
print(training_labels[1])
print(training_labels[2])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="WI2kaM93S2h1hxELrKKAZ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
</span></code></pre></div></div></div></div><p>...and compare to the originals:</p><div id="dxkx3A6AtE" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">print(y_train[0])
print(y_train[1])
print(y_train[2])</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="TN0MIRWllC2-oLAAI0y-h" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>5
0
4
</span></code></pre></div></div></div></div><p>You have finished preparing the dataset.</p><h2 id="id-3-build-and-train-a-small-neural-network-from-scratch" class="relative group"><span class="heading-text">3. Build and train a small neural network from scratch</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#id-3-build-and-train-a-small-neural-network-from-scratch" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>In this section you will familiarize yourself with some high-level concepts of the basic building blocks of a deep learning model. You can refer to the original <a target="_blank" rel="noreferrer" href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf" class="link">Deep learning<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> research publication for more information.</p><p>Afterwards, you will construct the building blocks of a simple deep learning model in Python and NumPy and train it to learn to identify handwritten digits from the MNIST dataset with a certain level of accuracy.</p><h3 id="neural-network-building-blocks-with-numpy" class="relative group"><span class="heading-text">Neural network building blocks with NumPy</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#neural-network-building-blocks-with-numpy" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><ul><li><p><em>Layers</em>: These building blocks work as data filters — they process data and learn representations from inputs to better predict the target outputs.</p><p>You will use 1 hidden layer in your model to pass the inputs forward (<em>forward propagation</em>) and propagate the gradients/error derivatives of a loss function backward (<em>backpropagation</em>). These are input, hidden and output layers.</p><p>In the hidden (middle) and output (last) layers, the neural network model will compute the weighted sum of inputs. To compute this process, you will use NumPy’s matrix multiplication function (the “dot multiply” or <code>np.dot(layer, weights)</code>).</p><blockquote><p><strong>Note:</strong> For simplicity, the bias term is omitted in this example (there is no <code>np.dot(layer, weights) + bias</code>).</p></blockquote></li><li><p><em>Weights</em>: These are important adjustable parameters that the neural network fine-tunes by forward and backward propagating the data. They are optimized through a process called <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">gradient descent</a>. Before the model training starts, the weights are randomly initialized with NumPy’s <a target="_blank" rel="noreferrer" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.random.html" class="link"><code>Generator.random()</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>.</p><p>The optimal weights should produce the highest prediction accuracy and the lowest error on the training and test sets.</p></li><li><p><em>Activation function</em>: Deep learning models are capable of determining non-linear relationships between inputs and outputs and these <a href="https://en.wikipedia.org/wiki/Activation_function" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">non-linear functions</a> are usually applied to the output of each layer.</p><p>You will use a <a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">rectified linear unit (ReLU)</a> to the hidden layer’s output (for example, <code>relu(np.dot(layer, weights))</code>.</p></li><li><p><em>Regularization</em>: This <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">technique</a> helps prevent the neural network model from <a href="https://en.wikipedia.org/wiki/Overfitting" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">overfitting</a>.</p><p>In this example, you will use a method called dropout — <a href="https://en.wikipedia.org/wiki/Dilution_(neural_networks)" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">dilution</a> — that randomly sets a number of features in a layer to 0s. You will define it with NumPy’s <a target="_blank" rel="noreferrer" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.integers.html" class="link"><code>Generator.integers()</code><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> method and apply it to the hidden layer of the network.</p></li><li><p><em>Loss function</em>: The computation determines the quality of predictions by comparing the image labels (the truth) with the predicted values in the final layer’s output.</p><p>For simplicity, you will use a basic total squared error using NumPy’s <code>np.sum()</code> function (for example, <code>np.sum((final_layer_output - image_labels) ** 2)</code>).</p></li><li><p><em>Accuracy</em>: This metric measures the accuracy of the network’s ability to predict on the data it hasn’t seen.</p></li></ul><h3 id="model-architecture-and-training-summary" class="relative group"><span class="heading-text">Model architecture and training summary</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#model-architecture-and-training-summary" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Here is a summary of the neural network model architecture and the training process:</p><img id="zceiRyqiXK" style="margin-left:auto;margin-right:auto" src="/numpy-tutorials/build/tutorial-deep-learni-18c33a02a86a205d4dc00e618c78f2e1.png" alt="Diagram showing operations detailed in this tutorial (The input imageis passed into a Hidden layer that creates a weighted sum of outputs.The weighted sum is passed to the Non-linearity, then regularization andinto the output layer. The output layer creates a prediction which canthen be compared to existing data. The errors are used to calculate theloss function and update weights in the hidden layer and outputlayer.)" data-canonical-url="_static/tutorial-deep-learning-on-mnist.png" class=""/><ul><li><p><em>The input layer</em>:</p><p>It is the input for the network — the previously preprocessed data that is loaded from <code>training_images</code> into <code>layer_0</code>.</p></li><li><p><em>The hidden (middle) layer</em>:</p><p><code>layer_1</code> takes the output from the previous layer and performs matrix-multiplication of the input by weights (<code>weights_1</code>) with NumPy’s <code>np.dot()</code>).</p><p>Then, this output is passed through the ReLU activation function for non-linearity and then dropout is applied to help with overfitting.</p></li><li><p><em>The output (last) layer</em>:</p><p><code>layer_2</code> ingests the output from <code>layer_1</code> and repeats the same “dot multiply” process with <code>weights_2</code>.</p><p>The final output returns 10 scores for each of the 0-9 digit labels. The network model ends with a size 10 layer — a 10-dimensional vector.</p></li><li><p><em>Forward propagation, backpropagation, training loop</em>:</p><p>In the beginning of model training, your network randomly initializes the weights and feeds the input data forward through the hidden and output layers. This process is the forward pass or forward propagation.</p><p>Then, the network propagates the “signal” from the loss function back through the hidden layer and adjusts the weights with the help of the learning rate parameter (more on that later).</p></li></ul><blockquote><p><strong>Note:</strong> In more technical terms, you:</p><ol start="1"><li><p>Measure the error by comparing the real label of an image (the truth) with the prediction of the model.</p></li><li><p>Differentiate the loss function.</p></li><li><p>Ingest the <a href="https://en.wikipedia.org/wiki/Gradient" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">gradients</a> with the respect to the output, and backpropagate them with the respect to the inputs through the layer(s).</p></li></ol><p>Since the network contains tensor operations and weight matrices, backpropagation uses the <a href="https://en.wikipedia.org/wiki/Chain_rule" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">chain rule</a>.</p><p>With each iteration (epoch) of the neural network training, this forward and backward propagation cycle adjusts the weights, which is reflected in the accuracy and error metrics. As you train the model, your goal is to minimize the error and maximize the accuracy on the training data, where the model learns from, as well as the test data, where you evaluate the model.</p></blockquote><h3 id="compose-the-model-and-begin-training-and-testing-it" class="relative group"><span class="heading-text">Compose the model and begin training and testing it</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#compose-the-model-and-begin-training-and-testing-it" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Having covered the main deep learning concepts and the neural network architecture, let’s write the code.</p><p><strong>1.</strong> We’ll start by creating a new random number generator, providing a seed
for reproducibility:</p><div id="hSO2EMKXjh" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">seed = 884736743
rng = np.random.default_rng(seed)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="gpKaKKzMIFb-5o2SdP4IX" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><p><strong>2.</strong> For the hidden layer, define the ReLU activation function for forward propagation and ReLU’s derivative that will be used during backpropagation:</p><div id="vL42di41DR" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define ReLU that returns the input if it&#x27;s positive and 0 otherwise.
def relu(x):
    return (x &gt;= 0) * x


# Set up a derivative of the ReLU function that returns 1 for a positive input
# and 0 otherwise.
def relu2deriv(output):
    return output &gt;= 0</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="-BEr4ILigsjvgJTp3sqbF" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><p><strong>3.</strong> Set certain default values of <a href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">hyperparameters</a>, such as:</p><ul><li><p><a href="https://en.wikipedia.org/wiki/Learning_rate" class="hover-link" target="_blank" rel="noreferrer" data-state="closed"><em>Learning rate</em></a>: <code>learning_rate</code> — helps limit the magnitude of weight updates to prevent them from overcorrecting.</p></li><li><p><em>Epochs (iterations)</em>: <code>epochs</code> — the number of complete passes — forward and backward propagations — of the data through the network. This parameter can positively or negatively affect the results. The higher the iterations, the longer the learning process may take. Because this is a computationally intensive task, we have chosen a very low number of epochs (20). To get meaningful results, you should choose a much larger number.</p></li><li><p><em>Size of the hidden (middle) layer in a network</em>: <code>hidden_size</code> — different sizes of the hidden layer can affect the results during training and testing.</p></li><li><p><em>Size of the input:</em> <code>pixels_per_image</code> — you have established that the image input is 784 (28x28) (in pixels).</p></li><li><p><em>Number of labels</em>: <code>num_labels</code> — indicates the output number for the output layer where the predictions occur for 10 (0 to 9) handwritten digit labels.</p></li></ul><div id="nCm94hdrml" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">learning_rate = 0.005
epochs = 20
hidden_size = 100
pixels_per_image = 784
num_labels = 10</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="YdbLSovz6WRtdck8Usxzu" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><p><strong>4.</strong> Initialize the weight vectors that will be used in the hidden and output layers with random values:</p><div id="bua4T2sW87" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">weights_1 = 0.2 * rng.random((pixels_per_image, hidden_size)) - 0.1
weights_2 = 0.2 * rng.random((hidden_size, num_labels)) - 0.1</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="xrYwJiEjbX_hMEIZf7xTk" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><p><strong>5.</strong> Set up the neural network’s learning experiment with a training loop and start the training process.
Note that the model is evaluated against the test set at each epoch to track
its performance over the training epochs.</p><p>Start the training process:</p><div id="QxpsV1xatJ" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># To store training and test set losses and accurate predictions
# for visualization.
store_training_loss = []
store_training_accurate_pred = []
store_test_loss = []
store_test_accurate_pred = []

# This is a training loop.
# Run the learning experiment for a defined number of epochs (iterations).
for j in range(epochs):

    #################
    # Training step #
    #################

    # Set the initial loss/error and the number of accurate predictions to zero.
    training_loss = 0.0
    training_accurate_predictions = 0

    # For all images in the training set, perform a forward pass
    # and backpropagation and adjust the weights accordingly.
    for i in range(len(training_images)):
        # Forward propagation/forward pass:
        # 1. The input layer:
        #    Initialize the training image data as inputs.
        layer_0 = training_images[i]
        # 2. The hidden layer:
        #    Take in the training image data into the middle layer by
        #    matrix-multiplying it by randomly initialized weights.
        layer_1 = np.dot(layer_0, weights_1)
        # 3. Pass the hidden layer&#x27;s output through the ReLU activation function.
        layer_1 = relu(layer_1)
        # 4. Define the dropout function for regularization.
        dropout_mask = rng.integers(low=0, high=2, size=layer_1.shape)
        # 5. Apply dropout to the hidden layer&#x27;s output.
        layer_1 *= dropout_mask * 2
        # 6. The output layer:
        #    Ingest the output of the middle layer into the the final layer
        #    by matrix-multiplying it by randomly initialized weights.
        #    Produce a 10-dimension vector with 10 scores.
        layer_2 = np.dot(layer_1, weights_2)

        # Backpropagation/backward pass:
        # 1. Measure the training error (loss function) between the actual
        #    image labels (the truth) and the prediction by the model.
        training_loss += np.sum((training_labels[i] - layer_2) ** 2)
        # 2. Increment the accurate prediction count.
        training_accurate_predictions += int(
            np.argmax(layer_2) == np.argmax(training_labels[i])
        )
        # 3. Differentiate the loss function/error.
        layer_2_delta = training_labels[i] - layer_2
        # 4. Propagate the gradients of the loss function back through the hidden layer.
        layer_1_delta = np.dot(weights_2, layer_2_delta) * relu2deriv(layer_1)
        # 5. Apply the dropout to the gradients.
        layer_1_delta *= dropout_mask
        # 6. Update the weights for the middle and input layers
        #    by multiplying them by the learning rate and the gradients.
        weights_1 += learning_rate * np.outer(layer_0, layer_1_delta)
        weights_2 += learning_rate * np.outer(layer_1, layer_2_delta)

    # Store training set losses and accurate predictions.
    store_training_loss.append(training_loss)
    store_training_accurate_pred.append(training_accurate_predictions)

    ###################
    # Evaluation step #
    ###################

    # Evaluate model performance on the test set at each epoch.

    # Unlike the training step, the weights are not modified for each image
    # (or batch). Therefore the model can be applied to the test images in a
    # vectorized manner, eliminating the need to loop over each image
    # individually:

    results = relu(test_images @ weights_1) @ weights_2

    # Measure the error between the actual label (truth) and prediction values.
    test_loss = np.sum((test_labels - results) ** 2)

    # Measure prediction accuracy on test set
    test_accurate_predictions = np.sum(
        np.argmax(results, axis=1) == np.argmax(test_labels, axis=1)
    )

    # Store test set losses and accurate predictions.
    store_test_loss.append(test_loss)
    store_test_accurate_pred.append(test_accurate_predictions)

    # Summarize error and accuracy metrics at each epoch
    print(
        (
            f&quot;Epoch: {j}\n&quot;
            f&quot;  Training set error: {training_loss / len(training_images):.3f}\n&quot;
            f&quot;  Training set accuracy: {training_accurate_predictions / len(training_images)}\n&quot;
            f&quot;  Test set error: {test_loss / len(test_images):.3f}\n&quot;
            f&quot;  Test set accuracy: {test_accurate_predictions / len(test_images)}&quot;
        )
    )</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="sl532XOA7u15BEMFowQRs" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 0
  Training set error: 0.898
  Training set accuracy: 0.397
  Test set error: 0.680
  Test set accuracy: 0.582
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 1
  Training set error: 0.656
  Training set accuracy: 0.633
  Test set error: 0.607
  Test set accuracy: 0.641
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 2
  Training set error: 0.592
  Training set accuracy: 0.68
  Test set error: 0.569
  Test set accuracy: 0.679
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 3
  Training set error: 0.556
  Training set accuracy: 0.7
  Test set error: 0.541
  Test set accuracy: 0.708
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 4
  Training set error: 0.534
  Training set accuracy: 0.732
  Test set error: 0.526
  Test set accuracy: 0.729
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 5
  Training set error: 0.515
  Training set accuracy: 0.715
  Test set error: 0.500
  Test set accuracy: 0.739
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 6
  Training set error: 0.495
  Training set accuracy: 0.748
  Test set error: 0.487
  Test set accuracy: 0.753
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 7
  Training set error: 0.483
  Training set accuracy: 0.769
  Test set error: 0.486
  Test set accuracy: 0.747
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 8
  Training set error: 0.473
  Training set accuracy: 0.776
  Test set error: 0.473
  Test set accuracy: 0.752
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 9
  Training set error: 0.460
  Training set accuracy: 0.788
  Test set error: 0.462
  Test set accuracy: 0.762
Epoch: 10
  Training set error: 0.465
  Training set accuracy: 0.769
  Test set error: 0.462
  Test set accuracy: 0.767
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 11
  Training set error: 0.443
  Training set accuracy: 0.801
  Test set error: 0.456
  Test set accuracy: 0.775
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 12
  Training set error: 0.448
  Training set accuracy: 0.795
  Test set error: 0.455
  Test set accuracy: 0.772
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 13
  Training set error: 0.438
  Training set accuracy: 0.787
  Test set error: 0.453
  Test set accuracy: 0.778
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 14
  Training set error: 0.446
  Training set accuracy: 0.791
  Test set error: 0.450
  Test set accuracy: 0.779
Epoch: 15
  Training set error: 0.441
  Training set accuracy: 0.788
  Test set error: 0.452
  Test set accuracy: 0.772
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 16
  Training set error: 0.437
  Training set accuracy: 0.786
  Test set error: 0.453
  Test set accuracy: 0.772
Epoch: 17
  Training set error: 0.436
  Training set accuracy: 0.794
  Test set error: 0.449
  Test set accuracy: 0.778
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 18
  Training set error: 0.433
  Training set accuracy: 0.801
  Test set error: 0.450
  Test set accuracy: 0.774
</span></code></pre></div></div><div data-name="safe-output-stream"><div><pre class="myst-jp-stream-output text-sm font-thin font-system"><code><span>Epoch: 19
  Training set error: 0.429
  Training set accuracy: 0.785
  Test set error: 0.436
  Test set accuracy: 0.784
</span></code></pre></div></div></div></div><p>The training process may take many minutes, depending on a number of factors, such as the processing power of the machine you are running the experiment on and the number of epochs. To reduce the waiting time, you can change the epoch (iteration) variable from 100 to a lower number, reset the runtime (which will reset the weights), and run the notebook cells again.</p><p>After executing the cell above, you can visualize the training and test set errors and accuracy for an instance of this training process.</p><div id="fosWp7yS6o" class="myst-jp-nb-block relative group/block"><div class="myst-jp-nb-block-spinner flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="myst-jp-nb-block sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute -top-[12px] right-0 flex flex-row rounded bg-white dark:bg-slate-800"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">epoch_range = np.arange(epochs) + 1  # Starting from 1

# The training set metrics.
training_metrics = {
    &quot;accuracy&quot;: np.asarray(store_training_accurate_pred) / len(training_images),
    &quot;error&quot;: np.asarray(store_training_loss) / len(training_images),
}

# The test set metrics.
test_metrics = {
    &quot;accuracy&quot;: np.asarray(store_test_accurate_pred) / len(test_images),
    &quot;error&quot;: np.asarray(store_test_loss) / len(test_images),
}

# Display the plots.
fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))
for ax, metrics, title in zip(
    axes, (training_metrics, test_metrics), (&quot;Training set&quot;, &quot;Test set&quot;)
):
    # Plot the metrics
    for metric, values in metrics.items():
        ax.plot(epoch_range, values, label=metric.capitalize())
    ax.set_title(title)
    ax.set_xlabel(&quot;Epochs&quot;)
    ax.legend()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-name="outputs-container" data-mdast-node-id="55bsp0jZQ0B2BPe0OUX0j" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div data-name="safe-output-image"><img src="/numpy-tutorials/build/87249290c03a34d5ea6dd3cb94f73280.png" alt="&lt;Figure size 1500x500 with 2 Axes&gt;"/></div></div></div><p><em>The training and testing error is shown above in the left and right
plots, respectively. As the number of Epochs increases, the total error
decreases and the accuracy increases.</em></p><p>The accuracy rates that your model reaches during training and testing may be somewhat plausible but you may also find the error rates to be quite high.</p><p>To reduce the error during training and testing, you can consider changing the simple loss function to, for example, categorical <a href="https://en.wikipedia.org/wiki/Cross_entropy" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">cross-entropy</a>. Other possible solutions are discussed below.</p><h2 id="next-steps" class="relative group"><span class="heading-text">Next steps</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#next-steps" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>You have learned how to build and train a simple feed-forward neural network from scratch using just NumPy to classify handwritten MNIST digits.</p><p>To further enhance and optimize your neural network model, you can consider one of a mixture of the following:</p><ul><li><p>Increase the training sample size from 1,000 to a higher number (up to 60,000).</p></li><li><p>Use <a target="_blank" rel="noreferrer" href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf" class="link">mini-batches and reduce the learning rate<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>.</p></li><li><p>Alter the architecture by introducing more hidden layers to make the network <a href="https://en.wikipedia.org/wiki/Deep_learning" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">deeper</a>.</p></li><li><p>Combine the <a href="https://en.wikipedia.org/wiki/Cross_entropy" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">cross-entropy</a> loss function with a <a href="https://en.wikipedia.org/wiki/Softmax_function" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">softmax</a> activation function in the last layer.</p></li><li><p>Introduce convolutional layers: replace the feedforward network with a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">convolutional neural network</a> architecture.</p></li><li><p>Use a higher epoch size to train longer and add more regularization techniques, such as <a href="https://en.wikipedia.org/wiki/Early_stopping" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">early stopping</a>, to prevent <a href="https://en.wikipedia.org/wiki/Overfitting" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">overfitting</a>.</p></li><li><p>Introduce a <a href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">validation set</a> for an unbiased valuation of the model fit.</p></li><li><p>Apply <a href="https://en.wikipedia.org/wiki/Batch_normalization" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">batch normalization</a> for faster and more stable training.</p></li><li><p>Tune other parameters, such as the learning rate and hidden layer size.</p></li></ul><p>Building a neural network from scratch with NumPy is a great way to learn more about NumPy and about deep learning. However, for real-world applications you should use specialized frameworks — such as <a target="_blank" rel="noreferrer" href="https://pytorch.org/" class="link">PyTorch<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, <a target="_blank" rel="noreferrer" href="https://github.com/google/jax" class="link">JAX<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>, <a target="_blank" rel="noreferrer" href="https://www.tensorflow.org/guide/tf_numpy" class="link">TensorFlow<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> or <a target="_blank" rel="noreferrer" href="https://mxnet.apache.org" class="link">MXNet<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> — that provide NumPy-like APIs, have built-in <a href="https://en.wikipedia.org/wiki/Automatic_differentiation" class="hover-link" target="_blank" rel="noreferrer" data-state="closed">automatic differentiation</a> and GPU support, and are designed for high-performance numerical computing and machine learning.</p><p>Finally, when developing a machine learning model, you should think about potential ethical issues and apply practices to avoid or mitigate those:</p><ul><li><p>Document a trained model with a Model Card - see the <cite class="" data-state="closed"><a href="https://doi.org/10.1145/3287560.3287596" target="_blank" rel="noreferrer" class="hover-link">Model Cards for Model Reporting paper</a></cite> by Margaret Mitchell et al..</p></li><li><p>Document a dataset with a Datasheet - see the <a target="_blank" rel="noreferrer" href="https://arxiv.org/abs/1803.09010" class="link">Datasheets for Datasets paper<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>) by Timnit Gebru et al..</p></li><li><p>Consider the impact of your model - who is affected by it, who does it benefit - see <a target="_blank" rel="noreferrer" href="https://www.nature.com/articles/d41586-020-02003-2" class="link">the article<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> and <a target="_blank" rel="noreferrer" href="https://slideslive.com/38923453/the-values-of-machine-learning" class="link">talk<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> by Pratyusha Kalluri.</p></li><li><p>For more resources, see <a target="_blank" rel="noreferrer" href="https://www.fast.ai/2018/09/24/ai-ethics-resources/" class="link">this blog post by Rachel Thomas<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> and the <a target="_blank" rel="noreferrer" href="https://www.radicalai.org/" class="link">Radical AI podcast<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a>.</p></li></ul><p>(Credit to <a target="_blank" rel="noreferrer" href="https://github.com/hsjeong5/MNIST-for-Numpy" class="link">hsjeong5<svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="link-icon"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 6H5.25A2.25 2.25 0 0 0 3 8.25v10.5A2.25 2.25 0 0 0 5.25 21h10.5A2.25 2.25 0 0 0 18 18.75V10.5m-10.5 6L21 3m0 0h-5.25M21 3v5.25"></path></svg></a> for demonstrating how to download MNIST without the use of external libraries.)</p><div class="myst-backmatter-parts"></div><section id="references" class="myst-bibliography article-grid subgrid-gap col-screen"><div><header class="myst-bibliography-header text-lg font-semibold text-stone-900 dark:text-white group">References<a class="no-underline text-inherit hover:text-inherit ml-2 select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#references" title="Link to References" aria-label="Link to References">¶</a></header></div><div class="myst-bibliography-list pl-3 mb-8 text-xs text-stone-500 dark:text-stone-300"><ol><li class="myst-bibliography-item break-words" id="cite-Mitchell_2019">Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., Spitzer, E., Raji, I. D., & Gebru, T. (2019). Model Cards for Model Reporting. <i>Proceedings of the Conference on Fairness, Accountability, and Transparency</i>, 220–229. <a target="_blank" rel="noreferrer" href="https://doi.org/10.1145/3287560.3287596">10.1145/3287560.3287596</a></li></ol></div></section><div class="myst-footer-links flex pt-10 mb-10 space-x-4"><a class="myst-footer-link flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700 myst-footer-link-prev" href="/numpy-tutorials/mooreslaw-tutorial"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-footer-link-icon self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="myst-footer-link-group text-xs text-gray-500 dark:text-gray-400">Applications</div>Moore&#x27;s Law</div></div></a><a class="myst-footer-link flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700 myst-footer-link-next" href="/numpy-tutorials/tutorial-x-ray-image-processing"><div class="flex h-full align-middle"><div class="flex-grow"><div class="myst-footer-link-group text-xs text-gray-500 dark:text-gray-400">Applications</div>X-ray image processing</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="myst-footer-link-icon self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></article></main><script>((a,l)=>{if(!window.history.state||!window.history.state.key){let u=Math.random().toString(32).slice(2);window.history.replaceState({key:u},"")}try{let d=JSON.parse(sessionStorage.getItem(a)||"{}")[l||window.history.state.key];typeof d=="number"&&window.scrollTo(0,d)}catch(u){console.error(u),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/numpy-tutorials/build/entry.client-PCJPW7TK.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-AQ2CODAG.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-JJXTQVMA.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-OZE3FFNP.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-CH4FVTDV.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-C4DFGG5C.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-J7TUH54J.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-FZ2S7OYD.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-JEM6JXYA.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-34XIY2DH.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-KQM5FBHR.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-7HNKBP4B.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-CUKUDK3R.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-3EBOCCHJ.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-O4VQNZ62.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-4OEDG4JQ.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/numpy-tutorials/build/root-SIO6LUTY.js"/><link rel="modulepreload" href="/numpy-tutorials/build/_shared/chunk-FAHZZXAC.js"/><link rel="modulepreload" href="/numpy-tutorials/build/routes/$-PRP77N34.js"/><script>window.__remixContext = {"url":"/tutorial-deep-learning-on-mnist","state":{"loaderData":{"root":{"config":{"version":3,"myst":"1.8.0","options":{"favicon":"/numpy-tutorials/build/favicon-ea9223d23b14c1a4324de69e580eef0d.png","logo":"/numpy-tutorials/build/numpylogo-278cf34e28ed8e84d4b79121bf103557.svg"},"nav":[],"actions":[],"projects":[{"title":"Numpy Tutorials","authors":[{"id":"Numpy Community","name":"Numpy Community"}],"github":"https://github.com/numpy/numpy-tutorials","toc":[{"file":"content/index.md"},{"children":[{"file":"content/mooreslaw-tutorial.md"},{"file":"content/tutorial-deep-learning-on-mnist.md"},{"file":"content/tutorial-x-ray-image-processing.md"},{"file":"content/tutorial-static_equilibrium.md"},{"file":"content/tutorial-plotting-fractals.md"},{"file":"content/tutorial-air-quality-analysis.md"}],"title":"Applications"},{"children":[{"file":"content/tutorial-svd.md"},{"file":"content/save-load-arrays.md"},{"file":"content/tutorial-ma.md"}],"title":"Features"},{"children":[{"file":"content/tutorial-style-guide.md"}],"file":"content/contributing.md","title":"Contributing"}],"thumbnail":"/numpy-tutorials/build/b77199e99a54e59b2e3c037c2cc90f21.svg","exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"Applications"},{"slug":"mooreslaw-tutorial","title":"Determining Moore’s Law with real data in NumPy","short_title":"Moore's Law","description":"","date":"","thumbnail":"/numpy-tutorials/build/01-mooreslaw-tutoria-b7ed0ec7045e43a575dc871f1d80ba79.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-deep-learning-on-mnist","title":"Deep learning on MNIST","description":"","date":"","thumbnail":"/numpy-tutorials/build/tutorial-deep-learni-18c33a02a86a205d4dc00e618c78f2e1.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-x-ray-image-processing","title":"X-ray image processing","description":"","date":"","thumbnail":"/numpy-tutorials/build/tutorial-x-ray-image-65a7be1124126ce5b284c9f07ce0d6ed.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-static-equilibrium","title":"Determining Static Equilibrium in NumPy","short_title":"Static Equilibrium","description":"","date":"","thumbnail":"/numpy-tutorials/build/static_eqbm-fig01-02f515938c9167160a1aa8c0c979c840.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-plotting-fractals","title":"Plotting Fractals","description":"","date":"","thumbnail":"/numpy-tutorials/build/fractal-05cf84dbcdf76b80fa747a06f861f631.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-air-quality-analysis","title":"Analyzing the impact of the lockdown on air quality in Delhi, India","short_title":"Analyzing Air Quality","description":"","date":"","thumbnail":"/numpy-tutorials/build/11-delhi-aqi-719dde59d7502416fd089cc1a3ee750a.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Features"},{"slug":"tutorial-svd","title":"Linear algebra on n-dimensional arrays","short_title":"Linear Algebra on n-D arrays","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"save-load-arrays","title":"Saving and sharing your NumPy arrays","short_title":"Sharing Array Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-ma","title":"Masked Arrays","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"contributing","title":"Contributing","short_title":"Contributing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"tutorial-style-guide","title":"Learn to write a NumPy tutorial","short_title":"Style Guide","description":"","date":"","thumbnail":"/numpy-tutorials/build/56554e3d11983df8f484e8d7b2c2bdae.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/numpy-tutorials"},"routes/$":{"config":{"version":3,"myst":"1.8.0","options":{"favicon":"/numpy-tutorials/build/favicon-ea9223d23b14c1a4324de69e580eef0d.png","logo":"/numpy-tutorials/build/numpylogo-278cf34e28ed8e84d4b79121bf103557.svg"},"nav":[],"actions":[],"projects":[{"title":"Numpy Tutorials","authors":[{"id":"Numpy Community","name":"Numpy Community"}],"github":"https://github.com/numpy/numpy-tutorials","toc":[{"file":"content/index.md"},{"children":[{"file":"content/mooreslaw-tutorial.md"},{"file":"content/tutorial-deep-learning-on-mnist.md"},{"file":"content/tutorial-x-ray-image-processing.md"},{"file":"content/tutorial-static_equilibrium.md"},{"file":"content/tutorial-plotting-fractals.md"},{"file":"content/tutorial-air-quality-analysis.md"}],"title":"Applications"},{"children":[{"file":"content/tutorial-svd.md"},{"file":"content/save-load-arrays.md"},{"file":"content/tutorial-ma.md"}],"title":"Features"},{"children":[{"file":"content/tutorial-style-guide.md"}],"file":"content/contributing.md","title":"Contributing"}],"thumbnail":"/numpy-tutorials/build/b77199e99a54e59b2e3c037c2cc90f21.svg","exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"Applications"},{"slug":"mooreslaw-tutorial","title":"Determining Moore’s Law with real data in NumPy","short_title":"Moore's Law","description":"","date":"","thumbnail":"/numpy-tutorials/build/01-mooreslaw-tutoria-b7ed0ec7045e43a575dc871f1d80ba79.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-deep-learning-on-mnist","title":"Deep learning on MNIST","description":"","date":"","thumbnail":"/numpy-tutorials/build/tutorial-deep-learni-18c33a02a86a205d4dc00e618c78f2e1.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-x-ray-image-processing","title":"X-ray image processing","description":"","date":"","thumbnail":"/numpy-tutorials/build/tutorial-x-ray-image-65a7be1124126ce5b284c9f07ce0d6ed.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-static-equilibrium","title":"Determining Static Equilibrium in NumPy","short_title":"Static Equilibrium","description":"","date":"","thumbnail":"/numpy-tutorials/build/static_eqbm-fig01-02f515938c9167160a1aa8c0c979c840.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-plotting-fractals","title":"Plotting Fractals","description":"","date":"","thumbnail":"/numpy-tutorials/build/fractal-05cf84dbcdf76b80fa747a06f861f631.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-air-quality-analysis","title":"Analyzing the impact of the lockdown on air quality in Delhi, India","short_title":"Analyzing Air Quality","description":"","date":"","thumbnail":"/numpy-tutorials/build/11-delhi-aqi-719dde59d7502416fd089cc1a3ee750a.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Features"},{"slug":"tutorial-svd","title":"Linear algebra on n-dimensional arrays","short_title":"Linear Algebra on n-D arrays","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"save-load-arrays","title":"Saving and sharing your NumPy arrays","short_title":"Sharing Array Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-ma","title":"Masked Arrays","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"contributing","title":"Contributing","short_title":"Contributing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"tutorial-style-guide","title":"Learn to write a NumPy tutorial","short_title":"Style Guide","description":"","date":"","thumbnail":"/numpy-tutorials/build/56554e3d11983df8f484e8d7b2c2bdae.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"page":{"version":3,"kind":"Notebook","sha256":"111785384f4be36833de17ef8ce0c78cd45dd4d9e6ff84ce37a3d7288958d621","slug":"tutorial-deep-learning-on-mnist","location":"/content/tutorial-deep-learning-on-mnist.md","dependencies":[],"frontmatter":{"title":"Deep learning on MNIST","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"jupytext":{"text_representation":{"extension":".md","format_name":"myst","format_version":"0.13","jupytext_version":"1.11.1"}},"content_includes_title":false,"authors":[{"id":"Numpy Community","name":"Numpy Community"}],"github":"https://github.com/numpy/numpy-tutorials","numbering":{"title":{"offset":1}},"source_url":"https://github.com/numpy/numpy-tutorials/blob/main/content/tutorial-deep-learning-on-mnist.md","edit_url":"https://github.com/numpy/numpy-tutorials/edit/main/content/tutorial-deep-learning-on-mnist.md","thumbnail":"/numpy-tutorials/build/tutorial-deep-learni-18c33a02a86a205d4dc00e618c78f2e1.png","exports":[{"format":"md","filename":"tutorial-deep-learning-on-mnist.md","url":"/numpy-tutorials/build/tutorial-deep-learni-1fd9a5045f67a505db7379099f85e15d.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"This tutorial demonstrates how to build a simple ","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"rXhSWSxhLq"},{"type":"link","url":"https://en.wikipedia.org/wiki/Feedforward_neural_network","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"feedforward neural network","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"a2jOOZLiBJ"}],"urlSource":"https://en.wikipedia.org/wiki/Feedforward_neural_network","data":{"page":"Feedforward_neural_network","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"VEyOiS8y4q"},{"type":"text","value":" (with one hidden layer) and train it from scratch with NumPy to recognize handwritten digit images.","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"lDOMyYzpEn"}],"key":"tzBJv1g9NS"},{"type":"paragraph","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"Your deep learning model — one of the most basic artificial neural networks that resembles the original ","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"ghf97qAPim"},{"type":"link","url":"https://en.wikipedia.org/wiki/Multilayer_perceptron","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"multi-layer perceptron","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"DyjsvNpTpQ"}],"urlSource":"https://en.wikipedia.org/wiki/Multilayer_perceptron","data":{"page":"Multilayer_perceptron","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"PCtGAY4fHn"},{"type":"text","value":" — will learn to classify digits from 0 to 9 from the ","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"mbj9ECom9q"},{"type":"link","url":"https://en.wikipedia.org/wiki/MNIST_database","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"MNIST","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"kqlb5Taoab"}],"urlSource":"https://en.wikipedia.org/wiki/MNIST_database","data":{"page":"MNIST_database","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"od1ehDPrSQ"},{"type":"text","value":" dataset. The dataset contains 60,000 training and 10,000 test images and corresponding labels. Each training and test image is of size 784 (or 28x28 pixels) — this will be your input for the neural network.","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"EbnvC5Bzy4"}],"key":"atk46o5Qne"},{"type":"paragraph","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"Based on the image inputs and their labels (","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"pvixNVquzo"},{"type":"link","url":"https://en.wikipedia.org/wiki/Supervised_learning","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"supervised learning","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"weR47Xg1gJ"}],"urlSource":"https://en.wikipedia.org/wiki/Supervised_learning","data":{"page":"Supervised_learning","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"yzUHwYOVur"},{"type":"text","value":"), your neural network will be trained to learn their features using forward propagation and backpropagation (","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"v2I2KGcluC"},{"type":"link","url":"https://en.wikipedia.org/wiki/Automatic_differentiation#Reverse_accumulation","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"text","value":"reverse-mode","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"WHV3SjQph7"}],"urlSource":"https://en.wikipedia.org/wiki/Automatic_differentiation#Reverse_accumulation","data":{"page":"Automatic_differentiation#Reverse_accumulation","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"rcwB1uyMtk"},{"type":"text","value":" differentiation). The final output of the network is a vector of 10 scores — one for each handwritten digit image. You will also evaluate how good your model is at classifying the images on the test set.","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"ppm00UhOdF"}],"key":"qq68Za8tWm"},{"type":"image","url":"/numpy-tutorials/build/tutorial-deep-learni-18c33a02a86a205d4dc00e618c78f2e1.png","alt":"Diagram showing operations detailed in this tutorial (The input imageis passed into a Hidden layer that creates a weighted sum of outputs.The weighted sum is passed to the Non-linearity, then regularization andinto the output layer. The output layer creates a prediction which canthen be compared to existing data. The errors are used to calculate theloss function and update weights in the hidden layer and outputlayer.)","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"flbOxZBY74","urlSource":"_static/tutorial-deep-learning-on-mnist.png"},{"type":"paragraph","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"This tutorial was adapted from the work by ","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"Vs68G5YEFl"},{"type":"link","url":"https://github.com/iamtrask/Grokking-Deep-Learning","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"Andrew Trask","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"f6zwdjwMbx"}],"urlSource":"https://github.com/iamtrask/Grokking-Deep-Learning","error":true,"key":"WSu6kFQosq"},{"type":"text","value":" (with the author’s permission).","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"gbr1H3chjr"}],"key":"LrItQctQO5"},{"type":"heading","depth":2,"position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"Prerequisites","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"RwfMRjOVEj"}],"identifier":"prerequisites","label":"Prerequisites","html_id":"prerequisites","implicit":true,"key":"HqqFMqMInX"},{"type":"paragraph","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"The reader should have some knowledge of Python, NumPy array manipulation, and linear algebra. In addition, you should be familiar with main concepts of ","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"QUlt7OH9GD"},{"type":"link","url":"https://en.wikipedia.org/wiki/Deep_learning","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"deep learning","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"qj0PdIzSx1"}],"urlSource":"https://en.wikipedia.org/wiki/Deep_learning","data":{"page":"Deep_learning","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"AlPdCiTGri"},{"type":"text","value":".","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"aa5JfKKiMf"}],"key":"AjwPj62or5"},{"type":"paragraph","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"To refresh the memory, you can take the ","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"byu9Tp9s7X"},{"type":"link","url":"https://docs.python.org/dev/tutorial/index.html","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"text","value":"Python","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"VySIO4Y0xn"}],"urlSource":"https://docs.python.org/dev/tutorial/index.html","key":"PnPvIyWZZ1"},{"type":"text","value":" and ","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"QtETNVcBwr"},{"type":"link","url":"/tutorial-svd","urlSource":"tutorial-svd","dataUrl":"/tutorial-svd.json","internal":true,"children":[{"type":"text","value":"Linear algebra on n-dimensional arrays","key":"sfz8XyoNRO"}],"protocol":"file","key":"Nsn2t3btyC"},{"type":"text","value":" tutorials.","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"fTlxMxHBr5"}],"key":"VsDnCqvwF2"},{"type":"paragraph","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"You are advised to read the ","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"TaVdG8vuQp"},{"type":"link","url":"http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"Deep learning","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"KkeHPZDn1T"}],"urlSource":"http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf","key":"kUSgnOTVRe"},{"type":"text","value":" paper published in 2015 by Yann LeCun, Yoshua Bengio, and Geoffrey Hinton, who are regarded as some of the pioneers of the field. You should also consider reading Andrew Trask’s ","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"UFdrfftI7q"},{"type":"link","url":"https://www.manning.com/books/grokking-deep-learning","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"text","value":"Grokking Deep Learning","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"aUhehbW8zM"}],"urlSource":"https://www.manning.com/books/grokking-deep-learning","key":"qwzTjTHZsW"},{"type":"text","value":", which teaches deep learning with NumPy.","position":{"start":{"line":38,"column":1},"end":{"line":38,"column":1}},"key":"BE1gkacsUl"}],"key":"i6kymPU70A"},{"type":"paragraph","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"children":[{"type":"text","value":"In addition to NumPy, you will be utilizing the following Python standard modules for data loading and processing:","position":{"start":{"line":40,"column":1},"end":{"line":40,"column":1}},"key":"KYKBkFJgYS"}],"key":"S0tztHi9no"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":41,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"link","url":"https://docs.python.org/3/library/urllib.html","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"inlineCode","value":"urllib","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"d2Y8a7Rjo7"}],"urlSource":"https://docs.python.org/3/library/urllib.html","key":"ddy2aKNsZd"},{"type":"text","value":" for URL handling","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"g9XFMkbahG"}],"key":"GoOW15dozn"}],"key":"zpGxekKQWo"},{"type":"listItem","spread":true,"position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"link","url":"https://docs.python.org/3/library/urllib.request.html","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"children":[{"type":"inlineCode","value":"request","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"sd8Mxg09jr"}],"urlSource":"https://docs.python.org/3/library/urllib.request.html","key":"e9XkbumKzV"},{"type":"text","value":" for URL opening","position":{"start":{"line":42,"column":1},"end":{"line":42,"column":1}},"key":"yg12xbpXkx"}],"key":"h7gvoEjTEu"}],"key":"JrpXutqqp0"},{"type":"listItem","spread":true,"position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"link","url":"https://docs.python.org/3/library/gzip.html","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"inlineCode","value":"gzip","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"u958lIXLaw"}],"urlSource":"https://docs.python.org/3/library/gzip.html","key":"fU8tOAXP0a"},{"type":"text","value":" for gzip file decompression","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"azp07xjhDy"}],"key":"UL9I67knx1"}],"key":"ZAsk4bbrez"},{"type":"listItem","spread":true,"position":{"start":{"line":44,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"link","url":"https://docs.python.org/3/library/pickle.html","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"inlineCode","value":"pickle","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"JZluwX4oi2"}],"urlSource":"https://docs.python.org/3/library/pickle.html","key":"bYexIoF4H3"},{"type":"text","value":" to work with the pickle file format","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"f5OpNocqfe"}],"key":"ZHcic1MTxE"},{"type":"paragraph","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"as well as:","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"jG7YSIxfin"}],"key":"QitTsrxrzV"}],"key":"xCfYigEwsJ"},{"type":"listItem","spread":true,"position":{"start":{"line":47,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"link","url":"https://matplotlib.org/","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"text","value":"Matplotlib","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"QKxmwGPEly"}],"urlSource":"https://matplotlib.org/","key":"aP8K5LVLrM"},{"type":"text","value":" for data visualization","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"FezJFEvFza"}],"key":"bKLF9FYwnB"}],"key":"vOrje0V1bE"}],"key":"MOPY5CiE8u"},{"type":"paragraph","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"This tutorial can be run locally in an isolated environment, such as ","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"Ylfn148XA4"},{"type":"link","url":"https://virtualenv.pypa.io/en/stable/","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"Virtualenv","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"mQNJ5ZYG7K"}],"urlSource":"https://virtualenv.pypa.io/en/stable/","key":"l1iPnJhnIl"},{"type":"text","value":" or ","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"YLwS9xAMqb"},{"type":"link","url":"https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"conda","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"m1ldNwIQzw"}],"urlSource":"https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html","key":"pxKXYtOJ2l"},{"type":"text","value":". You can use ","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"A5mA1LHTly"},{"type":"link","url":"https://jupyter.org/install","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"Jupyter Notebook or JupyterLab","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"XXzbNgjdoF"}],"urlSource":"https://jupyter.org/install","key":"qPUHlJxnUL"},{"type":"text","value":" to run each notebook cell. Don’t forget to ","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"DlwJ0ZfVMK"},{"type":"link","url":"https://numpy.org/doc/stable/user/absolute_beginners.html#installing-numpy","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"set up NumPy","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"kAji7kp7f4"}],"urlSource":"https://numpy.org/doc/stable/user/absolute_beginners.html#installing-numpy","key":"NIekwvacnu"},{"type":"text","value":" and ","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"XCYnBuictG"},{"type":"link","url":"https://matplotlib.org/users/installing.html#installing-an-official-release","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"text","value":"Matplotlib","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"G5D6RaeQvZ"}],"urlSource":"https://matplotlib.org/users/installing.html#installing-an-official-release","key":"phiMDLaF8b"},{"type":"text","value":".","position":{"start":{"line":49,"column":1},"end":{"line":49,"column":1}},"key":"XiWOR5ywRY"}],"key":"GrHAhmkHpl"},{"type":"heading","depth":2,"position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"children":[{"type":"text","value":"Table of contents","position":{"start":{"line":51,"column":1},"end":{"line":51,"column":1}},"key":"fWQR0pAQlV"}],"identifier":"table-of-contents","label":"Table of contents","html_id":"table-of-contents","implicit":true,"key":"LhiIaI7VKF"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":53,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":53,"column":1},"end":{"line":54,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"children":[{"type":"text","value":"Load the MNIST dataset","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"RCmSUHNIGC"}],"key":"GnchhOuMjt"}],"key":"EcwcMhwD21"},{"type":"listItem","spread":true,"position":{"start":{"line":55,"column":1},"end":{"line":56,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"text","value":"Preprocess the dataset","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"key":"mOmX7wkQCW"}],"key":"FNMc67Nog4"}],"key":"ZNNcI2bRby"},{"type":"listItem","spread":true,"position":{"start":{"line":57,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"text","value":"Build and train a small neural network from scratch","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"oyW02gGiXo"}],"key":"fo3Jigzcax"}],"key":"SdCyYcHQdr"},{"type":"listItem","spread":true,"position":{"start":{"line":59,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"children":[{"type":"text","value":"Next steps","position":{"start":{"line":59,"column":1},"end":{"line":59,"column":1}},"key":"d05JwwldGP"}],"key":"U5guxtH61e"}],"key":"old9XAKbmG"}],"key":"EZT15wC8R4"},{"type":"thematicBreak","position":{"start":{"line":61,"column":1},"end":{"line":61,"column":1}},"key":"hiZfbfE5jc"},{"type":"heading","depth":2,"position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"text","value":"1. Load the MNIST dataset","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"aD95XveZDk"}],"identifier":"id-1-load-the-mnist-dataset","label":"1. Load the MNIST dataset","html_id":"id-1-load-the-mnist-dataset","implicit":true,"key":"zy7wPVNW2T"},{"type":"paragraph","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"children":[{"type":"text","value":"In this section, you will download the zipped MNIST dataset files originally developed by Yann LeCun’s research team. (More details of the MNIST dataset are available on ","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"AyVyGZYXK8"},{"type":"link","url":"https://www.kaggle.com/datasets/hojjatk/mnist-dataset","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"children":[{"type":"text","value":"Kaggle","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"n15DLOvb4y"}],"urlSource":"https://www.kaggle.com/datasets/hojjatk/mnist-dataset","key":"EuP1GRk7yO"},{"type":"text","value":".) Then, you will transform them into 4 files of NumPy array type using built-in Python modules. Finally, you will split the arrays into training and test sets.","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"hY2bCtd1Hd"}],"key":"vIwjQiFlL1"},{"type":"paragraph","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"strong","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"text","value":"1.","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"ozeCXx35x0"}],"key":"UFoeVeoqDn"},{"type":"text","value":" Define a variable to store the training/test image/label names of the MNIST dataset in a list:","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"pDd3nhKsxO"}],"key":"IPe9a2XLK2"}],"key":"Og7H3ZSc9P"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"data_sources = {\n    \"training_images\": \"train-images-idx3-ubyte.gz\",  # 60,000 training images.\n    \"test_images\": \"t10k-images-idx3-ubyte.gz\",  # 10,000 test images.\n    \"training_labels\": \"train-labels-idx1-ubyte.gz\",  # 60,000 training labels.\n    \"test_labels\": \"t10k-labels-idx1-ubyte.gz\",  # 10,000 test labels.\n}","key":"EZDP9ZjALF"},{"type":"outputs","id":"DIyrl0itrPgO5VFflxx-U","children":[],"key":"N07JQgMqf1"}],"key":"Yd3PqtD7qc"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":78,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"strong","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"children":[{"type":"text","value":"2.","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"QoEXSsTQEe"}],"key":"k4ba78iZen"},{"type":"text","value":" Load the data. First check if the data is stored locally; if not, then\ndownload it.","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"wMt6dDo8to"}],"key":"h5c2vCdxzP"}],"key":"sQtprEzQJC"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Use responsibly! When running notebooks locally, be sure to keep local\n# copies of the datasets to prevent unnecessary server requests\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0\"\n}\nrequest_opts = {\n    \"headers\": headers,\n    \"params\": {\"raw\": \"true\"},\n}","visibility":"show","key":"EXt7bAwfQ2"},{"type":"outputs","id":"zooZSWFO_QqYthA1pGpGx","children":[],"visibility":"show","key":"yL5dhnR3rd"}],"data":{"tags":[]},"visibility":"remove","key":"AGDWVCdmhi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import requests\nimport os\n\ndata_dir = \"../_data\"\nos.makedirs(data_dir, exist_ok=True)\n\nbase_url = \"https://ossci-datasets.s3.amazonaws.com/mnist/\"\n\nfor fname in data_sources.values():\n    fpath = os.path.join(data_dir, fname)\n    if not os.path.exists(fpath):\n        print(\"Downloading file: \" + fname)\n        resp = requests.get(base_url + fname, stream=True, **request_opts)\n        resp.raise_for_status()  # Ensure download was succesful\n        with open(fpath, \"wb\") as fh:\n            for chunk in resp.iter_content(chunk_size=128):\n                fh.write(chunk)","key":"oHfg2uoP9i"},{"type":"outputs","id":"Ab52FiXPC_lF0xKUr1oA_","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Downloading file: train-images-idx3-ubyte.gz\n"},"key":"PdlzQUSaO8"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Downloading file: t10k-images-idx3-ubyte.gz\n"},"key":"ZAs7hNkjTK"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Downloading file: train-labels-idx1-ubyte.gz\n"},"key":"chgu7VeSAY"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Downloading file: t10k-labels-idx1-ubyte.gz\n"},"key":"xTyOqZw5tL"}],"key":"gByuCUCk2Q"}],"key":"rsmjFpml7N"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"children":[{"type":"strong","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"children":[{"type":"text","value":"3.","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"key":"rgzsXfhBIH"}],"key":"guJ8b57cMa"},{"type":"text","value":" Decompress the 4 files and create 4 ","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"key":"PFTeiDWC2h"},{"type":"link","url":"https://numpy.org/doc/stable/reference/arrays.ndarray.html","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"children":[{"type":"inlineCode","value":"ndarrays","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"key":"q82FdsTDhd"}],"urlSource":"https://numpy.org/doc/stable/reference/arrays.ndarray.html","key":"TNs9rSXcYC"},{"type":"text","value":", saving them into a dictionary. Each original image is of size 28x28 and neural networks normally expect a 1D vector input; therefore, you also need to reshape the images by multiplying 28 by 28 (784).","position":{"start":{"line":115,"column":1},"end":{"line":115,"column":1}},"key":"AC2ykDpSax"}],"key":"IXIXg6LyGj"}],"key":"XE75xlGhJM"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import gzip\nimport numpy as np\n\nmnist_dataset = {}\n\n# Images\nfor key in (\"training_images\", \"test_images\"):\n    with gzip.open(os.path.join(data_dir, data_sources[key]), \"rb\") as mnist_file:\n        mnist_dataset[key] = np.frombuffer(\n            mnist_file.read(), np.uint8, offset=16\n        ).reshape(-1, 28 * 28)\n# Labels\nfor key in (\"training_labels\", \"test_labels\"):\n    with gzip.open(os.path.join(data_dir, data_sources[key]), \"rb\") as mnist_file:\n        mnist_dataset[key] = np.frombuffer(mnist_file.read(), np.uint8, offset=8)","key":"FwtWSQTTa4"},{"type":"outputs","id":"drMzKZwTQDHp-6fbVPLxp","children":[],"key":"gLjckvHYoi"}],"key":"cYI8iDCcNX"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"children":[{"type":"strong","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"children":[{"type":"text","value":"4.","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"zLzfFOAcRe"}],"key":"MTdiwp8BjO"},{"type":"text","value":" Split the data into training and test sets using the standard notation of ","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"WyXMlv3gUo"},{"type":"inlineCode","value":"x","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"Z8DaDHoULv"},{"type":"text","value":" for data and ","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"aUHToHIqY7"},{"type":"inlineCode","value":"y","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"mXcZqgrOfj"},{"type":"text","value":" for labels, calling the training and test set images ","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"XOrlE9IIcd"},{"type":"inlineCode","value":"x_train","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"zN6984vy7c"},{"type":"text","value":" and ","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"pSjCTHcGMj"},{"type":"inlineCode","value":"x_test","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"YLrqYL9SCI"},{"type":"text","value":", and the labels ","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"sJ3zC9eXYX"},{"type":"inlineCode","value":"y_train","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"z9FziBxsbf"},{"type":"text","value":" and ","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"s0n8t0S1gW"},{"type":"inlineCode","value":"y_test","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"dV719KrjN9"},{"type":"text","value":":","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"a7FPqS2nu9"}],"key":"kMdtoG8ThE"}],"key":"iXEkExZlHd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"x_train, y_train, x_test, y_test = (\n    mnist_dataset[\"training_images\"],\n    mnist_dataset[\"training_labels\"],\n    mnist_dataset[\"test_images\"],\n    mnist_dataset[\"test_labels\"],\n)","key":"afCUahTRPB"},{"type":"outputs","id":"1UvYQW9iYtCs9eIpJK8bj","children":[],"key":"JCTXebSfOg"}],"key":"ZmeDSL5n04"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"children":[{"type":"strong","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"children":[{"type":"text","value":"5.","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"RGUNgekRKS"}],"key":"YoXSnsHO9x"},{"type":"text","value":" You can confirm that the shape of the image arrays is ","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"E22K9n78tt"},{"type":"inlineCode","value":"(60000, 784)","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"A7kgnnzb8O"},{"type":"text","value":" and ","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"xqaIM1qg5O"},{"type":"inlineCode","value":"(10000, 784)","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"YXE9YhZYqD"},{"type":"text","value":" for training and test sets, respectively, and the labels — ","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"IxhAhIqWel"},{"type":"inlineCode","value":"(60000,)","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"lILu9wrm9t"},{"type":"text","value":" and ","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"YtXTwj7Zu2"},{"type":"inlineCode","value":"(10000,)","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"EFOnOPUJws"},{"type":"text","value":":","position":{"start":{"line":146,"column":1},"end":{"line":146,"column":1}},"key":"dB76Km0EPY"}],"key":"qyOXa5iWhu"}],"key":"am0CicfmKl"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(\n    \"The shape of training images: {} and training labels: {}\".format(\n        x_train.shape, y_train.shape\n    )\n)\nprint(\n    \"The shape of test images: {} and test labels: {}\".format(\n        x_test.shape, y_test.shape\n    )\n)","key":"kSjNA1jxTv"},{"type":"outputs","id":"UHBe-UpNbos7TOeL6u-8x","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"The shape of training images: (60000, 784) and training labels: (60000,)\nThe shape of test images: (10000, 784) and test labels: (10000,)\n"},"key":"oWdZQY3KLb"}],"key":"oAGMlOMHpQ"}],"key":"UzMwBks9cS"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":161,"column":1},"end":{"line":161,"column":1}},"children":[{"type":"strong","position":{"start":{"line":161,"column":1},"end":{"line":161,"column":1}},"children":[{"type":"text","value":"6.","position":{"start":{"line":161,"column":1},"end":{"line":161,"column":1}},"key":"FUiEs0cw4T"}],"key":"jyPJO9Yf9D"},{"type":"text","value":" And you can inspect some images using Matplotlib:","position":{"start":{"line":161,"column":1},"end":{"line":161,"column":1}},"key":"QvsPoPxp7w"}],"key":"QetgoDfHyU"}],"key":"zDRb3rnL75"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib.pyplot as plt\n\n# Take the 60,000th image (indexed at 59,999) from the training set,\n# reshape from (784, ) to (28, 28) to have a valid shape for displaying purposes.\nmnist_image = x_train[59999, :].reshape(28, 28)\n# Set the color mapping to grayscale to have a black background.\nplt.imshow(mnist_image, cmap=\"gray\")\n# Display the image.\nplt.show()","key":"N3MOIjWeqF"},{"type":"outputs","id":"46sSghmFcMu0TPlUzy0sn","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"\u003cFigure size 640x480 with 1 Axes\u003e","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"e018622a0b32aae6fc08527a27232984","path":"/numpy-tutorials/build/e018622a0b32aae6fc08527a27232984.png"}}},"key":"TeU2TENKpv"}],"key":"zfjBg5kXnl"}],"key":"ZOLIJb6hBN"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Display 5 random images from the training set.\nnum_examples = 5\nseed = 147197952744\nrng = np.random.default_rng(seed)\n\nfig, axes = plt.subplots(1, num_examples)\nfor sample, ax in zip(rng.choice(x_train, size=num_examples, replace=False), axes):\n    ax.imshow(sample.reshape(28, 28), cmap=\"gray\")","key":"f3uWGjn9jV"},{"type":"outputs","id":"6DJofSZSadklAUDKskeLr","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"\u003cFigure size 640x480 with 5 Axes\u003e","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"b38af87a5e32f7a78feb44788a3ac955","path":"/numpy-tutorials/build/b38af87a5e32f7a78feb44788a3ac955.png"}}},"key":"wSqsV1N0ZR"}],"key":"mnq0lpiS4p"}],"key":"N8U2U5uZRL"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":186,"column":1},"end":{"line":187,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":186,"column":1},"end":{"line":186,"column":1}},"children":[{"type":"text","value":"Above are five images taken from the MNIST training set. Various hand-drawn\nArabic numerals are shown, with exact values chosen randomly with each run of the code.","position":{"start":{"line":186,"column":1},"end":{"line":186,"column":1}},"key":"H26i1g7PSm"}],"key":"IpMOKUIFSW"}],"key":"QVBVAorldV"},{"type":"blockquote","position":{"start":{"line":189,"column":1},"end":{"line":198,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":189,"column":1},"end":{"line":189,"column":1}},"children":[{"type":"strong","position":{"start":{"line":189,"column":1},"end":{"line":189,"column":1}},"children":[{"type":"text","value":"Note:","position":{"start":{"line":189,"column":1},"end":{"line":189,"column":1}},"key":"GgTxdNRsJW"}],"key":"NKASByF354"},{"type":"text","value":" You can also visualize a sample image as an array by printing ","position":{"start":{"line":189,"column":1},"end":{"line":189,"column":1}},"key":"fnZdWktWEN"},{"type":"inlineCode","value":"x_train[59999]","position":{"start":{"line":189,"column":1},"end":{"line":189,"column":1}},"key":"TthJzqpHZE"},{"type":"text","value":". Here, ","position":{"start":{"line":189,"column":1},"end":{"line":189,"column":1}},"key":"msh4DvpdgN"},{"type":"inlineCode","value":"59999","position":{"start":{"line":189,"column":1},"end":{"line":189,"column":1}},"key":"pu9I2Vhhl3"},{"type":"text","value":" is your 60,000th training image sample (","position":{"start":{"line":189,"column":1},"end":{"line":189,"column":1}},"key":"FmheiW88C1"},{"type":"inlineCode","value":"0","position":{"start":{"line":189,"column":1},"end":{"line":189,"column":1}},"key":"xWes7Zs2ar"},{"type":"text","value":" would be your first). Your output will be quite long and should contain an array of 8-bit integers:","position":{"start":{"line":189,"column":1},"end":{"line":189,"column":1}},"key":"C9dVZCM15S"}],"key":"mx63hbZ22d"},{"type":"code","lang":"","value":"...\n         0,   0,  38,  48,  48,  22,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,  62,  97, 198, 243, 254, 254, 212,  27,   0,   0,   0,   0,\n...","position":{"start":{"line":192,"column":1},"end":{"line":198,"column":1}},"key":"PRzOlr4VMH"}],"key":"OkDBmIcxJ1"}],"key":"LGQwmuO9P0"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Display the label of the 60,000th image (indexed at 59,999) from the training set.\ny_train[59999]","key":"gCptyJD7Qe"},{"type":"outputs","id":"JMrM1eMNxGWQPi3pCL9Vi","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"execute_result","execution_count":9,"metadata":{},"data":{"text/plain":{"content":"np.uint8(8)","content_type":"text/plain"}}},"key":"r7h5DtvRUh"}],"key":"M8vP2HoXTX"}],"key":"v7m4uRq4R5"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":205,"column":1},"end":{"line":205,"column":1}},"children":[{"type":"text","value":"2. Preprocess the data","position":{"start":{"line":205,"column":1},"end":{"line":205,"column":1}},"key":"Ve2LOtcviJ"}],"identifier":"id-2-preprocess-the-data","label":"2. Preprocess the data","html_id":"id-2-preprocess-the-data","implicit":true,"key":"L2428w4dPa"},{"type":"paragraph","position":{"start":{"line":207,"column":1},"end":{"line":207,"column":1}},"children":[{"type":"text","value":"Neural networks can work with inputs that are in a form of tensors (multidimensional arrays) of floating-point type. When preprocessing the data, you should consider the following processes: ","position":{"start":{"line":207,"column":1},"end":{"line":207,"column":1}},"key":"OmSn4g9oUP"},{"type":"link","url":"https://en.wikipedia.org/wiki/Vectorization_%28mathematics%29","position":{"start":{"line":207,"column":1},"end":{"line":207,"column":1}},"children":[{"type":"text","value":"vectorization","position":{"start":{"line":207,"column":1},"end":{"line":207,"column":1}},"key":"Puln2ImBDE"}],"urlSource":"https://en.wikipedia.org/wiki/Vectorization_%28mathematics%29","data":{"page":"Vectorization_%28mathematics%29","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"wj1x0bOTnF"},{"type":"text","value":" and ","position":{"start":{"line":207,"column":1},"end":{"line":207,"column":1}},"key":"UTOvoTnUZB"},{"type":"link","url":"https://en.wikipedia.org/wiki/Floating-point_arithmetic#Floating-point_numbers","position":{"start":{"line":207,"column":1},"end":{"line":207,"column":1}},"children":[{"type":"text","value":"conversion to a floating-point format","position":{"start":{"line":207,"column":1},"end":{"line":207,"column":1}},"key":"r08LvmhbPV"}],"urlSource":"https://en.wikipedia.org/wiki/Floating-point_arithmetic#Floating-point_numbers","data":{"page":"Floating-point_arithmetic#Floating-point_numbers","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"qxfEkSG2EM"},{"type":"text","value":".","position":{"start":{"line":207,"column":1},"end":{"line":207,"column":1}},"key":"PgPji8e10Z"}],"key":"vqyzQRRUuS"},{"type":"paragraph","position":{"start":{"line":209,"column":1},"end":{"line":209,"column":1}},"children":[{"type":"text","value":"Since the MNIST data is already vectorized and the arrays are of ","position":{"start":{"line":209,"column":1},"end":{"line":209,"column":1}},"key":"s7JJZe6idj"},{"type":"inlineCode","value":"dtype","position":{"start":{"line":209,"column":1},"end":{"line":209,"column":1}},"key":"xVRLtCd3wW"},{"type":"text","value":" ","position":{"start":{"line":209,"column":1},"end":{"line":209,"column":1}},"key":"sBZZJ4ttnh"},{"type":"inlineCode","value":"uint8","position":{"start":{"line":209,"column":1},"end":{"line":209,"column":1}},"key":"YtXUmrmEIO"},{"type":"text","value":", your next challenge is to convert them to a floating-point format, such as ","position":{"start":{"line":209,"column":1},"end":{"line":209,"column":1}},"key":"dTMucWSoar"},{"type":"inlineCode","value":"float64","position":{"start":{"line":209,"column":1},"end":{"line":209,"column":1}},"key":"N6ViOsHi6N"},{"type":"text","value":" (","position":{"start":{"line":209,"column":1},"end":{"line":209,"column":1}},"key":"bB2gGXD73Y"},{"type":"link","url":"https://en.wikipedia.org/wiki/Double-precision_floating-point_format","position":{"start":{"line":209,"column":1},"end":{"line":209,"column":1}},"children":[{"type":"text","value":"double-precision","position":{"start":{"line":209,"column":1},"end":{"line":209,"column":1}},"key":"HSSXPrbUxh"}],"urlSource":"https://en.wikipedia.org/wiki/Double-precision_floating-point_format","data":{"page":"Double-precision_floating-point_format","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"EewcuAbjZ0"},{"type":"text","value":"):","position":{"start":{"line":209,"column":1},"end":{"line":209,"column":1}},"key":"DxswZ8jit2"}],"key":"PMr7OJ0E9b"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":211,"column":1},"end":{"line":213,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"children":[{"type":"paragraph","children":[{"type":"emphasis","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"children":[{"type":"text","value":"Normalizing","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"LMfmRpjFqV"}],"key":"wY1h4XGMkE"},{"type":"text","value":" the image data: a ","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"pY7PXeFbJa"},{"type":"link","url":"https://en.wikipedia.org/wiki/Feature_scaling#Application","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"children":[{"type":"text","value":"feature scaling","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"I2ge8uGnOw"}],"urlSource":"https://en.wikipedia.org/wiki/Feature_scaling#Application","data":{"page":"Feature_scaling#Application","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"vhnuohqaDt"},{"type":"text","value":" procedure that can speed up the neural network training process by standardizing the ","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"DjmUl89fua"},{"type":"link","url":"https://arxiv.org/pdf/1502.03167.pdf","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"children":[{"type":"text","value":"distribution of your input data","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"FEIi6BsFhu"}],"urlSource":"https://arxiv.org/pdf/1502.03167.pdf","key":"Ocu1XTdYd5"},{"type":"text","value":".","position":{"start":{"line":211,"column":1},"end":{"line":211,"column":1}},"key":"jZGzzoCneC"}],"key":"B8kbs9RTKf"}],"key":"Qp4F2P5Wei"},{"type":"listItem","spread":true,"position":{"start":{"line":212,"column":1},"end":{"line":213,"column":1}},"children":[{"type":"paragraph","children":[{"type":"emphasis","position":{"start":{"line":212,"column":1},"end":{"line":212,"column":1}},"children":[{"type":"link","url":"https://en.wikipedia.org/wiki/One-hot","position":{"start":{"line":212,"column":1},"end":{"line":212,"column":1}},"children":[{"type":"text","value":"One-hot/categorical encoding","position":{"start":{"line":212,"column":1},"end":{"line":212,"column":1}},"key":"qzTrvdAzyF"}],"urlSource":"https://en.wikipedia.org/wiki/One-hot","data":{"page":"One-hot","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"QHzbEAtzy7"}],"key":"Di4k69MpNG"},{"type":"text","value":" of the image labels.","position":{"start":{"line":212,"column":1},"end":{"line":212,"column":1}},"key":"RLF10TvBHL"}],"key":"RXxyrnDyxL"}],"key":"yRvUbIJlt0"}],"key":"WWJYTbyiZF"},{"type":"paragraph","position":{"start":{"line":214,"column":1},"end":{"line":214,"column":1}},"children":[{"type":"text","value":"In practice, you can use different types of floating-point precision depending on your goals and you can find more information about that in the ","position":{"start":{"line":214,"column":1},"end":{"line":214,"column":1}},"key":"FzkYH36nLF"},{"type":"link","url":"https://blogs.nvidia.com/blog/2019/11/15/whats-the-difference-between-single-double-multi-and-mixed-precision-computing/","position":{"start":{"line":214,"column":1},"end":{"line":214,"column":1}},"children":[{"type":"text","value":"Nvidia","position":{"start":{"line":214,"column":1},"end":{"line":214,"column":1}},"key":"vOxwBN1KlG"}],"urlSource":"https://blogs.nvidia.com/blog/2019/11/15/whats-the-difference-between-single-double-multi-and-mixed-precision-computing/","key":"WPLClzMZcZ"},{"type":"text","value":" and ","position":{"start":{"line":214,"column":1},"end":{"line":214,"column":1}},"key":"PcKlFYbmMA"},{"type":"link","url":"https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus","position":{"start":{"line":214,"column":1},"end":{"line":214,"column":1}},"children":[{"type":"text","value":"Google Cloud","position":{"start":{"line":214,"column":1},"end":{"line":214,"column":1}},"key":"srS07xfrIF"}],"urlSource":"https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus","key":"kdJT1kv9TP"},{"type":"text","value":" blog posts.","position":{"start":{"line":214,"column":1},"end":{"line":214,"column":1}},"key":"Pj9cdWzmRa"}],"key":"V0fUMcYqMB"},{"type":"heading","depth":3,"position":{"start":{"line":216,"column":1},"end":{"line":216,"column":1}},"children":[{"type":"text","value":"Convert the image data to the floating-point format","position":{"start":{"line":216,"column":1},"end":{"line":216,"column":1}},"key":"DigAW828TQ"}],"identifier":"convert-the-image-data-to-the-floating-point-format","label":"Convert the image data to the floating-point format","html_id":"convert-the-image-data-to-the-floating-point-format","implicit":true,"key":"yPxAR8bfv0"},{"type":"paragraph","position":{"start":{"line":218,"column":1},"end":{"line":218,"column":1}},"children":[{"type":"text","value":"The images data contain 8-bit integers encoded in the [0, 255] interval with color values between 0 and 255.","position":{"start":{"line":218,"column":1},"end":{"line":218,"column":1}},"key":"j4x5GwFH4G"}],"key":"bTOups8Tpn"},{"type":"paragraph","position":{"start":{"line":220,"column":1},"end":{"line":220,"column":1}},"children":[{"type":"text","value":"You will normalize them into floating-point arrays in the [0, 1] interval by dividing them by 255.","position":{"start":{"line":220,"column":1},"end":{"line":220,"column":1}},"key":"laFGqhaXDz"}],"key":"FUe7jhKSKx"},{"type":"paragraph","position":{"start":{"line":222,"column":1},"end":{"line":222,"column":1}},"children":[{"type":"strong","position":{"start":{"line":222,"column":1},"end":{"line":222,"column":1}},"children":[{"type":"text","value":"1.","position":{"start":{"line":222,"column":1},"end":{"line":222,"column":1}},"key":"mDv9kFy4TS"}],"key":"IhdOlq3H3v"},{"type":"text","value":" Check that the vectorized image data has type ","position":{"start":{"line":222,"column":1},"end":{"line":222,"column":1}},"key":"yfKiga3UlX"},{"type":"inlineCode","value":"uint8","position":{"start":{"line":222,"column":1},"end":{"line":222,"column":1}},"key":"ZNnXR2zWwW"},{"type":"text","value":":","position":{"start":{"line":222,"column":1},"end":{"line":222,"column":1}},"key":"zaJ30mG7OG"}],"key":"kq2ySbMKSn"}],"key":"CnqHn58wVx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(\"The data type of training images: {}\".format(x_train.dtype))\nprint(\"The data type of test images: {}\".format(x_test.dtype))","key":"Zp8JAXT5NG"},{"type":"outputs","id":"1qvOwriuypIOpC7SgylZs","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"The data type of training images: uint8\nThe data type of test images: uint8\n"},"key":"ToGgdCtCfv"}],"key":"Ymg703ySq5"}],"key":"Eb1K6Hl4Pq"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":229,"column":1},"end":{"line":235,"column":1}},"children":[{"type":"strong","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"children":[{"type":"text","value":"2.","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"Yddka7Ov12"}],"key":"JyxyYSjVly"},{"type":"text","value":" Normalize the arrays by dividing them by 255 (and thus promoting the data type from ","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"jTqLEtElTC"},{"type":"inlineCode","value":"uint8","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"Wv4WcTGQat"},{"type":"text","value":" to ","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"MMNb2MUb1u"},{"type":"inlineCode","value":"float64","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"EQ0ezeuIO1"},{"type":"text","value":") and then assign the train and test image data variables — ","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"G77tMFJHhK"},{"type":"inlineCode","value":"x_train","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"nMqr1ABsNU"},{"type":"text","value":" and ","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"TDDRs9IP0W"},{"type":"inlineCode","value":"x_test","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"VjA1CTDBBi"},{"type":"text","value":" — to ","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"nDqqTCYtJ5"},{"type":"inlineCode","value":"training_images","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"AxRimzFfcF"},{"type":"text","value":" and ","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"JQxarmMJTY"},{"type":"inlineCode","value":"train_labels","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"kFhifiglie"},{"type":"text","value":", respectively.\nTo reduce the model training and evaluation time in this example, only a subset\nof the training and test images will be used.\nBoth ","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"xdYiBCbr2D"},{"type":"inlineCode","value":"training_images","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"GpvEyRhglm"},{"type":"text","value":" and ","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"J1Io5GEiEd"},{"type":"inlineCode","value":"test_images","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"FC3DFk0iJw"},{"type":"text","value":" will contain only 1,000 samples each out\nof the complete datasets of 60,000 and 10,000 images, respectively.\nThese values can be controlled by changing the  ","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"dPlI37j4sn"},{"type":"inlineCode","value":"training_sample","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"p4tCgUKSsH"},{"type":"text","value":" and\n","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"UwxQF5isD2"},{"type":"inlineCode","value":"test_sample","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"u9111cJJtE"},{"type":"text","value":" below, up to their maximum values of 60,000 and 10,000.","position":{"start":{"line":229,"column":1},"end":{"line":229,"column":1}},"key":"yGjjLuIVPG"}],"key":"jgy35zIHOP"}],"key":"WgoujKqNxT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"training_sample, test_sample = 1000, 1000\ntraining_images = x_train[0:training_sample] / 255\ntest_images = x_test[0:test_sample] / 255","key":"nyr3lskbJp"},{"type":"outputs","id":"iJ3MjN5i3kiwsRd8auJFd","children":[],"key":"vv7gNPHFi6"}],"key":"Y6F8O4Ncw3"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":243,"column":1},"end":{"line":243,"column":1}},"children":[{"type":"strong","position":{"start":{"line":243,"column":1},"end":{"line":243,"column":1}},"children":[{"type":"text","value":"3.","position":{"start":{"line":243,"column":1},"end":{"line":243,"column":1}},"key":"uiTQqM6ttu"}],"key":"IvjWHFrKOH"},{"type":"text","value":" Confirm that the image data has changed to the floating-point format:","position":{"start":{"line":243,"column":1},"end":{"line":243,"column":1}},"key":"RRJkluzXRL"}],"key":"YZVDWpZdOp"}],"key":"Sq30VPovZM"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(\"The data type of training images: {}\".format(training_images.dtype))\nprint(\"The data type of test images: {}\".format(test_images.dtype))","key":"ESqW4pjuvw"},{"type":"outputs","id":"UD0D4mWo92bD6dqADZZDU","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"The data type of training images: float64\nThe data type of test images: float64\n"},"key":"MITk8yUN7N"}],"key":"dMWFzWi4YM"}],"key":"TKh7ZGWDR8"},{"type":"block","children":[{"type":"blockquote","position":{"start":{"line":250,"column":1},"end":{"line":258,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":250,"column":1},"end":{"line":250,"column":1}},"children":[{"type":"strong","position":{"start":{"line":250,"column":1},"end":{"line":250,"column":1}},"children":[{"type":"text","value":"Note:","position":{"start":{"line":250,"column":1},"end":{"line":250,"column":1}},"key":"iwt9I4fduM"}],"key":"fGLffaXs7q"},{"type":"text","value":" You can also check that normalization was successful by printing ","position":{"start":{"line":250,"column":1},"end":{"line":250,"column":1}},"key":"pWikxocYat"},{"type":"inlineCode","value":"training_images[0]","position":{"start":{"line":250,"column":1},"end":{"line":250,"column":1}},"key":"W198cRXOVa"},{"type":"text","value":" in a notebook cell. Your long output should contain an array of floating-point numbers:","position":{"start":{"line":250,"column":1},"end":{"line":250,"column":1}},"key":"i9mu8eBIh8"}],"key":"BaXQudmzfR"},{"type":"code","lang":"","value":"...\n       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n...","position":{"start":{"line":252,"column":1},"end":{"line":258,"column":1}},"key":"ixVo7F7wIT"}],"key":"kuLKfV5bu3"},{"type":"heading","depth":3,"position":{"start":{"line":260,"column":1},"end":{"line":260,"column":1}},"children":[{"type":"text","value":"Convert the labels to floating point through categorical/one-hot encoding","position":{"start":{"line":260,"column":1},"end":{"line":260,"column":1}},"key":"px4Oain45B"}],"identifier":"convert-the-labels-to-floating-point-through-categorical-one-hot-encoding","label":"Convert the labels to floating point through categorical/one-hot encoding","html_id":"convert-the-labels-to-floating-point-through-categorical-one-hot-encoding","implicit":true,"key":"xt7St9HndA"},{"type":"paragraph","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"children":[{"type":"text","value":"You will use one-hot encoding to embed each digit label as an all-zero vector with ","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"SJywLMAguA"},{"type":"inlineCode","value":"np.zeros()","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"J67zL65msk"},{"type":"text","value":" and place ","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"F25862OHTn"},{"type":"inlineCode","value":"1","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"cVKEgUjkdN"},{"type":"text","value":" for a label index. As a result, your label data will be arrays with ","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"zPnQmVR9ll"},{"type":"inlineCode","value":"1.0","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"kIap4iA1rO"},{"type":"text","value":" (or ","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"uji0O5WyNS"},{"type":"inlineCode","value":"1.","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"J6R88RAd36"},{"type":"text","value":") in the position of each image label.","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"xNp0RB0KWa"}],"key":"dOYdEri62Y"},{"type":"paragraph","position":{"start":{"line":264,"column":1},"end":{"line":264,"column":1}},"children":[{"type":"text","value":"Since there are 10 labels (from 0 to 9) in total, your arrays will look similar to this:","position":{"start":{"line":264,"column":1},"end":{"line":264,"column":1}},"key":"W3RgMLzv1r"}],"key":"rWTWvTLpLY"},{"type":"code","lang":"","value":"array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])","position":{"start":{"line":266,"column":1},"end":{"line":268,"column":1}},"key":"LujIzFEKmF"},{"type":"paragraph","position":{"start":{"line":270,"column":1},"end":{"line":270,"column":1}},"children":[{"type":"strong","position":{"start":{"line":270,"column":1},"end":{"line":270,"column":1}},"children":[{"type":"text","value":"1.","position":{"start":{"line":270,"column":1},"end":{"line":270,"column":1}},"key":"VvfhTpONG5"}],"key":"ac5r959Gxk"},{"type":"text","value":" Confirm that the image label data are integers with ","position":{"start":{"line":270,"column":1},"end":{"line":270,"column":1}},"key":"enAWrDWfqc"},{"type":"inlineCode","value":"dtype","position":{"start":{"line":270,"column":1},"end":{"line":270,"column":1}},"key":"F1BUx5pb7x"},{"type":"text","value":" ","position":{"start":{"line":270,"column":1},"end":{"line":270,"column":1}},"key":"f4N1TnffFt"},{"type":"inlineCode","value":"uint8","position":{"start":{"line":270,"column":1},"end":{"line":270,"column":1}},"key":"dIDa2qpM9o"},{"type":"text","value":":","position":{"start":{"line":270,"column":1},"end":{"line":270,"column":1}},"key":"KyZsQ5wD73"}],"key":"hi6xIHKMrj"}],"key":"eqL8DuxWil"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(\"The data type of training labels: {}\".format(y_train.dtype))\nprint(\"The data type of test labels: {}\".format(y_test.dtype))","key":"XmO3pvvC90"},{"type":"outputs","id":"7iAywViV7gvuHcD3Ulbox","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"The data type of training labels: uint8\nThe data type of test labels: uint8\n"},"key":"oSA297OKvj"}],"key":"NMlCSA2QVh"}],"key":"cDt24acBLd"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":277,"column":1},"end":{"line":277,"column":1}},"children":[{"type":"strong","position":{"start":{"line":277,"column":1},"end":{"line":277,"column":1}},"children":[{"type":"text","value":"2.","position":{"start":{"line":277,"column":1},"end":{"line":277,"column":1}},"key":"IeN7q8IUvo"}],"key":"DGCOBLMCcx"},{"type":"text","value":" Define a function that performs one-hot encoding on arrays:","position":{"start":{"line":277,"column":1},"end":{"line":277,"column":1}},"key":"WPDQncAw6X"}],"key":"fTsGxRO3b0"}],"key":"LqaDEgVfa2"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def one_hot_encoding(labels, dimension=10):\n    # Define a one-hot variable for an all-zero vector\n    # with 10 dimensions (number labels from 0 to 9).\n    one_hot_labels = labels[..., None] == np.arange(dimension)[None]\n    # Return one-hot encoded labels.\n    return one_hot_labels.astype(np.float64)","key":"lc3XM6olno"},{"type":"outputs","id":"tJo3xmPGbmqPFtgY-Wlpo","children":[],"key":"m37AA9zC23"}],"key":"KfBkCgSbcd"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":288,"column":1},"end":{"line":288,"column":1}},"children":[{"type":"strong","position":{"start":{"line":288,"column":1},"end":{"line":288,"column":1}},"children":[{"type":"text","value":"3.","position":{"start":{"line":288,"column":1},"end":{"line":288,"column":1}},"key":"arJpqjLQHt"}],"key":"rfCcGPcaAB"},{"type":"text","value":" Encode the labels and assign the values to new variables:","position":{"start":{"line":288,"column":1},"end":{"line":288,"column":1}},"key":"RIXvF5FgPA"}],"key":"hhi4gVzCrh"}],"key":"KcY4wTFQRu"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"training_labels = one_hot_encoding(y_train[:training_sample])\ntest_labels = one_hot_encoding(y_test[:test_sample])","key":"mv9A4bS4Cw"},{"type":"outputs","id":"2XYWLDW2f92kYQWJTQW8P","children":[],"key":"g1KuFqY0o5"}],"key":"eo0GbxLu83"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":295,"column":1},"end":{"line":295,"column":1}},"children":[{"type":"strong","position":{"start":{"line":295,"column":1},"end":{"line":295,"column":1}},"children":[{"type":"text","value":"4.","position":{"start":{"line":295,"column":1},"end":{"line":295,"column":1}},"key":"TY5TVvQhFe"}],"key":"zLe0w1SbjR"},{"type":"text","value":" Check that the data type has changed to floating point:","position":{"start":{"line":295,"column":1},"end":{"line":295,"column":1}},"key":"zTbQCGJDtX"}],"key":"Vr1vNkUPWb"}],"key":"FVAhMqVoij"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(\"The data type of training labels: {}\".format(training_labels.dtype))\nprint(\"The data type of test labels: {}\".format(test_labels.dtype))","key":"EjsjWxkyQO"},{"type":"outputs","id":"2x2yk5D4WSOCEj0lSmk8I","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"The data type of training labels: float64\nThe data type of test labels: float64\n"},"key":"bhApCNuA2W"}],"key":"VkXC1jgj5S"}],"key":"Wxsa9Uz9AW"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":302,"column":1},"end":{"line":302,"column":1}},"children":[{"type":"strong","position":{"start":{"line":302,"column":1},"end":{"line":302,"column":1}},"children":[{"type":"text","value":"5.","position":{"start":{"line":302,"column":1},"end":{"line":302,"column":1}},"key":"aZy4Tnd6QB"}],"key":"Sh4P8YGgMV"},{"type":"text","value":" Examine a few encoded labels:","position":{"start":{"line":302,"column":1},"end":{"line":302,"column":1}},"key":"N6nsMGaLrc"}],"key":"yAj0NscgGC"}],"key":"yanljWhcZh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(training_labels[0])\nprint(training_labels[1])\nprint(training_labels[2])","key":"S5ph5dOBuY"},{"type":"outputs","id":"WI2kaM93S2h1hxELrKKAZ","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"},"key":"xxoMGjEDOZ"}],"key":"pGrfYGWcjq"}],"key":"lzynfcJaKD"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":310,"column":1},"end":{"line":310,"column":1}},"children":[{"type":"text","value":"...and compare to the originals:","position":{"start":{"line":310,"column":1},"end":{"line":310,"column":1}},"key":"UVtcfx5MY4"}],"key":"eFLl8QsyN1"}],"key":"flOBaTrbnh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(y_train[0])\nprint(y_train[1])\nprint(y_train[2])","key":"ieoLXMmgwL"},{"type":"outputs","id":"TN0MIRWllC2-oLAAI0y-h","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"5\n0\n4\n"},"key":"HztQNjABXa"}],"key":"bK1uQZRiba"}],"key":"dxkx3A6AtE"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":318,"column":1},"end":{"line":318,"column":1}},"children":[{"type":"text","value":"You have finished preparing the dataset.","position":{"start":{"line":318,"column":1},"end":{"line":318,"column":1}},"key":"OjeBcqzW7u"}],"key":"FwU3YZ9eWF"},{"type":"heading","depth":2,"position":{"start":{"line":320,"column":1},"end":{"line":320,"column":1}},"children":[{"type":"text","value":"3. Build and train a small neural network from scratch","position":{"start":{"line":320,"column":1},"end":{"line":320,"column":1}},"key":"PrFG8ok1Dh"}],"identifier":"id-3-build-and-train-a-small-neural-network-from-scratch","label":"3. Build and train a small neural network from scratch","html_id":"id-3-build-and-train-a-small-neural-network-from-scratch","implicit":true,"key":"GY0LDazkwm"},{"type":"paragraph","position":{"start":{"line":322,"column":1},"end":{"line":322,"column":1}},"children":[{"type":"text","value":"In this section you will familiarize yourself with some high-level concepts of the basic building blocks of a deep learning model. You can refer to the original ","position":{"start":{"line":322,"column":1},"end":{"line":322,"column":1}},"key":"M2yWzOeVHa"},{"type":"link","url":"http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf","position":{"start":{"line":322,"column":1},"end":{"line":322,"column":1}},"children":[{"type":"text","value":"Deep learning","position":{"start":{"line":322,"column":1},"end":{"line":322,"column":1}},"key":"YmnJjHgpYH"}],"urlSource":"http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf","key":"wd4UkfLwKN"},{"type":"text","value":" research publication for more information.","position":{"start":{"line":322,"column":1},"end":{"line":322,"column":1}},"key":"qUByB33I6v"}],"key":"c18kOzDcNX"},{"type":"paragraph","position":{"start":{"line":324,"column":1},"end":{"line":324,"column":1}},"children":[{"type":"text","value":"Afterwards, you will construct the building blocks of a simple deep learning model in Python and NumPy and train it to learn to identify handwritten digits from the MNIST dataset with a certain level of accuracy.","position":{"start":{"line":324,"column":1},"end":{"line":324,"column":1}},"key":"d7zIx7d3MD"}],"key":"Z9g6HEvHaO"},{"type":"heading","depth":3,"position":{"start":{"line":326,"column":1},"end":{"line":326,"column":1}},"children":[{"type":"text","value":"Neural network building blocks with NumPy","position":{"start":{"line":326,"column":1},"end":{"line":326,"column":1}},"key":"ql9nhoptFa"}],"identifier":"neural-network-building-blocks-with-numpy","label":"Neural network building blocks with NumPy","html_id":"neural-network-building-blocks-with-numpy","implicit":true,"key":"bhCMo6GCtK"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":328,"column":1},"end":{"line":353,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":328,"column":1},"end":{"line":335,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":328,"column":1},"end":{"line":328,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":328,"column":1},"end":{"line":328,"column":1}},"children":[{"type":"text","value":"Layers","position":{"start":{"line":328,"column":1},"end":{"line":328,"column":1}},"key":"JbX3AfPdaL"}],"key":"PUuUDorX7o"},{"type":"text","value":": These building blocks work as data filters — they process data and learn representations from inputs to better predict the target outputs.","position":{"start":{"line":328,"column":1},"end":{"line":328,"column":1}},"key":"ASJBMKg5jp"}],"key":"PR4tpYsEH9"},{"type":"paragraph","position":{"start":{"line":330,"column":1},"end":{"line":330,"column":1}},"children":[{"type":"text","value":"You will use 1 hidden layer in your model to pass the inputs forward (","position":{"start":{"line":330,"column":1},"end":{"line":330,"column":1}},"key":"u6NzOCjAv0"},{"type":"emphasis","position":{"start":{"line":330,"column":1},"end":{"line":330,"column":1}},"children":[{"type":"text","value":"forward propagation","position":{"start":{"line":330,"column":1},"end":{"line":330,"column":1}},"key":"zgzUYib02h"}],"key":"yXSAousGoQ"},{"type":"text","value":") and propagate the gradients/error derivatives of a loss function backward (","position":{"start":{"line":330,"column":1},"end":{"line":330,"column":1}},"key":"OpgMxI6c8C"},{"type":"emphasis","position":{"start":{"line":330,"column":1},"end":{"line":330,"column":1}},"children":[{"type":"text","value":"backpropagation","position":{"start":{"line":330,"column":1},"end":{"line":330,"column":1}},"key":"AWXNt7P1KD"}],"key":"v6pzEqutQo"},{"type":"text","value":"). These are input, hidden and output layers.","position":{"start":{"line":330,"column":1},"end":{"line":330,"column":1}},"key":"dazgM6kvUQ"}],"key":"wqdDINXPlL"},{"type":"paragraph","position":{"start":{"line":332,"column":1},"end":{"line":332,"column":1}},"children":[{"type":"text","value":"In the hidden (middle) and output (last) layers, the neural network model will compute the weighted sum of inputs. To compute this process, you will use NumPy’s matrix multiplication function (the “dot multiply” or ","position":{"start":{"line":332,"column":1},"end":{"line":332,"column":1}},"key":"jBhrvimE5c"},{"type":"inlineCode","value":"np.dot(layer, weights)","position":{"start":{"line":332,"column":1},"end":{"line":332,"column":1}},"key":"JSGaJnCi1G"},{"type":"text","value":").","position":{"start":{"line":332,"column":1},"end":{"line":332,"column":1}},"key":"naEaFhECbk"}],"key":"HQURoVuuZZ"},{"type":"blockquote","position":{"start":{"line":334,"column":1},"end":{"line":334,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":334,"column":1},"end":{"line":334,"column":1}},"children":[{"type":"strong","position":{"start":{"line":334,"column":1},"end":{"line":334,"column":1}},"children":[{"type":"text","value":"Note:","position":{"start":{"line":334,"column":1},"end":{"line":334,"column":1}},"key":"veJXVPhIZh"}],"key":"thFo1xDTiz"},{"type":"text","value":" For simplicity, the bias term is omitted in this example (there is no ","position":{"start":{"line":334,"column":1},"end":{"line":334,"column":1}},"key":"jAJVoey0Oz"},{"type":"inlineCode","value":"np.dot(layer, weights) + bias","position":{"start":{"line":334,"column":1},"end":{"line":334,"column":1}},"key":"BmY6czExHk"},{"type":"text","value":").","position":{"start":{"line":334,"column":1},"end":{"line":334,"column":1}},"key":"ykAOk86a3h"}],"key":"hdCvxF5sMo"}],"key":"xFMfWBZhBc"}],"key":"qJLOh8EkAZ"},{"type":"listItem","spread":true,"position":{"start":{"line":336,"column":1},"end":{"line":339,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"children":[{"type":"text","value":"Weights","position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"key":"buWLZigBTu"}],"key":"zveEOzYsWX"},{"type":"text","value":": These are important adjustable parameters that the neural network fine-tunes by forward and backward propagating the data. They are optimized through a process called ","position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"key":"iLvtM09QUN"},{"type":"link","url":"https://en.wikipedia.org/wiki/Stochastic_gradient_descent","position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"children":[{"type":"text","value":"gradient descent","position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"key":"KuAXX4I9Hl"}],"urlSource":"https://en.wikipedia.org/wiki/Stochastic_gradient_descent","data":{"page":"Stochastic_gradient_descent","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"sLso0shNCp"},{"type":"text","value":". Before the model training starts, the weights are randomly initialized with NumPy’s ","position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"key":"ibd993TiZe"},{"type":"link","url":"https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.random.html","position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"children":[{"type":"inlineCode","value":"Generator.random()","position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"key":"q5bJW5fG1P"}],"urlSource":"https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.random.html","key":"siHw8Yu4jM"},{"type":"text","value":".","position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"key":"Ua7Bgpy5xN"}],"key":"HYGRICehfU"},{"type":"paragraph","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"children":[{"type":"text","value":"The optimal weights should produce the highest prediction accuracy and the lowest error on the training and test sets.","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"MRqN8vtc9y"}],"key":"LnhLQ5hJVo"}],"key":"n6vKGbxj8n"},{"type":"listItem","spread":true,"position":{"start":{"line":340,"column":1},"end":{"line":343,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"children":[{"type":"text","value":"Activation function","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"z33ImXlXF2"}],"key":"l3JsL9MTMW"},{"type":"text","value":": Deep learning models are capable of determining non-linear relationships between inputs and outputs and these ","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"XVMlpiZ7iD"},{"type":"link","url":"https://en.wikipedia.org/wiki/Activation_function","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"children":[{"type":"text","value":"non-linear functions","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"wbKxJy5s7G"}],"urlSource":"https://en.wikipedia.org/wiki/Activation_function","data":{"page":"Activation_function","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"BGU940Q0A0"},{"type":"text","value":" are usually applied to the output of each layer.","position":{"start":{"line":340,"column":1},"end":{"line":340,"column":1}},"key":"BV6dWcnFhs"}],"key":"kAMxTWvLcU"},{"type":"paragraph","position":{"start":{"line":342,"column":1},"end":{"line":342,"column":1}},"children":[{"type":"text","value":"You will use a ","position":{"start":{"line":342,"column":1},"end":{"line":342,"column":1}},"key":"rajP6QeyG6"},{"type":"link","url":"https://en.wikipedia.org/wiki/Rectifier_(neural_networks)","position":{"start":{"line":342,"column":1},"end":{"line":342,"column":1}},"children":[{"type":"text","value":"rectified linear unit (ReLU)","position":{"start":{"line":342,"column":1},"end":{"line":342,"column":1}},"key":"si2bLK9HDh"}],"urlSource":"https://en.wikipedia.org/wiki/Rectifier_(neural_networks)","data":{"page":"Rectifier_(neural_networks)","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"ajzomVroy8"},{"type":"text","value":" to the hidden layer’s output (for example, ","position":{"start":{"line":342,"column":1},"end":{"line":342,"column":1}},"key":"lPTS3bmu9N"},{"type":"inlineCode","value":"relu(np.dot(layer, weights))","position":{"start":{"line":342,"column":1},"end":{"line":342,"column":1}},"key":"AAZOAkZbUM"},{"type":"text","value":".","position":{"start":{"line":342,"column":1},"end":{"line":342,"column":1}},"key":"CPzkrly5GO"}],"key":"yThtrNBFsW"}],"key":"OGsXgtS6GZ"},{"type":"listItem","spread":true,"position":{"start":{"line":344,"column":1},"end":{"line":347,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":344,"column":1},"end":{"line":344,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":344,"column":1},"end":{"line":344,"column":1}},"children":[{"type":"text","value":"Regularization","position":{"start":{"line":344,"column":1},"end":{"line":344,"column":1}},"key":"una3zYJ5kK"}],"key":"gowCHxkcgn"},{"type":"text","value":": This ","position":{"start":{"line":344,"column":1},"end":{"line":344,"column":1}},"key":"ex0XyIPxfU"},{"type":"link","url":"https://en.wikipedia.org/wiki/Regularization_(mathematics)","position":{"start":{"line":344,"column":1},"end":{"line":344,"column":1}},"children":[{"type":"text","value":"technique","position":{"start":{"line":344,"column":1},"end":{"line":344,"column":1}},"key":"iep6tvsXyh"}],"urlSource":"https://en.wikipedia.org/wiki/Regularization_(mathematics)","data":{"page":"Regularization_(mathematics)","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"cq3DOJvr1s"},{"type":"text","value":" helps prevent the neural network model from ","position":{"start":{"line":344,"column":1},"end":{"line":344,"column":1}},"key":"jvKrgn91aJ"},{"type":"link","url":"https://en.wikipedia.org/wiki/Overfitting","position":{"start":{"line":344,"column":1},"end":{"line":344,"column":1}},"children":[{"type":"text","value":"overfitting","position":{"start":{"line":344,"column":1},"end":{"line":344,"column":1}},"key":"IRMzmMSwLn"}],"urlSource":"https://en.wikipedia.org/wiki/Overfitting","data":{"page":"Overfitting","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"gZ3IRIne78"},{"type":"text","value":".","position":{"start":{"line":344,"column":1},"end":{"line":344,"column":1}},"key":"az3jNEIJk0"}],"key":"HWEUbTx5Nm"},{"type":"paragraph","position":{"start":{"line":346,"column":1},"end":{"line":346,"column":1}},"children":[{"type":"text","value":"In this example, you will use a method called dropout — ","position":{"start":{"line":346,"column":1},"end":{"line":346,"column":1}},"key":"vF5tZv6LXt"},{"type":"link","url":"https://en.wikipedia.org/wiki/Dilution_(neural_networks)","position":{"start":{"line":346,"column":1},"end":{"line":346,"column":1}},"children":[{"type":"text","value":"dilution","position":{"start":{"line":346,"column":1},"end":{"line":346,"column":1}},"key":"XYbgh5qZRE"}],"urlSource":"https://en.wikipedia.org/wiki/Dilution_(neural_networks)","data":{"page":"Dilution_(neural_networks)","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"GXkPdgDfG2"},{"type":"text","value":" — that randomly sets a number of features in a layer to 0s. You will define it with NumPy’s ","position":{"start":{"line":346,"column":1},"end":{"line":346,"column":1}},"key":"JsYuGccjzQ"},{"type":"link","url":"https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.integers.html","position":{"start":{"line":346,"column":1},"end":{"line":346,"column":1}},"children":[{"type":"inlineCode","value":"Generator.integers()","position":{"start":{"line":346,"column":1},"end":{"line":346,"column":1}},"key":"vo7XiUlLAW"}],"urlSource":"https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.integers.html","key":"eXTQ3QJQ5U"},{"type":"text","value":" method and apply it to the hidden layer of the network.","position":{"start":{"line":346,"column":1},"end":{"line":346,"column":1}},"key":"HUTwip9TYw"}],"key":"ycoDdjX6nJ"}],"key":"P4CwWBFbqQ"},{"type":"listItem","spread":true,"position":{"start":{"line":348,"column":1},"end":{"line":351,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":348,"column":1},"end":{"line":348,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":348,"column":1},"end":{"line":348,"column":1}},"children":[{"type":"text","value":"Loss function","position":{"start":{"line":348,"column":1},"end":{"line":348,"column":1}},"key":"dhrFha1N40"}],"key":"Rz6uRlRpL9"},{"type":"text","value":": The computation determines the quality of predictions by comparing the image labels (the truth) with the predicted values in the final layer’s output.","position":{"start":{"line":348,"column":1},"end":{"line":348,"column":1}},"key":"amAYPy0S1u"}],"key":"e3XnoA8YeN"},{"type":"paragraph","position":{"start":{"line":350,"column":1},"end":{"line":350,"column":1}},"children":[{"type":"text","value":"For simplicity, you will use a basic total squared error using NumPy’s ","position":{"start":{"line":350,"column":1},"end":{"line":350,"column":1}},"key":"kAUrGXIBXd"},{"type":"inlineCode","value":"np.sum()","position":{"start":{"line":350,"column":1},"end":{"line":350,"column":1}},"key":"FzpyWeZQW9"},{"type":"text","value":" function (for example, ","position":{"start":{"line":350,"column":1},"end":{"line":350,"column":1}},"key":"uObuDgGxxQ"},{"type":"inlineCode","value":"np.sum((final_layer_output - image_labels) ** 2)","position":{"start":{"line":350,"column":1},"end":{"line":350,"column":1}},"key":"iy3lBZiTLD"},{"type":"text","value":").","position":{"start":{"line":350,"column":1},"end":{"line":350,"column":1}},"key":"ivtBPh8yMR"}],"key":"qb8cCvLzzB"}],"key":"RhvvrPzsJb"},{"type":"listItem","spread":true,"position":{"start":{"line":352,"column":1},"end":{"line":353,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":352,"column":1},"end":{"line":352,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":352,"column":1},"end":{"line":352,"column":1}},"children":[{"type":"text","value":"Accuracy","position":{"start":{"line":352,"column":1},"end":{"line":352,"column":1}},"key":"manz8jyaxF"}],"key":"asA1EP08eG"},{"type":"text","value":": This metric measures the accuracy of the network’s ability to predict on the data it hasn’t seen.","position":{"start":{"line":352,"column":1},"end":{"line":352,"column":1}},"key":"YQSmcax0Uq"}],"key":"cLxStAyaSC"}],"key":"ds0cqoO8Uh"}],"key":"QJi5IaMXmz"},{"type":"heading","depth":3,"position":{"start":{"line":354,"column":1},"end":{"line":354,"column":1}},"children":[{"type":"text","value":"Model architecture and training summary","position":{"start":{"line":354,"column":1},"end":{"line":354,"column":1}},"key":"cTkSFJEyhX"}],"identifier":"model-architecture-and-training-summary","label":"Model architecture and training summary","html_id":"model-architecture-and-training-summary","implicit":true,"key":"VnAsRhxC6K"},{"type":"paragraph","position":{"start":{"line":356,"column":1},"end":{"line":356,"column":1}},"children":[{"type":"text","value":"Here is a summary of the neural network model architecture and the training process:","position":{"start":{"line":356,"column":1},"end":{"line":356,"column":1}},"key":"Eg17bWuY7Y"}],"key":"tcEr2HYeBo"},{"type":"image","url":"/numpy-tutorials/build/tutorial-deep-learni-18c33a02a86a205d4dc00e618c78f2e1.png","alt":"Diagram showing operations detailed in this tutorial (The input imageis passed into a Hidden layer that creates a weighted sum of outputs.The weighted sum is passed to the Non-linearity, then regularization andinto the output layer. The output layer creates a prediction which canthen be compared to existing data. The errors are used to calculate theloss function and update weights in the hidden layer and outputlayer.)","position":{"start":{"line":359,"column":1},"end":{"line":359,"column":1}},"key":"zceiRyqiXK","urlSource":"_static/tutorial-deep-learning-on-mnist.png"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":367,"column":1},"end":{"line":388,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":367,"column":1},"end":{"line":370,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":367,"column":1},"end":{"line":367,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":367,"column":1},"end":{"line":367,"column":1}},"children":[{"type":"text","value":"The input layer","position":{"start":{"line":367,"column":1},"end":{"line":367,"column":1}},"key":"XJ5uUk6usy"}],"key":"zMHjY5ZGEM"},{"type":"text","value":":","position":{"start":{"line":367,"column":1},"end":{"line":367,"column":1}},"key":"QOpTDiUdO7"}],"key":"coOkIbggY1"},{"type":"paragraph","position":{"start":{"line":369,"column":1},"end":{"line":369,"column":1}},"children":[{"type":"text","value":"It is the input for the network — the previously preprocessed data that is loaded from ","position":{"start":{"line":369,"column":1},"end":{"line":369,"column":1}},"key":"SFBQiDm9bB"},{"type":"inlineCode","value":"training_images","position":{"start":{"line":369,"column":1},"end":{"line":369,"column":1}},"key":"zV153rxiTD"},{"type":"text","value":" into ","position":{"start":{"line":369,"column":1},"end":{"line":369,"column":1}},"key":"qySm2F2Fkv"},{"type":"inlineCode","value":"layer_0","position":{"start":{"line":369,"column":1},"end":{"line":369,"column":1}},"key":"d0RQRaerFC"},{"type":"text","value":".","position":{"start":{"line":369,"column":1},"end":{"line":369,"column":1}},"key":"AMWLmPkQs7"}],"key":"hWzg70VNx4"}],"key":"spBGNRdLv7"},{"type":"listItem","spread":true,"position":{"start":{"line":371,"column":1},"end":{"line":376,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":371,"column":1},"end":{"line":371,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":371,"column":1},"end":{"line":371,"column":1}},"children":[{"type":"text","value":"The hidden (middle) layer","position":{"start":{"line":371,"column":1},"end":{"line":371,"column":1}},"key":"ForUuxoPUG"}],"key":"C8xKSMpjnS"},{"type":"text","value":":","position":{"start":{"line":371,"column":1},"end":{"line":371,"column":1}},"key":"jViCicgqco"}],"key":"BJOtNlbHRL"},{"type":"paragraph","position":{"start":{"line":373,"column":1},"end":{"line":373,"column":1}},"children":[{"type":"inlineCode","value":"layer_1","position":{"start":{"line":373,"column":1},"end":{"line":373,"column":1}},"key":"fs7IDyiHyp"},{"type":"text","value":" takes the output from the previous layer and performs matrix-multiplication of the input by weights (","position":{"start":{"line":373,"column":1},"end":{"line":373,"column":1}},"key":"d9QOKZIlc7"},{"type":"inlineCode","value":"weights_1","position":{"start":{"line":373,"column":1},"end":{"line":373,"column":1}},"key":"xNZKFAEVpv"},{"type":"text","value":") with NumPy’s ","position":{"start":{"line":373,"column":1},"end":{"line":373,"column":1}},"key":"lESkwHqRSE"},{"type":"inlineCode","value":"np.dot()","position":{"start":{"line":373,"column":1},"end":{"line":373,"column":1}},"key":"cYyCAaduir"},{"type":"text","value":").","position":{"start":{"line":373,"column":1},"end":{"line":373,"column":1}},"key":"VEfe6UZ60B"}],"key":"fxym02IEXW"},{"type":"paragraph","position":{"start":{"line":375,"column":1},"end":{"line":375,"column":1}},"children":[{"type":"text","value":"Then, this output is passed through the ReLU activation function for non-linearity and then dropout is applied to help with overfitting.","position":{"start":{"line":375,"column":1},"end":{"line":375,"column":1}},"key":"BiPrzKrk5D"}],"key":"e74PPjXtMx"}],"key":"UVc6ryAAkk"},{"type":"listItem","spread":true,"position":{"start":{"line":377,"column":1},"end":{"line":382,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":377,"column":1},"end":{"line":377,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":377,"column":1},"end":{"line":377,"column":1}},"children":[{"type":"text","value":"The output (last) layer","position":{"start":{"line":377,"column":1},"end":{"line":377,"column":1}},"key":"iJ19Olo5wY"}],"key":"xlOw4uH1PW"},{"type":"text","value":":","position":{"start":{"line":377,"column":1},"end":{"line":377,"column":1}},"key":"eFazwlyVl9"}],"key":"aN5JfdoMnE"},{"type":"paragraph","position":{"start":{"line":379,"column":1},"end":{"line":379,"column":1}},"children":[{"type":"inlineCode","value":"layer_2","position":{"start":{"line":379,"column":1},"end":{"line":379,"column":1}},"key":"wm9V98tkUy"},{"type":"text","value":" ingests the output from ","position":{"start":{"line":379,"column":1},"end":{"line":379,"column":1}},"key":"dJijvDhdh0"},{"type":"inlineCode","value":"layer_1","position":{"start":{"line":379,"column":1},"end":{"line":379,"column":1}},"key":"dRXhFS9LWY"},{"type":"text","value":" and repeats the same “dot multiply” process with ","position":{"start":{"line":379,"column":1},"end":{"line":379,"column":1}},"key":"rfL0FG60Ks"},{"type":"inlineCode","value":"weights_2","position":{"start":{"line":379,"column":1},"end":{"line":379,"column":1}},"key":"SzzFwhkiKE"},{"type":"text","value":".","position":{"start":{"line":379,"column":1},"end":{"line":379,"column":1}},"key":"TNJBe0r4vM"}],"key":"Oq3vQ97jXT"},{"type":"paragraph","position":{"start":{"line":381,"column":1},"end":{"line":381,"column":1}},"children":[{"type":"text","value":"The final output returns 10 scores for each of the 0-9 digit labels. The network model ends with a size 10 layer — a 10-dimensional vector.","position":{"start":{"line":381,"column":1},"end":{"line":381,"column":1}},"key":"eUyIezd7kx"}],"key":"Yvdk9Urf0c"}],"key":"QCtRRChj8C"},{"type":"listItem","spread":true,"position":{"start":{"line":383,"column":1},"end":{"line":388,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":383,"column":1},"end":{"line":383,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":383,"column":1},"end":{"line":383,"column":1}},"children":[{"type":"text","value":"Forward propagation, backpropagation, training loop","position":{"start":{"line":383,"column":1},"end":{"line":383,"column":1}},"key":"Qb6YefLIm1"}],"key":"w9RCcFkJW6"},{"type":"text","value":":","position":{"start":{"line":383,"column":1},"end":{"line":383,"column":1}},"key":"SPtHDsm0IN"}],"key":"uiEkrP0Zit"},{"type":"paragraph","position":{"start":{"line":385,"column":1},"end":{"line":385,"column":1}},"children":[{"type":"text","value":"In the beginning of model training, your network randomly initializes the weights and feeds the input data forward through the hidden and output layers. This process is the forward pass or forward propagation.","position":{"start":{"line":385,"column":1},"end":{"line":385,"column":1}},"key":"IeciEX88EE"}],"key":"mizPPXqgdP"},{"type":"paragraph","position":{"start":{"line":387,"column":1},"end":{"line":387,"column":1}},"children":[{"type":"text","value":"Then, the network propagates the “signal” from the loss function back through the hidden layer and adjusts the weights with the help of the learning rate parameter (more on that later).","position":{"start":{"line":387,"column":1},"end":{"line":387,"column":1}},"key":"DUwZQGhabO"}],"key":"dShX7Hko4l"}],"key":"fSobr1VbZQ"}],"key":"gVg3PivAHV"},{"type":"blockquote","position":{"start":{"line":389,"column":1},"end":{"line":397,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":389,"column":1},"end":{"line":389,"column":1}},"children":[{"type":"strong","position":{"start":{"line":389,"column":1},"end":{"line":389,"column":1}},"children":[{"type":"text","value":"Note:","position":{"start":{"line":389,"column":1},"end":{"line":389,"column":1}},"key":"gA7lus6foU"}],"key":"zbtczDjca5"},{"type":"text","value":" In more technical terms, you:","position":{"start":{"line":389,"column":1},"end":{"line":389,"column":1}},"key":"nT5q19vpqA"}],"key":"rngkecT2ob"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":391,"column":1},"end":{"line":394,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":391,"column":1},"end":{"line":391,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Measure the error by comparing the real label of an image (the truth) with the prediction of the model.","position":{"start":{"line":391,"column":1},"end":{"line":391,"column":1}},"key":"gz76bSkw1t"}],"key":"wrp8KQlf5V"}],"key":"Y1k705G3qr"},{"type":"listItem","spread":true,"position":{"start":{"line":392,"column":1},"end":{"line":392,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Differentiate the loss function.","position":{"start":{"line":392,"column":1},"end":{"line":392,"column":1}},"key":"bN2l5GFGHu"}],"key":"G6BDZFbxQQ"}],"key":"QXppvoQwbM"},{"type":"listItem","spread":true,"position":{"start":{"line":393,"column":1},"end":{"line":394,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Ingest the ","position":{"start":{"line":393,"column":1},"end":{"line":393,"column":1}},"key":"cQxCx8L8SG"},{"type":"link","url":"https://en.wikipedia.org/wiki/Gradient","position":{"start":{"line":393,"column":1},"end":{"line":393,"column":1}},"children":[{"type":"text","value":"gradients","position":{"start":{"line":393,"column":1},"end":{"line":393,"column":1}},"key":"QVz9ylqvp7"}],"urlSource":"https://en.wikipedia.org/wiki/Gradient","data":{"page":"Gradient","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"muoFtZygIk"},{"type":"text","value":" with the respect to the output, and backpropagate them with the respect to the inputs through the layer(s).","position":{"start":{"line":393,"column":1},"end":{"line":393,"column":1}},"key":"HdHxFZJEIP"}],"key":"lu6BByhijh"}],"key":"NYc3TUaVEw"}],"key":"ZEdpLIVpz3"},{"type":"paragraph","position":{"start":{"line":395,"column":1},"end":{"line":395,"column":1}},"children":[{"type":"text","value":"Since the network contains tensor operations and weight matrices, backpropagation uses the ","position":{"start":{"line":395,"column":1},"end":{"line":395,"column":1}},"key":"hycIStGMAO"},{"type":"link","url":"https://en.wikipedia.org/wiki/Chain_rule","position":{"start":{"line":395,"column":1},"end":{"line":395,"column":1}},"children":[{"type":"text","value":"chain rule","position":{"start":{"line":395,"column":1},"end":{"line":395,"column":1}},"key":"glzi0CfJxM"}],"urlSource":"https://en.wikipedia.org/wiki/Chain_rule","data":{"page":"Chain_rule","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"RwbhXx9CXJ"},{"type":"text","value":".","position":{"start":{"line":395,"column":1},"end":{"line":395,"column":1}},"key":"bEpOj3a4c3"}],"key":"x1ZH4KgQ7V"},{"type":"paragraph","position":{"start":{"line":397,"column":1},"end":{"line":397,"column":1}},"children":[{"type":"text","value":"With each iteration (epoch) of the neural network training, this forward and backward propagation cycle adjusts the weights, which is reflected in the accuracy and error metrics. As you train the model, your goal is to minimize the error and maximize the accuracy on the training data, where the model learns from, as well as the test data, where you evaluate the model.","position":{"start":{"line":397,"column":1},"end":{"line":397,"column":1}},"key":"AXqY5jxHkp"}],"key":"PFzb3JtdwI"}],"key":"rfAvWe7vZb"},{"type":"heading","depth":3,"position":{"start":{"line":399,"column":1},"end":{"line":399,"column":1}},"children":[{"type":"text","value":"Compose the model and begin training and testing it","position":{"start":{"line":399,"column":1},"end":{"line":399,"column":1}},"key":"RHNGmS1axq"}],"identifier":"compose-the-model-and-begin-training-and-testing-it","label":"Compose the model and begin training and testing it","html_id":"compose-the-model-and-begin-training-and-testing-it","implicit":true,"key":"BDu8AneAIg"},{"type":"paragraph","position":{"start":{"line":401,"column":1},"end":{"line":401,"column":1}},"children":[{"type":"text","value":"Having covered the main deep learning concepts and the neural network architecture, let’s write the code.","position":{"start":{"line":401,"column":1},"end":{"line":401,"column":1}},"key":"lqgOccNho1"}],"key":"vn8zMvSvFd"},{"type":"paragraph","position":{"start":{"line":403,"column":1},"end":{"line":404,"column":1}},"children":[{"type":"strong","position":{"start":{"line":403,"column":1},"end":{"line":403,"column":1}},"children":[{"type":"text","value":"1.","position":{"start":{"line":403,"column":1},"end":{"line":403,"column":1}},"key":"WSLjxIuu3M"}],"key":"XlAD4X2weI"},{"type":"text","value":" We’ll start by creating a new random number generator, providing a seed\nfor reproducibility:","position":{"start":{"line":403,"column":1},"end":{"line":403,"column":1}},"key":"ldd2De7FAR"}],"key":"bz8DNYJ2Yt"}],"key":"S156qoJ58c"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"seed = 884736743\nrng = np.random.default_rng(seed)","key":"ad74BUUsDO"},{"type":"outputs","id":"gpKaKKzMIFb-5o2SdP4IX","children":[],"key":"Xj1RKa34B8"}],"key":"hSO2EMKXjh"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":411,"column":1},"end":{"line":411,"column":1}},"children":[{"type":"strong","position":{"start":{"line":411,"column":1},"end":{"line":411,"column":1}},"children":[{"type":"text","value":"2.","position":{"start":{"line":411,"column":1},"end":{"line":411,"column":1}},"key":"IeGDHBHXj3"}],"key":"iY14BxfEDg"},{"type":"text","value":" For the hidden layer, define the ReLU activation function for forward propagation and ReLU’s derivative that will be used during backpropagation:","position":{"start":{"line":411,"column":1},"end":{"line":411,"column":1}},"key":"zU2iQi4yzF"}],"key":"gsAZomvTfh"}],"key":"jLzD1x6Kvv"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Define ReLU that returns the input if it's positive and 0 otherwise.\ndef relu(x):\n    return (x \u003e= 0) * x\n\n\n# Set up a derivative of the ReLU function that returns 1 for a positive input\n# and 0 otherwise.\ndef relu2deriv(output):\n    return output \u003e= 0","key":"vSyTiXgMO2"},{"type":"outputs","id":"-BEr4ILigsjvgJTp3sqbF","children":[],"key":"CFrzGYdueu"}],"key":"vL42di41DR"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":425,"column":1},"end":{"line":425,"column":1}},"children":[{"type":"strong","position":{"start":{"line":425,"column":1},"end":{"line":425,"column":1}},"children":[{"type":"text","value":"3.","position":{"start":{"line":425,"column":1},"end":{"line":425,"column":1}},"key":"AvHHVLYKri"}],"key":"DK2kUPAn0t"},{"type":"text","value":" Set certain default values of ","position":{"start":{"line":425,"column":1},"end":{"line":425,"column":1}},"key":"WqXsU4vE8n"},{"type":"link","url":"https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)","position":{"start":{"line":425,"column":1},"end":{"line":425,"column":1}},"children":[{"type":"text","value":"hyperparameters","position":{"start":{"line":425,"column":1},"end":{"line":425,"column":1}},"key":"QMz0JhZ2YE"}],"urlSource":"https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)","data":{"page":"Hyperparameter_(machine_learning)","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"TqrcfZ63Y8"},{"type":"text","value":", such as:","position":{"start":{"line":425,"column":1},"end":{"line":425,"column":1}},"key":"zoctJQdDi5"}],"key":"oqnDW4VXxw"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":427,"column":1},"end":{"line":432,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":427,"column":1},"end":{"line":427,"column":1}},"children":[{"type":"paragraph","children":[{"type":"link","url":"https://en.wikipedia.org/wiki/Learning_rate","position":{"start":{"line":427,"column":1},"end":{"line":427,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":427,"column":1},"end":{"line":427,"column":1}},"children":[{"type":"text","value":"Learning rate","position":{"start":{"line":427,"column":1},"end":{"line":427,"column":1}},"key":"HH2MLnF3EX"}],"key":"nBvUZOADyL"}],"urlSource":"https://en.wikipedia.org/wiki/Learning_rate","data":{"page":"Learning_rate","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"ukPt6DSfwV"},{"type":"text","value":": ","position":{"start":{"line":427,"column":1},"end":{"line":427,"column":1}},"key":"iO04kF9Smt"},{"type":"inlineCode","value":"learning_rate","position":{"start":{"line":427,"column":1},"end":{"line":427,"column":1}},"key":"weQ1jmlnlX"},{"type":"text","value":" — helps limit the magnitude of weight updates to prevent them from overcorrecting.","position":{"start":{"line":427,"column":1},"end":{"line":427,"column":1}},"key":"ERcUJIdeQm"}],"key":"jBTcts3YYC"}],"key":"FCRvN85yM5"},{"type":"listItem","spread":true,"position":{"start":{"line":428,"column":1},"end":{"line":428,"column":1}},"children":[{"type":"paragraph","children":[{"type":"emphasis","position":{"start":{"line":428,"column":1},"end":{"line":428,"column":1}},"children":[{"type":"text","value":"Epochs (iterations)","position":{"start":{"line":428,"column":1},"end":{"line":428,"column":1}},"key":"n4Y65WUtd9"}],"key":"hYAVX0nOjH"},{"type":"text","value":": ","position":{"start":{"line":428,"column":1},"end":{"line":428,"column":1}},"key":"WzceFuAoH2"},{"type":"inlineCode","value":"epochs","position":{"start":{"line":428,"column":1},"end":{"line":428,"column":1}},"key":"m5H2dLD05D"},{"type":"text","value":" — the number of complete passes — forward and backward propagations — of the data through the network. This parameter can positively or negatively affect the results. The higher the iterations, the longer the learning process may take. Because this is a computationally intensive task, we have chosen a very low number of epochs (20). To get meaningful results, you should choose a much larger number.","position":{"start":{"line":428,"column":1},"end":{"line":428,"column":1}},"key":"ByRsu8TOYh"}],"key":"l2XjHfoBp8"}],"key":"BcLeFAqJTQ"},{"type":"listItem","spread":true,"position":{"start":{"line":429,"column":1},"end":{"line":429,"column":1}},"children":[{"type":"paragraph","children":[{"type":"emphasis","position":{"start":{"line":429,"column":1},"end":{"line":429,"column":1}},"children":[{"type":"text","value":"Size of the hidden (middle) layer in a network","position":{"start":{"line":429,"column":1},"end":{"line":429,"column":1}},"key":"QvaMR4XGm0"}],"key":"UYvY4bhrk1"},{"type":"text","value":": ","position":{"start":{"line":429,"column":1},"end":{"line":429,"column":1}},"key":"pkELsYIpEH"},{"type":"inlineCode","value":"hidden_size","position":{"start":{"line":429,"column":1},"end":{"line":429,"column":1}},"key":"X1ArT7qsSz"},{"type":"text","value":" — different sizes of the hidden layer can affect the results during training and testing.","position":{"start":{"line":429,"column":1},"end":{"line":429,"column":1}},"key":"nWAy3aIJJb"}],"key":"fUpxCP3arW"}],"key":"f0XMw3fkxm"},{"type":"listItem","spread":true,"position":{"start":{"line":430,"column":1},"end":{"line":430,"column":1}},"children":[{"type":"paragraph","children":[{"type":"emphasis","position":{"start":{"line":430,"column":1},"end":{"line":430,"column":1}},"children":[{"type":"text","value":"Size of the input:","position":{"start":{"line":430,"column":1},"end":{"line":430,"column":1}},"key":"TO3JtJPdv1"}],"key":"X6pFRL3uA3"},{"type":"text","value":" ","position":{"start":{"line":430,"column":1},"end":{"line":430,"column":1}},"key":"ck0oxrW9HG"},{"type":"inlineCode","value":"pixels_per_image","position":{"start":{"line":430,"column":1},"end":{"line":430,"column":1}},"key":"NnzDiPzYNm"},{"type":"text","value":" — you have established that the image input is 784 (28x28) (in pixels).","position":{"start":{"line":430,"column":1},"end":{"line":430,"column":1}},"key":"Ruu53QvGZR"}],"key":"h93Dnvtrw4"}],"key":"ffXHNzWKAW"},{"type":"listItem","spread":true,"position":{"start":{"line":431,"column":1},"end":{"line":432,"column":1}},"children":[{"type":"paragraph","children":[{"type":"emphasis","position":{"start":{"line":431,"column":1},"end":{"line":431,"column":1}},"children":[{"type":"text","value":"Number of labels","position":{"start":{"line":431,"column":1},"end":{"line":431,"column":1}},"key":"gHYgVQqoA5"}],"key":"wWO3O3bKyP"},{"type":"text","value":": ","position":{"start":{"line":431,"column":1},"end":{"line":431,"column":1}},"key":"yUOPKDyuM6"},{"type":"inlineCode","value":"num_labels","position":{"start":{"line":431,"column":1},"end":{"line":431,"column":1}},"key":"s63dphjAvu"},{"type":"text","value":" — indicates the output number for the output layer where the predictions occur for 10 (0 to 9) handwritten digit labels.","position":{"start":{"line":431,"column":1},"end":{"line":431,"column":1}},"key":"DEpjLLVmKX"}],"key":"ERplTUHPYg"}],"key":"ASCjhXvTn0"}],"key":"t8RQM7jPSy"}],"key":"Jjvk6yX2si"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"learning_rate = 0.005\nepochs = 20\nhidden_size = 100\npixels_per_image = 784\nnum_labels = 10","key":"hyunLNYtbq"},{"type":"outputs","id":"YdbLSovz6WRtdck8Usxzu","children":[],"key":"QxNb8c9Ogb"}],"key":"nCm94hdrml"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":441,"column":1},"end":{"line":441,"column":1}},"children":[{"type":"strong","position":{"start":{"line":441,"column":1},"end":{"line":441,"column":1}},"children":[{"type":"text","value":"4.","position":{"start":{"line":441,"column":1},"end":{"line":441,"column":1}},"key":"ivsw3LgS5b"}],"key":"BtlJYJd778"},{"type":"text","value":" Initialize the weight vectors that will be used in the hidden and output layers with random values:","position":{"start":{"line":441,"column":1},"end":{"line":441,"column":1}},"key":"E8jjOnDiZ2"}],"key":"sjtZUu0Pt6"}],"key":"kPASoN3XDx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"weights_1 = 0.2 * rng.random((pixels_per_image, hidden_size)) - 0.1\nweights_2 = 0.2 * rng.random((hidden_size, num_labels)) - 0.1","key":"E5sktEYzRH"},{"type":"outputs","id":"xrYwJiEjbX_hMEIZf7xTk","children":[],"key":"i7VpA9dUjL"}],"key":"bua4T2sW87"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":448,"column":1},"end":{"line":450,"column":1}},"children":[{"type":"strong","position":{"start":{"line":448,"column":1},"end":{"line":448,"column":1}},"children":[{"type":"text","value":"5.","position":{"start":{"line":448,"column":1},"end":{"line":448,"column":1}},"key":"nhd1qOWgiN"}],"key":"gvBEm0t7Bi"},{"type":"text","value":" Set up the neural network’s learning experiment with a training loop and start the training process.\nNote that the model is evaluated against the test set at each epoch to track\nits performance over the training epochs.","position":{"start":{"line":448,"column":1},"end":{"line":448,"column":1}},"key":"oyG6GFbXNC"}],"key":"GEHtaLvFda"},{"type":"paragraph","position":{"start":{"line":452,"column":1},"end":{"line":452,"column":1}},"children":[{"type":"text","value":"Start the training process:","position":{"start":{"line":452,"column":1},"end":{"line":452,"column":1}},"key":"GXRNdKjTKM"}],"key":"Wk8S73Ta9o"}],"key":"Sbb11itW81"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# To store training and test set losses and accurate predictions\n# for visualization.\nstore_training_loss = []\nstore_training_accurate_pred = []\nstore_test_loss = []\nstore_test_accurate_pred = []\n\n# This is a training loop.\n# Run the learning experiment for a defined number of epochs (iterations).\nfor j in range(epochs):\n\n    #################\n    # Training step #\n    #################\n\n    # Set the initial loss/error and the number of accurate predictions to zero.\n    training_loss = 0.0\n    training_accurate_predictions = 0\n\n    # For all images in the training set, perform a forward pass\n    # and backpropagation and adjust the weights accordingly.\n    for i in range(len(training_images)):\n        # Forward propagation/forward pass:\n        # 1. The input layer:\n        #    Initialize the training image data as inputs.\n        layer_0 = training_images[i]\n        # 2. The hidden layer:\n        #    Take in the training image data into the middle layer by\n        #    matrix-multiplying it by randomly initialized weights.\n        layer_1 = np.dot(layer_0, weights_1)\n        # 3. Pass the hidden layer's output through the ReLU activation function.\n        layer_1 = relu(layer_1)\n        # 4. Define the dropout function for regularization.\n        dropout_mask = rng.integers(low=0, high=2, size=layer_1.shape)\n        # 5. Apply dropout to the hidden layer's output.\n        layer_1 *= dropout_mask * 2\n        # 6. The output layer:\n        #    Ingest the output of the middle layer into the the final layer\n        #    by matrix-multiplying it by randomly initialized weights.\n        #    Produce a 10-dimension vector with 10 scores.\n        layer_2 = np.dot(layer_1, weights_2)\n\n        # Backpropagation/backward pass:\n        # 1. Measure the training error (loss function) between the actual\n        #    image labels (the truth) and the prediction by the model.\n        training_loss += np.sum((training_labels[i] - layer_2) ** 2)\n        # 2. Increment the accurate prediction count.\n        training_accurate_predictions += int(\n            np.argmax(layer_2) == np.argmax(training_labels[i])\n        )\n        # 3. Differentiate the loss function/error.\n        layer_2_delta = training_labels[i] - layer_2\n        # 4. Propagate the gradients of the loss function back through the hidden layer.\n        layer_1_delta = np.dot(weights_2, layer_2_delta) * relu2deriv(layer_1)\n        # 5. Apply the dropout to the gradients.\n        layer_1_delta *= dropout_mask\n        # 6. Update the weights for the middle and input layers\n        #    by multiplying them by the learning rate and the gradients.\n        weights_1 += learning_rate * np.outer(layer_0, layer_1_delta)\n        weights_2 += learning_rate * np.outer(layer_1, layer_2_delta)\n\n    # Store training set losses and accurate predictions.\n    store_training_loss.append(training_loss)\n    store_training_accurate_pred.append(training_accurate_predictions)\n\n    ###################\n    # Evaluation step #\n    ###################\n\n    # Evaluate model performance on the test set at each epoch.\n\n    # Unlike the training step, the weights are not modified for each image\n    # (or batch). Therefore the model can be applied to the test images in a\n    # vectorized manner, eliminating the need to loop over each image\n    # individually:\n\n    results = relu(test_images @ weights_1) @ weights_2\n\n    # Measure the error between the actual label (truth) and prediction values.\n    test_loss = np.sum((test_labels - results) ** 2)\n\n    # Measure prediction accuracy on test set\n    test_accurate_predictions = np.sum(\n        np.argmax(results, axis=1) == np.argmax(test_labels, axis=1)\n    )\n\n    # Store test set losses and accurate predictions.\n    store_test_loss.append(test_loss)\n    store_test_accurate_pred.append(test_accurate_predictions)\n\n    # Summarize error and accuracy metrics at each epoch\n    print(\n        (\n            f\"Epoch: {j}\\n\"\n            f\"  Training set error: {training_loss / len(training_images):.3f}\\n\"\n            f\"  Training set accuracy: {training_accurate_predictions / len(training_images)}\\n\"\n            f\"  Test set error: {test_loss / len(test_images):.3f}\\n\"\n            f\"  Test set accuracy: {test_accurate_predictions / len(test_images)}\"\n        )\n    )","key":"ryGVfcmT2T"},{"type":"outputs","id":"sl532XOA7u15BEMFowQRs","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 0\n  Training set error: 0.898\n  Training set accuracy: 0.397\n  Test set error: 0.680\n  Test set accuracy: 0.582\n"},"key":"kexQqoFUz9"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 1\n  Training set error: 0.656\n  Training set accuracy: 0.633\n  Test set error: 0.607\n  Test set accuracy: 0.641\n"},"key":"AiK4oysOmb"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 2\n  Training set error: 0.592\n  Training set accuracy: 0.68\n  Test set error: 0.569\n  Test set accuracy: 0.679\n"},"key":"zSuTSalv7l"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 3\n  Training set error: 0.556\n  Training set accuracy: 0.7\n  Test set error: 0.541\n  Test set accuracy: 0.708\n"},"key":"UClyrfsPLS"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 4\n  Training set error: 0.534\n  Training set accuracy: 0.732\n  Test set error: 0.526\n  Test set accuracy: 0.729\n"},"key":"mLCDc4yY80"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 5\n  Training set error: 0.515\n  Training set accuracy: 0.715\n  Test set error: 0.500\n  Test set accuracy: 0.739\n"},"key":"KnaiLtt5uZ"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 6\n  Training set error: 0.495\n  Training set accuracy: 0.748\n  Test set error: 0.487\n  Test set accuracy: 0.753\n"},"key":"YubqzmZKLA"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 7\n  Training set error: 0.483\n  Training set accuracy: 0.769\n  Test set error: 0.486\n  Test set accuracy: 0.747\n"},"key":"UtMGHvX81y"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 8\n  Training set error: 0.473\n  Training set accuracy: 0.776\n  Test set error: 0.473\n  Test set accuracy: 0.752\n"},"key":"P10NeZiWEc"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 9\n  Training set error: 0.460\n  Training set accuracy: 0.788\n  Test set error: 0.462\n  Test set accuracy: 0.762\nEpoch: 10\n  Training set error: 0.465\n  Training set accuracy: 0.769\n  Test set error: 0.462\n  Test set accuracy: 0.767\n"},"key":"X60kb381s4"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 11\n  Training set error: 0.443\n  Training set accuracy: 0.801\n  Test set error: 0.456\n  Test set accuracy: 0.775\n"},"key":"HqPrZqZowt"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 12\n  Training set error: 0.448\n  Training set accuracy: 0.795\n  Test set error: 0.455\n  Test set accuracy: 0.772\n"},"key":"rjDZC5tuvF"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 13\n  Training set error: 0.438\n  Training set accuracy: 0.787\n  Test set error: 0.453\n  Test set accuracy: 0.778\n"},"key":"jCkszG6YXS"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 14\n  Training set error: 0.446\n  Training set accuracy: 0.791\n  Test set error: 0.450\n  Test set accuracy: 0.779\nEpoch: 15\n  Training set error: 0.441\n  Training set accuracy: 0.788\n  Test set error: 0.452\n  Test set accuracy: 0.772\n"},"key":"qvHRol53sw"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 16\n  Training set error: 0.437\n  Training set accuracy: 0.786\n  Test set error: 0.453\n  Test set accuracy: 0.772\nEpoch: 17\n  Training set error: 0.436\n  Training set accuracy: 0.794\n  Test set error: 0.449\n  Test set accuracy: 0.778\n"},"key":"qYvmukKejV"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 18\n  Training set error: 0.433\n  Training set accuracy: 0.801\n  Test set error: 0.450\n  Test set accuracy: 0.774\n"},"key":"wiJWlz0UJJ"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Epoch: 19\n  Training set error: 0.429\n  Training set accuracy: 0.785\n  Test set error: 0.436\n  Test set accuracy: 0.784\n"},"key":"nyz7H1sLL5"}],"key":"hQcW87hw8X"}],"key":"QxpsV1xatJ"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":557,"column":1},"end":{"line":557,"column":1}},"children":[{"type":"text","value":"The training process may take many minutes, depending on a number of factors, such as the processing power of the machine you are running the experiment on and the number of epochs. To reduce the waiting time, you can change the epoch (iteration) variable from 100 to a lower number, reset the runtime (which will reset the weights), and run the notebook cells again.","position":{"start":{"line":557,"column":1},"end":{"line":557,"column":1}},"key":"H2T22wYqpJ"}],"key":"aAdKSxeICt"}],"key":"CuCSMrEL0d"},{"type":"block","position":{"start":{"line":559,"column":1},"end":{"line":559,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":561,"column":1},"end":{"line":561,"column":1}},"children":[{"type":"text","value":"After executing the cell above, you can visualize the training and test set errors and accuracy for an instance of this training process.","position":{"start":{"line":561,"column":1},"end":{"line":561,"column":1}},"key":"eBJb7NNURD"}],"key":"caOhYW96l1"}],"key":"kjzEtAR2yq"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"epoch_range = np.arange(epochs) + 1  # Starting from 1\n\n# The training set metrics.\ntraining_metrics = {\n    \"accuracy\": np.asarray(store_training_accurate_pred) / len(training_images),\n    \"error\": np.asarray(store_training_loss) / len(training_images),\n}\n\n# The test set metrics.\ntest_metrics = {\n    \"accuracy\": np.asarray(store_test_accurate_pred) / len(test_images),\n    \"error\": np.asarray(store_test_loss) / len(test_images),\n}\n\n# Display the plots.\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\nfor ax, metrics, title in zip(\n    axes, (training_metrics, test_metrics), (\"Training set\", \"Test set\")\n):\n    # Plot the metrics\n    for metric, values in metrics.items():\n        ax.plot(epoch_range, values, label=metric.capitalize())\n    ax.set_title(title)\n    ax.set_xlabel(\"Epochs\")\n    ax.legend()\nplt.show()","key":"JSrISytFwi"},{"type":"outputs","id":"55bsp0jZQ0B2BPe0OUX0j","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"\u003cFigure size 1500x500 with 2 Axes\u003e","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"87249290c03a34d5ea6dd3cb94f73280","path":"/numpy-tutorials/build/87249290c03a34d5ea6dd3cb94f73280.png"}}},"key":"TfqAwFoGBp"}],"key":"hOYwrnNUu3"}],"key":"fosWp7yS6o"},{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":592,"column":1},"end":{"line":594,"column":1}},"children":[{"type":"emphasis","position":{"start":{"line":592,"column":1},"end":{"line":592,"column":1}},"children":[{"type":"text","value":"The training and testing error is shown above in the left and right\nplots, respectively. As the number of Epochs increases, the total error\ndecreases and the accuracy increases.","position":{"start":{"line":592,"column":1},"end":{"line":592,"column":1}},"key":"D3alPSD2xq"}],"key":"cJ0Nha9YmR"}],"key":"cXqIcGPsb5"},{"type":"paragraph","position":{"start":{"line":596,"column":1},"end":{"line":596,"column":1}},"children":[{"type":"text","value":"The accuracy rates that your model reaches during training and testing may be somewhat plausible but you may also find the error rates to be quite high.","position":{"start":{"line":596,"column":1},"end":{"line":596,"column":1}},"key":"hxlSIizLs1"}],"key":"UZ3GSSmH7T"},{"type":"paragraph","position":{"start":{"line":598,"column":1},"end":{"line":598,"column":1}},"children":[{"type":"text","value":"To reduce the error during training and testing, you can consider changing the simple loss function to, for example, categorical ","position":{"start":{"line":598,"column":1},"end":{"line":598,"column":1}},"key":"rH3olgn2ll"},{"type":"link","url":"https://en.wikipedia.org/wiki/Cross_entropy","position":{"start":{"line":598,"column":1},"end":{"line":598,"column":1}},"children":[{"type":"text","value":"cross-entropy","position":{"start":{"line":598,"column":1},"end":{"line":598,"column":1}},"key":"wk6q2Qicxz"}],"urlSource":"https://en.wikipedia.org/wiki/Cross_entropy","data":{"page":"Cross_entropy","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"tNmuL1l8T8"},{"type":"text","value":". Other possible solutions are discussed below.","position":{"start":{"line":598,"column":1},"end":{"line":598,"column":1}},"key":"HWaeaHQBjH"}],"key":"ouzHO4AVIo"},{"type":"heading","depth":2,"position":{"start":{"line":600,"column":1},"end":{"line":600,"column":1}},"children":[{"type":"text","value":"Next steps","position":{"start":{"line":600,"column":1},"end":{"line":600,"column":1}},"key":"p9FmiiiBRN"}],"identifier":"next-steps","label":"Next steps","html_id":"next-steps","implicit":true,"key":"yN7V4XZ276"},{"type":"paragraph","position":{"start":{"line":602,"column":1},"end":{"line":602,"column":1}},"children":[{"type":"text","value":"You have learned how to build and train a simple feed-forward neural network from scratch using just NumPy to classify handwritten MNIST digits.","position":{"start":{"line":602,"column":1},"end":{"line":602,"column":1}},"key":"AqybmqiKj3"}],"key":"dIPdOevFdE"},{"type":"paragraph","position":{"start":{"line":604,"column":1},"end":{"line":604,"column":1}},"children":[{"type":"text","value":"To further enhance and optimize your neural network model, you can consider one of a mixture of the following:","position":{"start":{"line":604,"column":1},"end":{"line":604,"column":1}},"key":"kw2waHaQBU"}],"key":"OnVSmkgie2"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":605,"column":1},"end":{"line":614,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":605,"column":1},"end":{"line":605,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Increase the training sample size from 1,000 to a higher number (up to 60,000).","position":{"start":{"line":605,"column":1},"end":{"line":605,"column":1}},"key":"B1S4gPabb9"}],"key":"ra7j2NgxP0"}],"key":"z4gRx7ZKoV"},{"type":"listItem","spread":true,"position":{"start":{"line":606,"column":1},"end":{"line":606,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Use ","position":{"start":{"line":606,"column":1},"end":{"line":606,"column":1}},"key":"D3lKESgboV"},{"type":"link","url":"http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf","position":{"start":{"line":606,"column":1},"end":{"line":606,"column":1}},"children":[{"type":"text","value":"mini-batches and reduce the learning rate","position":{"start":{"line":606,"column":1},"end":{"line":606,"column":1}},"key":"J851Z1ftvt"}],"urlSource":"http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf","key":"Gb9mmjwli8"},{"type":"text","value":".","position":{"start":{"line":606,"column":1},"end":{"line":606,"column":1}},"key":"yyDwXRzZoT"}],"key":"DK6KruNcro"}],"key":"dyCkWt1pjQ"},{"type":"listItem","spread":true,"position":{"start":{"line":607,"column":1},"end":{"line":607,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Alter the architecture by introducing more hidden layers to make the network ","position":{"start":{"line":607,"column":1},"end":{"line":607,"column":1}},"key":"G98pzRFDas"},{"type":"link","url":"https://en.wikipedia.org/wiki/Deep_learning","position":{"start":{"line":607,"column":1},"end":{"line":607,"column":1}},"children":[{"type":"text","value":"deeper","position":{"start":{"line":607,"column":1},"end":{"line":607,"column":1}},"key":"n3oimnKXG2"}],"urlSource":"https://en.wikipedia.org/wiki/Deep_learning","data":{"page":"Deep_learning","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"NFr7XYMtBx"},{"type":"text","value":".","position":{"start":{"line":607,"column":1},"end":{"line":607,"column":1}},"key":"hZfD2qGqX7"}],"key":"dchbio1H9j"}],"key":"WbrleJV9ZP"},{"type":"listItem","spread":true,"position":{"start":{"line":608,"column":1},"end":{"line":608,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Combine the ","position":{"start":{"line":608,"column":1},"end":{"line":608,"column":1}},"key":"LQ7o1d4QhX"},{"type":"link","url":"https://en.wikipedia.org/wiki/Cross_entropy","position":{"start":{"line":608,"column":1},"end":{"line":608,"column":1}},"children":[{"type":"text","value":"cross-entropy","position":{"start":{"line":608,"column":1},"end":{"line":608,"column":1}},"key":"beye1BWobR"}],"urlSource":"https://en.wikipedia.org/wiki/Cross_entropy","data":{"page":"Cross_entropy","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"sks2EJ7Ug2"},{"type":"text","value":" loss function with a ","position":{"start":{"line":608,"column":1},"end":{"line":608,"column":1}},"key":"Y4eIDZdDUy"},{"type":"link","url":"https://en.wikipedia.org/wiki/Softmax_function","position":{"start":{"line":608,"column":1},"end":{"line":608,"column":1}},"children":[{"type":"text","value":"softmax","position":{"start":{"line":608,"column":1},"end":{"line":608,"column":1}},"key":"DKVztbDzja"}],"urlSource":"https://en.wikipedia.org/wiki/Softmax_function","data":{"page":"Softmax_function","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"OnCLbzSW43"},{"type":"text","value":" activation function in the last layer.","position":{"start":{"line":608,"column":1},"end":{"line":608,"column":1}},"key":"fVvDnUgjq6"}],"key":"u5A7OMKYLK"}],"key":"MMaPjTd3XK"},{"type":"listItem","spread":true,"position":{"start":{"line":609,"column":1},"end":{"line":609,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Introduce convolutional layers: replace the feedforward network with a ","position":{"start":{"line":609,"column":1},"end":{"line":609,"column":1}},"key":"q9wR7orjQk"},{"type":"link","url":"https://en.wikipedia.org/wiki/Convolutional_neural_network","position":{"start":{"line":609,"column":1},"end":{"line":609,"column":1}},"children":[{"type":"text","value":"convolutional neural network","position":{"start":{"line":609,"column":1},"end":{"line":609,"column":1}},"key":"Ybw4zmaT8p"}],"urlSource":"https://en.wikipedia.org/wiki/Convolutional_neural_network","data":{"page":"Convolutional_neural_network","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"wD9q0IvRyd"},{"type":"text","value":" architecture.","position":{"start":{"line":609,"column":1},"end":{"line":609,"column":1}},"key":"gwZfeiCOCz"}],"key":"AcG1eMPo46"}],"key":"uhMw3dfpeq"},{"type":"listItem","spread":true,"position":{"start":{"line":610,"column":1},"end":{"line":610,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Use a higher epoch size to train longer and add more regularization techniques, such as ","position":{"start":{"line":610,"column":1},"end":{"line":610,"column":1}},"key":"dayiZjyQfa"},{"type":"link","url":"https://en.wikipedia.org/wiki/Early_stopping","position":{"start":{"line":610,"column":1},"end":{"line":610,"column":1}},"children":[{"type":"text","value":"early stopping","position":{"start":{"line":610,"column":1},"end":{"line":610,"column":1}},"key":"kMT3u8W7fi"}],"urlSource":"https://en.wikipedia.org/wiki/Early_stopping","data":{"page":"Early_stopping","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"mhhkBtj3gh"},{"type":"text","value":", to prevent ","position":{"start":{"line":610,"column":1},"end":{"line":610,"column":1}},"key":"dp9oqhj6MF"},{"type":"link","url":"https://en.wikipedia.org/wiki/Overfitting","position":{"start":{"line":610,"column":1},"end":{"line":610,"column":1}},"children":[{"type":"text","value":"overfitting","position":{"start":{"line":610,"column":1},"end":{"line":610,"column":1}},"key":"Yc3FGcTbkJ"}],"urlSource":"https://en.wikipedia.org/wiki/Overfitting","data":{"page":"Overfitting","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"jWQN9VSW0k"},{"type":"text","value":".","position":{"start":{"line":610,"column":1},"end":{"line":610,"column":1}},"key":"fMoL4SocbG"}],"key":"AP089UQ7pZ"}],"key":"Xqlmga2ETy"},{"type":"listItem","spread":true,"position":{"start":{"line":611,"column":1},"end":{"line":611,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Introduce a ","position":{"start":{"line":611,"column":1},"end":{"line":611,"column":1}},"key":"EOLUjlgh2r"},{"type":"link","url":"https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets","position":{"start":{"line":611,"column":1},"end":{"line":611,"column":1}},"children":[{"type":"text","value":"validation set","position":{"start":{"line":611,"column":1},"end":{"line":611,"column":1}},"key":"Kp67SxQ09F"}],"urlSource":"https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets","data":{"page":"Training,_validation,_and_test_sets","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"bOmR0Rs1CP"},{"type":"text","value":" for an unbiased valuation of the model fit.","position":{"start":{"line":611,"column":1},"end":{"line":611,"column":1}},"key":"Z1O5mCfXvj"}],"key":"BCLlHtFB1r"}],"key":"ykWLiMaCKR"},{"type":"listItem","spread":true,"position":{"start":{"line":612,"column":1},"end":{"line":612,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Apply ","position":{"start":{"line":612,"column":1},"end":{"line":612,"column":1}},"key":"S216QnqYU5"},{"type":"link","url":"https://en.wikipedia.org/wiki/Batch_normalization","position":{"start":{"line":612,"column":1},"end":{"line":612,"column":1}},"children":[{"type":"text","value":"batch normalization","position":{"start":{"line":612,"column":1},"end":{"line":612,"column":1}},"key":"WSKcHUgUrf"}],"urlSource":"https://en.wikipedia.org/wiki/Batch_normalization","data":{"page":"Batch_normalization","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"P8fcagpMat"},{"type":"text","value":" for faster and more stable training.","position":{"start":{"line":612,"column":1},"end":{"line":612,"column":1}},"key":"Z1Pu2WI2nQ"}],"key":"bLrFigMAsY"}],"key":"SufHiM1hEP"},{"type":"listItem","spread":true,"position":{"start":{"line":613,"column":1},"end":{"line":614,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Tune other parameters, such as the learning rate and hidden layer size.","position":{"start":{"line":613,"column":1},"end":{"line":613,"column":1}},"key":"B95d86vSrP"}],"key":"fWNnqgOs6M"}],"key":"fZzXdjY96t"}],"key":"mmcWHqJuA0"},{"type":"paragraph","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"children":[{"type":"text","value":"Building a neural network from scratch with NumPy is a great way to learn more about NumPy and about deep learning. However, for real-world applications you should use specialized frameworks — such as ","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"key":"JOopSkrnV9"},{"type":"link","url":"https://pytorch.org/","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"children":[{"type":"text","value":"PyTorch","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"key":"qSQWU3K1Vx"}],"urlSource":"https://pytorch.org/","key":"F0tHoHNW1C"},{"type":"text","value":", ","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"key":"GWnXV7ka1g"},{"type":"link","url":"https://github.com/google/jax","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"children":[{"type":"text","value":"JAX","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"key":"BUY1nSy0qC"}],"urlSource":"https://github.com/google/jax","error":true,"key":"A1vD1mJCqJ"},{"type":"text","value":", ","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"key":"HVx40Ofg1b"},{"type":"link","url":"https://www.tensorflow.org/guide/tf_numpy","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"children":[{"type":"text","value":"TensorFlow","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"key":"vw0ZnkRHdk"}],"urlSource":"https://www.tensorflow.org/guide/tf_numpy","key":"ErtWtSzdsS"},{"type":"text","value":" or ","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"key":"ChVl8ibTu5"},{"type":"link","url":"https://mxnet.apache.org","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"children":[{"type":"text","value":"MXNet","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"key":"CnojojJZWR"}],"urlSource":"https://mxnet.apache.org","key":"ycmBRUhDM7"},{"type":"text","value":" — that provide NumPy-like APIs, have built-in ","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"key":"ZPw32wUZEA"},{"type":"link","url":"https://en.wikipedia.org/wiki/Automatic_differentiation","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"children":[{"type":"text","value":"automatic differentiation","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"key":"mi4V7nu0y3"}],"urlSource":"https://en.wikipedia.org/wiki/Automatic_differentiation","data":{"page":"Automatic_differentiation","wiki":"https://en.wikipedia.org/","lang":"en"},"internal":false,"protocol":"wiki","key":"maYEZqBVoS"},{"type":"text","value":" and GPU support, and are designed for high-performance numerical computing and machine learning.","position":{"start":{"line":615,"column":1},"end":{"line":615,"column":1}},"key":"tMSmUqKITR"}],"key":"CzIseNcetq"},{"type":"paragraph","position":{"start":{"line":617,"column":1},"end":{"line":617,"column":1}},"children":[{"type":"text","value":"Finally, when developing a machine learning model, you should think about potential ethical issues and apply practices to avoid or mitigate those:","position":{"start":{"line":617,"column":1},"end":{"line":617,"column":1}},"key":"J6pYKjHacu"}],"key":"zMn4hMTylH"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":618,"column":1},"end":{"line":622,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":618,"column":1},"end":{"line":618,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Document a trained model with a Model Card - see the ","position":{"start":{"line":618,"column":1},"end":{"line":618,"column":1}},"key":"syX0SI7Z97"},{"type":"cite","url":"https://doi.org/10.1145/3287560.3287596","position":{"start":{"line":618,"column":1},"end":{"line":618,"column":1}},"children":[{"type":"text","value":"Model Cards for Model Reporting paper","position":{"start":{"line":618,"column":1},"end":{"line":618,"column":1}},"key":"i0ptbnwJpi"}],"kind":"narrative","label":"Mitchell_2019","identifier":"https://doi.org/10.1145/3287560.3287596","enumerator":"1","key":"UKpVytl7iM"},{"type":"text","value":" by Margaret Mitchell et al..","position":{"start":{"line":618,"column":1},"end":{"line":618,"column":1}},"key":"YpnkEdb1HS"}],"key":"ZkstiFzzt1"}],"key":"vU6kv6f9B6"},{"type":"listItem","spread":true,"position":{"start":{"line":619,"column":1},"end":{"line":619,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Document a dataset with a Datasheet - see the ","position":{"start":{"line":619,"column":1},"end":{"line":619,"column":1}},"key":"L1f0UdZfl5"},{"type":"link","url":"https://arxiv.org/abs/1803.09010","position":{"start":{"line":619,"column":1},"end":{"line":619,"column":1}},"children":[{"type":"text","value":"Datasheets for Datasets paper","position":{"start":{"line":619,"column":1},"end":{"line":619,"column":1}},"key":"AZueHowyeO"}],"urlSource":"https://arxiv.org/abs/1803.09010","key":"AlXBOskMXq"},{"type":"text","value":") by Timnit Gebru et al..","position":{"start":{"line":619,"column":1},"end":{"line":619,"column":1}},"key":"cGKlcld3do"}],"key":"anFecdUmKT"}],"key":"niS27gmuF5"},{"type":"listItem","spread":true,"position":{"start":{"line":620,"column":1},"end":{"line":620,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Consider the impact of your model - who is affected by it, who does it benefit - see ","position":{"start":{"line":620,"column":1},"end":{"line":620,"column":1}},"key":"e33sJCh2sR"},{"type":"link","url":"https://www.nature.com/articles/d41586-020-02003-2","position":{"start":{"line":620,"column":1},"end":{"line":620,"column":1}},"children":[{"type":"text","value":"the article","position":{"start":{"line":620,"column":1},"end":{"line":620,"column":1}},"key":"AGm24AP3qF"}],"urlSource":"https://www.nature.com/articles/d41586-020-02003-2","key":"HAeLv3hgez"},{"type":"text","value":" and ","position":{"start":{"line":620,"column":1},"end":{"line":620,"column":1}},"key":"YVhb6RpLd8"},{"type":"link","url":"https://slideslive.com/38923453/the-values-of-machine-learning","position":{"start":{"line":620,"column":1},"end":{"line":620,"column":1}},"children":[{"type":"text","value":"talk","position":{"start":{"line":620,"column":1},"end":{"line":620,"column":1}},"key":"yU3SC1PhxN"}],"urlSource":"https://slideslive.com/38923453/the-values-of-machine-learning","key":"MJS0B765wj"},{"type":"text","value":" by Pratyusha Kalluri.","position":{"start":{"line":620,"column":1},"end":{"line":620,"column":1}},"key":"xjwCCnQicm"}],"key":"wArYrnyPen"}],"key":"xdACDGlILG"},{"type":"listItem","spread":true,"position":{"start":{"line":621,"column":1},"end":{"line":622,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"For more resources, see ","position":{"start":{"line":621,"column":1},"end":{"line":621,"column":1}},"key":"evQeSleNup"},{"type":"link","url":"https://www.fast.ai/2018/09/24/ai-ethics-resources/","position":{"start":{"line":621,"column":1},"end":{"line":621,"column":1}},"children":[{"type":"text","value":"this blog post by Rachel Thomas","position":{"start":{"line":621,"column":1},"end":{"line":621,"column":1}},"key":"Dh8PXuwOK1"}],"urlSource":"https://www.fast.ai/2018/09/24/ai-ethics-resources/","key":"D4MWdnFxxF"},{"type":"text","value":" and the ","position":{"start":{"line":621,"column":1},"end":{"line":621,"column":1}},"key":"bfifKkrQ2c"},{"type":"link","url":"https://www.radicalai.org/","position":{"start":{"line":621,"column":1},"end":{"line":621,"column":1}},"children":[{"type":"text","value":"Radical AI podcast","position":{"start":{"line":621,"column":1},"end":{"line":621,"column":1}},"key":"YkrU8nOMH4"}],"urlSource":"https://www.radicalai.org/","key":"b8ciytjMPd"},{"type":"text","value":".","position":{"start":{"line":621,"column":1},"end":{"line":621,"column":1}},"key":"CSsS0qcRCd"}],"key":"e445fieJ13"}],"key":"av2WYgru8g"}],"key":"D33A5tB7OX"},{"type":"paragraph","position":{"start":{"line":623,"column":1},"end":{"line":623,"column":1}},"children":[{"type":"text","value":"(Credit to ","position":{"start":{"line":623,"column":1},"end":{"line":623,"column":1}},"key":"OgdIAG5eo1"},{"type":"link","url":"https://github.com/hsjeong5/MNIST-for-Numpy","position":{"start":{"line":623,"column":1},"end":{"line":623,"column":1}},"children":[{"type":"text","value":"hsjeong5","position":{"start":{"line":623,"column":1},"end":{"line":623,"column":1}},"key":"yhIyEPPTDL"}],"urlSource":"https://github.com/hsjeong5/MNIST-for-Numpy","error":true,"key":"oXjcSSvWzk"},{"type":"text","value":" for demonstrating how to download MNIST without the use of external libraries.)","position":{"start":{"line":623,"column":1},"end":{"line":623,"column":1}},"key":"bfcBVfAGtX"}],"key":"BxaxOL33t4"}],"key":"AjQAdRVyWi"}],"key":"yUjcQzVSXC"},"references":{"cite":{"order":["Mitchell_2019"],"data":{"Mitchell_2019":{"label":"Mitchell_2019","enumerator":"1","doi":"10.1145/3287560.3287596","html":"Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., Spitzer, E., Raji, I. D., \u0026 Gebru, T. (2019). Model Cards for Model Reporting. \u003ci\u003eProceedings of the Conference on Fairness, Accountability, and Transparency\u003c/i\u003e, 220–229. \u003ca target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.1145/3287560.3287596\"\u003e10.1145/3287560.3287596\u003c/a\u003e","url":"https://doi.org/10.1145/3287560.3287596"}}}},"footer":{"navigation":{"prev":{"title":"Determining Moore’s Law with real data in NumPy","short_title":"Moore's Law","url":"/mooreslaw-tutorial","group":"Applications"},"next":{"title":"X-ray image processing","url":"/tutorial-x-ray-image-processing","group":"Applications"}}},"domain":"http://localhost:3000"},"project":{"title":"Numpy Tutorials","authors":[{"id":"Numpy Community","name":"Numpy Community"}],"github":"https://github.com/numpy/numpy-tutorials","toc":[{"file":"content/index.md"},{"children":[{"file":"content/mooreslaw-tutorial.md"},{"file":"content/tutorial-deep-learning-on-mnist.md"},{"file":"content/tutorial-x-ray-image-processing.md"},{"file":"content/tutorial-static_equilibrium.md"},{"file":"content/tutorial-plotting-fractals.md"},{"file":"content/tutorial-air-quality-analysis.md"}],"title":"Applications"},{"children":[{"file":"content/tutorial-svd.md"},{"file":"content/save-load-arrays.md"},{"file":"content/tutorial-ma.md"}],"title":"Features"},{"children":[{"file":"content/tutorial-style-guide.md"}],"file":"content/contributing.md","title":"Contributing"}],"thumbnail":"/numpy-tutorials/build/b77199e99a54e59b2e3c037c2cc90f21.svg","exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"Applications"},{"slug":"mooreslaw-tutorial","title":"Determining Moore’s Law with real data in NumPy","short_title":"Moore's Law","description":"","date":"","thumbnail":"/numpy-tutorials/build/01-mooreslaw-tutoria-b7ed0ec7045e43a575dc871f1d80ba79.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-deep-learning-on-mnist","title":"Deep learning on MNIST","description":"","date":"","thumbnail":"/numpy-tutorials/build/tutorial-deep-learni-18c33a02a86a205d4dc00e618c78f2e1.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-x-ray-image-processing","title":"X-ray image processing","description":"","date":"","thumbnail":"/numpy-tutorials/build/tutorial-x-ray-image-65a7be1124126ce5b284c9f07ce0d6ed.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-static-equilibrium","title":"Determining Static Equilibrium in NumPy","short_title":"Static Equilibrium","description":"","date":"","thumbnail":"/numpy-tutorials/build/static_eqbm-fig01-02f515938c9167160a1aa8c0c979c840.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-plotting-fractals","title":"Plotting Fractals","description":"","date":"","thumbnail":"/numpy-tutorials/build/fractal-05cf84dbcdf76b80fa747a06f861f631.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-air-quality-analysis","title":"Analyzing the impact of the lockdown on air quality in Delhi, India","short_title":"Analyzing Air Quality","description":"","date":"","thumbnail":"/numpy-tutorials/build/11-delhi-aqi-719dde59d7502416fd089cc1a3ee750a.jpg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Features"},{"slug":"tutorial-svd","title":"Linear algebra on n-dimensional arrays","short_title":"Linear Algebra on n-D arrays","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"save-load-arrays","title":"Saving and sharing your NumPy arrays","short_title":"Sharing Array Data","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"tutorial-ma","title":"Masked Arrays","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"contributing","title":"Contributing","short_title":"Contributing","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"tutorial-style-guide","title":"Learn to write a NumPy tutorial","short_title":"Style Guide","description":"","date":"","thumbnail":"/numpy-tutorials/build/56554e3d11983df8f484e8d7b2c2bdae.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/numpy-tutorials/build/manifest-3595279D.js";
import * as route0 from "/numpy-tutorials/build/root-SIO6LUTY.js";
import * as route1 from "/numpy-tutorials/build/routes/$-PRP77N34.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/numpy-tutorials/build/entry.client-PCJPW7TK.js");</script></body></html>