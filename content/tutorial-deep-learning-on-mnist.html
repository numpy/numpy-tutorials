
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Deep learning on MNIST &#8212; NumPy Tutorials</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/tutorial-deep-learning-on-mnist';</script>
    <link rel="icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="X-ray image processing" href="tutorial-x-ray-image-processing.html" />
    <link rel="prev" title="Determining Moore’s Law with real data in NumPy" href="mooreslaw-tutorial.html" />
  <meta name="robots" content="noindex" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/numpylogo.svg" class="logo__image only-light" alt="NumPy Tutorials - Home"/>
    <img src="../_static/numpylogo.svg" class="logo__image only-dark pst-js-only" alt="NumPy Tutorials - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/numpy/numpy-tutorials/" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-square-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../features.html">NumPy Features</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorial-svd.html">Linear algebra on n-dimensional arrays</a></li>
<li class="toctree-l2"><a class="reference internal" href="save-load-arrays.html">Saving and sharing your NumPy arrays</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial-ma.html">Masked Arrays</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../applications.html">NumPy Applications</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="mooreslaw-tutorial.html">Determining Moore’s Law with real data in NumPy</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Deep learning on MNIST</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial-x-ray-image-processing.html">X-ray image processing</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial-static_equilibrium.html">Determining Static Equilibrium in NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial-plotting-fractals.html">Plotting Fractals</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial-air-quality-analysis.html">Analyzing the impact of the lockdown on air quality in Delhi, India</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../contributing.html">Contributing</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="pairing.html">Pairing Jupyter notebooks and MyST-NB</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial-style-guide.html">Learn to write a NumPy tutorial</a></li>
</ul>
</details></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../articles.html">Articles</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorial-deep-reinforcement-learning-with-pong-from-pixels.html">Deep reinforcement learning with Pong from pixels</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial-nlp-from-scratch.html">Sentiment Analysis on notable speeches of the last decade</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/numpy/numpy-tutorials/main?urlpath=tree/site/content/tutorial-deep-learning-on-mnist.md" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Binder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Binder logo" src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/numpy/numpy-tutorials" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/numpy/numpy-tutorials/issues/new?title=Issue%20on%20page%20%2Fcontent/tutorial-deep-learning-on-mnist.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/content/tutorial-deep-learning-on-mnist.ipynb" target="_blank"
   class="btn btn-sm btn-download-notebook-button dropdown-item"
   title="Download notebook file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li><a href="../_sources/content/tutorial-deep-learning-on-mnist.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Deep learning on MNIST</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites">Prerequisites</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-contents">Table of contents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-mnist-dataset">1. Load the MNIST dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocess-the-data">2. Preprocess the data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convert-the-image-data-to-the-floating-point-format">Convert the image data to the floating-point format</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convert-the-labels-to-floating-point-through-categorical-one-hot-encoding">Convert the labels to floating point through categorical/one-hot encoding</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#build-and-train-a-small-neural-network-from-scratch">3. Build and train a small neural network from scratch</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-network-building-blocks-with-numpy">Neural network building blocks with NumPy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-architecture-and-training-summary">Model architecture and training summary</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compose-the-model-and-begin-training-and-testing-it">Compose the model and begin training and testing it</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next steps</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="deep-learning-on-mnist">
<h1>Deep learning on MNIST<a class="headerlink" href="#deep-learning-on-mnist" title="Link to this heading">#</a></h1>
<p>This tutorial demonstrates how to build a simple <a class="reference external" href="https://en.wikipedia.org/wiki/Feedforward_neural_network">feedforward neural network</a> (with one hidden layer) and train it from scratch with NumPy to recognize handwritten digit images.</p>
<p>Your deep learning model — one of the most basic artificial neural networks that resembles the original <a class="reference external" href="https://en.wikipedia.org/wiki/Multilayer_perceptron">multi-layer perceptron</a> — will learn to classify digits from 0 to 9 from the <a class="reference external" href="https://en.wikipedia.org/wiki/MNIST_database">MNIST</a> dataset. The dataset contains 60,000 training and 10,000 test images and corresponding labels. Each training and test image is of size 784 (or 28x28 pixels) — this will be your input for the neural network.</p>
<p>Based on the image inputs and their labels (<a class="reference external" href="https://en.wikipedia.org/wiki/Supervised_learning">supervised learning</a>), your neural network will be trained to learn their features using forward propagation and backpropagation (<a class="reference external" href="https://en.wikipedia.org/wiki/Automatic_differentiation#Reverse_accumulation">reverse-mode</a> differentiation). The final output of the network is a vector of 10 scores — one for each handwritten digit image. You will also evaluate how good your model is at classifying the images on the test set.</p>
<p><img alt="Diagram showing operations detailed in this tutorial (The input imageis passed into a Hidden layer that creates a weighted sum of outputs.The weighted sum is passed to the Non-linearity, then regularization andinto the output layer. The output layer creates a prediction which canthen be compared to existing data. The errors are used to calculate theloss function and update weights in the hidden layer and outputlayer.)" src="../_images/tutorial-deep-learning-on-mnist.png" /></p>
<p>This tutorial was adapted from the work by <a class="reference external" href="https://github.com/iamtrask/Grokking-Deep-Learning">Andrew Trask</a> (with the author’s permission).</p>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">#</a></h2>
<p>The reader should have some knowledge of Python, NumPy array manipulation, and linear algebra. In addition, you should be familiar with main concepts of <a class="reference external" href="https://en.wikipedia.org/wiki/Deep_learning">deep learning</a>.</p>
<p>To refresh the memory, you can take the <a class="reference external" href="https://docs.python.org/dev/tutorial/index.html">Python</a> and <a class="reference external" href="https://numpy.org/doc/stable/user/tutorial-svd.html">Linear algebra on n-dimensional arrays</a> tutorials.</p>
<p>You are advised to read the <a class="reference external" href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf">Deep learning</a> paper published in 2015 by Yann LeCun, Yoshua Bengio, and Geoffrey Hinton, who are regarded as some of the pioneers of the field. You should also consider reading Andrew Trask’s <a class="reference external" href="https://www.manning.com/books/grokking-deep-learning">Grokking Deep Learning</a>, which teaches deep learning with NumPy.</p>
<p>In addition to NumPy, you will be utilizing the following Python standard modules for data loading and processing:</p>
<ul>
<li><p><a class="reference external" href="https://docs.python.org/3/library/urllib.html"><code class="docutils literal notranslate"><span class="pre">urllib</span></code></a> for URL handling</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/urllib.request.html"><code class="docutils literal notranslate"><span class="pre">request</span></code></a> for URL opening</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/gzip.html"><code class="docutils literal notranslate"><span class="pre">gzip</span></code></a> for gzip file decompression</p></li>
<li><p><a class="reference external" href="https://docs.python.org/3/library/pickle.html"><code class="docutils literal notranslate"><span class="pre">pickle</span></code></a> to work with the pickle file format</p>
<p>as well as:</p>
</li>
<li><p><a class="reference external" href="https://matplotlib.org/">Matplotlib</a> for data visualization</p></li>
</ul>
<p>This tutorial can be run locally in an isolated environment, such as <a class="reference external" href="https://virtualenv.pypa.io/en/stable/">Virtualenv</a> or <a class="reference external" href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html">conda</a>. You can use <a class="reference external" href="https://jupyter.org/install">Jupyter Notebook or JupyterLab</a> to run each notebook cell. Don’t forget to <a class="reference external" href="https://numpy.org/doc/stable/user/absolute_beginners.html#installing-numpy">set up NumPy</a> and <a class="reference external" href="https://matplotlib.org/users/installing.html#installing-an-official-release">Matplotlib</a>.</p>
</section>
<section id="table-of-contents">
<h2>Table of contents<a class="headerlink" href="#table-of-contents" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Load the MNIST dataset</p></li>
<li><p>Preprocess the dataset</p></li>
<li><p>Build and train a small neural network from scratch</p></li>
<li><p>Next steps</p></li>
</ol>
</section>
<hr class="docutils" />
<section id="load-the-mnist-dataset">
<h2>1. Load the MNIST dataset<a class="headerlink" href="#load-the-mnist-dataset" title="Link to this heading">#</a></h2>
<p>In this section, you will download the zipped MNIST dataset files originally stored in <a class="reference external" href="http://yann.lecun.com/exdb/mnist/">Yann LeCun’s website</a>. Then, you will transform them into 4 files of NumPy array type using built-in Python modules. Finally, you will split the arrays into training and test sets.</p>
<p><strong>1.</strong> Define a variable to store the training/test image/label names of the MNIST dataset in a list:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_sources</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;training_images&quot;</span><span class="p">:</span> <span class="s2">&quot;train-images-idx3-ubyte.gz&quot;</span><span class="p">,</span>  <span class="c1"># 60,000 training images.</span>
    <span class="s2">&quot;test_images&quot;</span><span class="p">:</span> <span class="s2">&quot;t10k-images-idx3-ubyte.gz&quot;</span><span class="p">,</span>  <span class="c1"># 10,000 test images.</span>
    <span class="s2">&quot;training_labels&quot;</span><span class="p">:</span> <span class="s2">&quot;train-labels-idx1-ubyte.gz&quot;</span><span class="p">,</span>  <span class="c1"># 60,000 training labels.</span>
    <span class="s2">&quot;test_labels&quot;</span><span class="p">:</span> <span class="s2">&quot;t10k-labels-idx1-ubyte.gz&quot;</span><span class="p">,</span>  <span class="c1"># 10,000 test labels.</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<p><strong>2.</strong> Load the data. First check if the data is stored locally; if not, then
download it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="s2">&quot;../_data&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">base_url</span> <span class="o">=</span> <span class="s2">&quot;https://github.com/rossbar/numpy-tutorial-data-mirror/blob/main/&quot;</span>

<span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">data_sources</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
    <span class="n">fpath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">fname</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">fpath</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Downloading file: &quot;</span> <span class="o">+</span> <span class="n">fname</span><span class="p">)</span>
        <span class="n">resp</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">base_url</span> <span class="o">+</span> <span class="n">fname</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">request_opts</span><span class="p">)</span>
        <span class="n">resp</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>  <span class="c1"># Ensure download was succesful</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fpath</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fh</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">resp</span><span class="o">.</span><span class="n">iter_content</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
                <span class="n">fh</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>3.</strong> Decompress the 4 files and create 4 <a class="reference external" href="https://numpy.org/doc/stable/reference/arrays.ndarray.html"><code class="docutils literal notranslate"><span class="pre">ndarrays</span></code></a>, saving them into a dictionary. Each original image is of size 28x28 and neural networks normally expect a 1D vector input; therefore, you also need to reshape the images by multiplying 28 by 28 (784).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gzip</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">mnist_dataset</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># Images</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;training_images&quot;</span><span class="p">,</span> <span class="s2">&quot;test_images&quot;</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">data_sources</span><span class="p">[</span><span class="n">key</span><span class="p">]),</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">mnist_file</span><span class="p">:</span>
        <span class="n">mnist_dataset</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span>
            <span class="n">mnist_file</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">16</span>
        <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span>
<span class="c1"># Labels</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;training_labels&quot;</span><span class="p">,</span> <span class="s2">&quot;test_labels&quot;</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">gzip</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">data_sources</span><span class="p">[</span><span class="n">key</span><span class="p">]),</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">mnist_file</span><span class="p">:</span>
        <span class="n">mnist_dataset</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">frombuffer</span><span class="p">(</span><span class="n">mnist_file</span><span class="o">.</span><span class="n">read</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span> <span class="n">offset</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>4.</strong> Split the data into training and test sets using the standard notation of <code class="docutils literal notranslate"><span class="pre">x</span></code> for data and <code class="docutils literal notranslate"><span class="pre">y</span></code> for labels, calling the training and test set images <code class="docutils literal notranslate"><span class="pre">x_train</span></code> and <code class="docutils literal notranslate"><span class="pre">x_test</span></code>, and the labels <code class="docutils literal notranslate"><span class="pre">y_train</span></code> and <code class="docutils literal notranslate"><span class="pre">y_test</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">mnist_dataset</span><span class="p">[</span><span class="s2">&quot;training_images&quot;</span><span class="p">],</span>
    <span class="n">mnist_dataset</span><span class="p">[</span><span class="s2">&quot;training_labels&quot;</span><span class="p">],</span>
    <span class="n">mnist_dataset</span><span class="p">[</span><span class="s2">&quot;test_images&quot;</span><span class="p">],</span>
    <span class="n">mnist_dataset</span><span class="p">[</span><span class="s2">&quot;test_labels&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>5.</strong> You can confirm that the shape of the image arrays is <code class="docutils literal notranslate"><span class="pre">(60000,</span> <span class="pre">784)</span></code> and <code class="docutils literal notranslate"><span class="pre">(10000,</span> <span class="pre">784)</span></code> for training and test sets, respectively, and the labels — <code class="docutils literal notranslate"><span class="pre">(60000,)</span></code> and <code class="docutils literal notranslate"><span class="pre">(10000,)</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;The shape of training images: </span><span class="si">{}</span><span class="s2"> and training labels: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span>
    <span class="p">)</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="s2">&quot;The shape of test images: </span><span class="si">{}</span><span class="s2"> and test labels: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The shape of training images: (60000, 784) and training labels: (60000,)
The shape of test images: (10000, 784) and test labels: (10000,)
</pre></div>
</div>
</div>
</div>
<p><strong>6.</strong> And you can inspect some images using Matplotlib:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Take the 60,000th image (indexed at 59,999) from the training set,</span>
<span class="c1"># reshape from (784, ) to (28, 28) to have a valid shape for displaying purposes.</span>
<span class="n">mnist_image</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="mi">59999</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
<span class="c1"># Set the color mapping to grayscale to have a black background.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mnist_image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
<span class="c1"># Display the image.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/ff0e390c253c16307d6a92cdc1a4edc1d6fb135b1df740fa85b90ea19deb2ae2.png" src="../_images/ff0e390c253c16307d6a92cdc1a4edc1d6fb135b1df740fa85b90ea19deb2ae2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Display 5 random images from the training set.</span>
<span class="n">num_examples</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">147197952744</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_examples</span><span class="p">)</span>
<span class="k">for</span> <span class="n">sample</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">num_examples</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">sample</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;gray&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/38d38c64e2ce52644ed18584e8bd44776825f4e3b95c76e6ed3f34b1ec1ed07d.png" src="../_images/38d38c64e2ce52644ed18584e8bd44776825f4e3b95c76e6ed3f34b1ec1ed07d.png" />
</div>
</div>
<p><em>Above are five images taken from the MNIST training set. Various hand-drawn
Arabic numerals are shown, with exact values chosen randomly with each run of the code.</em></p>
<blockquote>
<div><p><strong>Note:</strong> You can also visualize a sample image as an array by printing <code class="docutils literal notranslate"><span class="pre">x_train[59999]</span></code>. Here, <code class="docutils literal notranslate"><span class="pre">59999</span></code> is your 60,000th training image sample (<code class="docutils literal notranslate"><span class="pre">0</span></code> would be your first). Your output will be quite long and should contain an array of 8-bit integers:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
         <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>  <span class="mi">38</span><span class="p">,</span>  <span class="mi">48</span><span class="p">,</span>  <span class="mi">48</span><span class="p">,</span>  <span class="mi">22</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>
         <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>
         <span class="mi">0</span><span class="p">,</span>  <span class="mi">62</span><span class="p">,</span>  <span class="mi">97</span><span class="p">,</span> <span class="mi">198</span><span class="p">,</span> <span class="mi">243</span><span class="p">,</span> <span class="mi">254</span><span class="p">,</span> <span class="mi">254</span><span class="p">,</span> <span class="mi">212</span><span class="p">,</span>  <span class="mi">27</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>   <span class="mi">0</span><span class="p">,</span>
<span class="o">...</span>
</pre></div>
</div>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Display the label of the 60,000th image (indexed at 59,999) from the training set.</span>
<span class="n">y_train</span><span class="p">[</span><span class="mi">59999</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>np.uint8(8)
</pre></div>
</div>
</div>
</div>
</section>
<section id="preprocess-the-data">
<h2>2. Preprocess the data<a class="headerlink" href="#preprocess-the-data" title="Link to this heading">#</a></h2>
<p>Neural networks can work with inputs that are in a form of tensors (multidimensional arrays) of floating-point type. When preprocessing the data, you should consider the following processes: <a class="reference external" href="https://en.wikipedia.org/wiki/Vectorization_%28mathematics%29">vectorization</a> and <a class="reference external" href="https://en.wikipedia.org/wiki/Floating-point_arithmetic#Floating-point_numbers">conversion to a floating-point format</a>.</p>
<p>Since the MNIST data is already vectorized and the arrays are of <code class="docutils literal notranslate"><span class="pre">dtype</span></code> <code class="docutils literal notranslate"><span class="pre">uint8</span></code>, your next challenge is to convert them to a floating-point format, such as <code class="docutils literal notranslate"><span class="pre">float64</span></code> (<a class="reference external" href="https://en.wikipedia.org/wiki/Double-precision_floating-point_format">double-precision</a>):</p>
<ul class="simple">
<li><p><em>Normalizing</em> the image data: a <a class="reference external" href="https://en.wikipedia.org/wiki/Feature_scaling#Application">feature scaling</a> procedure that can speed up the neural network training process by standardizing the <a class="reference external" href="https://arxiv.org/pdf/1502.03167.pdf">distribution of your input data</a>.</p></li>
<li><p><em><a class="reference external" href="https://en.wikipedia.org/wiki/One-hot">One-hot/categorical encoding</a></em> of the image labels.</p></li>
</ul>
<p>In practice, you can use different types of floating-point precision depending on your goals and you can find more information about that in the <a class="reference external" href="https://blogs.nvidia.com/blog/2019/11/15/whats-the-difference-between-single-double-multi-and-mixed-precision-computing/">Nvidia</a> and <a class="reference external" href="https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus">Google Cloud</a> blog posts.</p>
<section id="convert-the-image-data-to-the-floating-point-format">
<h3>Convert the image data to the floating-point format<a class="headerlink" href="#convert-the-image-data-to-the-floating-point-format" title="Link to this heading">#</a></h3>
<p>The images data contain 8-bit integers encoded in the [0, 255] interval with color values between 0 and 255.</p>
<p>You will normalize them into floating-point arrays in the [0, 1] interval by dividing them by 255.</p>
<p><strong>1.</strong> Check that the vectorized image data has type <code class="docutils literal notranslate"><span class="pre">uint8</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The data type of training images: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The data type of test images: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The data type of training images: uint8
The data type of test images: uint8
</pre></div>
</div>
</div>
</div>
<p><strong>2.</strong> Normalize the arrays by dividing them by 255 (and thus promoting the data type from <code class="docutils literal notranslate"><span class="pre">uint8</span></code> to <code class="docutils literal notranslate"><span class="pre">float64</span></code>) and then assign the train and test image data variables — <code class="docutils literal notranslate"><span class="pre">x_train</span></code> and <code class="docutils literal notranslate"><span class="pre">x_test</span></code> — to <code class="docutils literal notranslate"><span class="pre">training_images</span></code> and <code class="docutils literal notranslate"><span class="pre">train_labels</span></code>, respectively.
To reduce the model training and evaluation time in this example, only a subset
of the training and test images will be used.
Both <code class="docutils literal notranslate"><span class="pre">training_images</span></code> and <code class="docutils literal notranslate"><span class="pre">test_images</span></code> will contain only 1,000 samples each out
of the complete datasets of 60,000 and 10,000 images, respectively.
These values can be controlled by changing the  <code class="docutils literal notranslate"><span class="pre">training_sample</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_sample</span></code> below, up to their maximum values of 60,000 and 10,000.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">training_sample</span><span class="p">,</span> <span class="n">test_sample</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span>
<span class="n">training_images</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">training_sample</span><span class="p">]</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">test_images</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">test_sample</span><span class="p">]</span> <span class="o">/</span> <span class="mi">255</span>
</pre></div>
</div>
</div>
</div>
<p><strong>3.</strong> Confirm that the image data has changed to the floating-point format:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The data type of training images: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">training_images</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The data type of test images: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_images</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The data type of training images: float64
The data type of test images: float64
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p><strong>Note:</strong> You can also check that normalization was successful by printing <code class="docutils literal notranslate"><span class="pre">training_images[0]</span></code> in a notebook cell. Your long output should contain an array of floating-point numbers:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">...</span>
       <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.</span>        <span class="p">,</span> <span class="mf">0.01176471</span><span class="p">,</span> <span class="mf">0.07058824</span><span class="p">,</span> <span class="mf">0.07058824</span><span class="p">,</span>
       <span class="mf">0.07058824</span><span class="p">,</span> <span class="mf">0.49411765</span><span class="p">,</span> <span class="mf">0.53333333</span><span class="p">,</span> <span class="mf">0.68627451</span><span class="p">,</span> <span class="mf">0.10196078</span><span class="p">,</span>
       <span class="mf">0.65098039</span><span class="p">,</span> <span class="mf">1.</span>        <span class="p">,</span> <span class="mf">0.96862745</span><span class="p">,</span> <span class="mf">0.49803922</span><span class="p">,</span> <span class="mf">0.</span>        <span class="p">,</span>
<span class="o">...</span>
</pre></div>
</div>
</div></blockquote>
</section>
<section id="convert-the-labels-to-floating-point-through-categorical-one-hot-encoding">
<h3>Convert the labels to floating point through categorical/one-hot encoding<a class="headerlink" href="#convert-the-labels-to-floating-point-through-categorical-one-hot-encoding" title="Link to this heading">#</a></h3>
<p>You will use one-hot encoding to embed each digit label as an all-zero vector with <code class="docutils literal notranslate"><span class="pre">np.zeros()</span></code> and place <code class="docutils literal notranslate"><span class="pre">1</span></code> for a label index. As a result, your label data will be arrays with <code class="docutils literal notranslate"><span class="pre">1.0</span></code> (or <code class="docutils literal notranslate"><span class="pre">1.</span></code>) in the position of each image label.</p>
<p>Since there are 10 labels (from 0 to 9) in total, your arrays will look similar to this:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">])</span>
</pre></div>
</div>
<p><strong>1.</strong> Confirm that the image label data are integers with <code class="docutils literal notranslate"><span class="pre">dtype</span></code> <code class="docutils literal notranslate"><span class="pre">uint8</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The data type of training labels: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The data type of test labels: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_test</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The data type of training labels: uint8
The data type of test labels: uint8
</pre></div>
</div>
</div>
</div>
<p><strong>2.</strong> Define a function that performs one-hot encoding on arrays:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">one_hot_encoding</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="c1"># Define a one-hot variable for an all-zero vector</span>
    <span class="c1"># with 10 dimensions (number labels from 0 to 9).</span>
    <span class="n">one_hot_labels</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">dimension</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span>
    <span class="c1"># Return one-hot encoded labels.</span>
    <span class="k">return</span> <span class="n">one_hot_labels</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>3.</strong> Encode the labels and assign the values to new variables:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">training_labels</span> <span class="o">=</span> <span class="n">one_hot_encoding</span><span class="p">(</span><span class="n">y_train</span><span class="p">[:</span><span class="n">training_sample</span><span class="p">])</span>
<span class="n">test_labels</span> <span class="o">=</span> <span class="n">one_hot_encoding</span><span class="p">(</span><span class="n">y_test</span><span class="p">[:</span><span class="n">test_sample</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p><strong>4.</strong> Check that the data type has changed to floating point:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The data type of training labels: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">training_labels</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The data type of test labels: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_labels</span><span class="o">.</span><span class="n">dtype</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The data type of training labels: float64
The data type of test labels: float64
</pre></div>
</div>
</div>
</div>
<p><strong>5.</strong> Examine a few encoded labels:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">training_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">training_labels</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">training_labels</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]
[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]
</pre></div>
</div>
</div>
</div>
<p>…and compare to the originals:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>5
0
4
</pre></div>
</div>
</div>
</div>
<p>You have finished preparing the dataset.</p>
</section>
</section>
<section id="build-and-train-a-small-neural-network-from-scratch">
<h2>3. Build and train a small neural network from scratch<a class="headerlink" href="#build-and-train-a-small-neural-network-from-scratch" title="Link to this heading">#</a></h2>
<p>In this section you will familiarize yourself with some high-level concepts of the basic building blocks of a deep learning model. You can refer to the original <a class="reference external" href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf">Deep learning</a> research publication for more information.</p>
<p>Afterwards, you will construct the building blocks of a simple deep learning model in Python and NumPy and train it to learn to identify handwritten digits from the MNIST dataset with a certain level of accuracy.</p>
<section id="neural-network-building-blocks-with-numpy">
<h3>Neural network building blocks with NumPy<a class="headerlink" href="#neural-network-building-blocks-with-numpy" title="Link to this heading">#</a></h3>
<ul>
<li><p><em>Layers</em>: These building blocks work as data filters — they process data and learn representations from inputs to better predict the target outputs.</p>
<p>You will use 1 hidden layer in your model to pass the inputs forward (<em>forward propagation</em>) and propagate the gradients/error derivatives of a loss function backward (<em>backpropagation</em>). These are input, hidden and output layers.</p>
<p>In the hidden (middle) and output (last) layers, the neural network model will compute the weighted sum of inputs. To compute this process, you will use NumPy’s matrix multiplication function (the “dot multiply” or <code class="docutils literal notranslate"><span class="pre">np.dot(layer,</span> <span class="pre">weights)</span></code>).</p>
<blockquote>
<div><p><strong>Note:</strong> For simplicity, the bias term is omitted in this example (there is no <code class="docutils literal notranslate"><span class="pre">np.dot(layer,</span> <span class="pre">weights)</span> <span class="pre">+</span> <span class="pre">bias</span></code>).</p>
</div></blockquote>
</li>
<li><p><em>Weights</em>: These are important adjustable parameters that the neural network fine-tunes by forward and backward propagating the data. They are optimized through a process called <a class="reference external" href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">gradient descent</a>. Before the model training starts, the weights are randomly initialized with NumPy’s <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.random.html"><code class="docutils literal notranslate"><span class="pre">Generator.random()</span></code></a>.</p>
<p>The optimal weights should produce the highest prediction accuracy and the lowest error on the training and test sets.</p>
</li>
<li><p><em>Activation function</em>: Deep learning models are capable of determining non-linear relationships between inputs and outputs and these <a class="reference external" href="https://en.wikipedia.org/wiki/Activation_function">non-linear functions</a> are usually applied to the output of each layer.</p>
<p>You will use a <a class="reference external" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">rectified linear unit (ReLU)</a> to the hidden layer’s output (for example, <code class="docutils literal notranslate"><span class="pre">relu(np.dot(layer,</span> <span class="pre">weights))</span></code>.</p>
</li>
<li><p><em>Regularization</em>: This <a class="reference external" href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">technique</a> helps prevent the neural network model from <a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a>.</p>
<p>In this example, you will use a method called dropout — <a class="reference external" href="https://en.wikipedia.org/wiki/Dilution_(neural_networks)">dilution</a> — that randomly sets a number of features in a layer to 0s. You will define it with NumPy’s <a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.integers.html"><code class="docutils literal notranslate"><span class="pre">Generator.integers()</span></code></a> method and apply it to the hidden layer of the network.</p>
</li>
<li><p><em>Loss function</em>: The computation determines the quality of predictions by comparing the image labels (the truth) with the predicted values in the final layer’s output.</p>
<p>For simplicity, you will use a basic total squared error using NumPy’s <code class="docutils literal notranslate"><span class="pre">np.sum()</span></code> function (for example, <code class="docutils literal notranslate"><span class="pre">np.sum((final_layer_output</span> <span class="pre">-</span> <span class="pre">image_labels)</span> <span class="pre">**</span> <span class="pre">2)</span></code>).</p>
</li>
<li><p><em>Accuracy</em>: This metric measures the accuracy of the network’s ability to predict on the data it hasn’t seen.</p></li>
</ul>
</section>
<section id="model-architecture-and-training-summary">
<h3>Model architecture and training summary<a class="headerlink" href="#model-architecture-and-training-summary" title="Link to this heading">#</a></h3>
<p>Here is a summary of the neural network model architecture and the training process:</p>
<p><img alt="Diagram showing operations detailed in this tutorial (The input imageis passed into a Hidden layer that creates a weighted sum of outputs.The weighted sum is passed to the Non-linearity, then regularization andinto the output layer. The output layer creates a prediction which canthen be compared to existing data. The errors are used to calculate theloss function and update weights in the hidden layer and outputlayer.)" src="../_images/tutorial-deep-learning-on-mnist.png" /></p>
<ul>
<li><p><em>The input layer</em>:</p>
<p>It is the input for the network — the previously preprocessed data that is loaded from <code class="docutils literal notranslate"><span class="pre">training_images</span></code> into <code class="docutils literal notranslate"><span class="pre">layer_0</span></code>.</p>
</li>
<li><p><em>The hidden (middle) layer</em>:</p>
<p><code class="docutils literal notranslate"><span class="pre">layer_1</span></code> takes the output from the previous layer and performs matrix-multiplication of the input by weights (<code class="docutils literal notranslate"><span class="pre">weights_1</span></code>) with NumPy’s <code class="docutils literal notranslate"><span class="pre">np.dot()</span></code>).</p>
<p>Then, this output is passed through the ReLU activation function for non-linearity and then dropout is applied to help with overfitting.</p>
</li>
<li><p><em>The output (last) layer</em>:</p>
<p><code class="docutils literal notranslate"><span class="pre">layer_2</span></code> ingests the output from <code class="docutils literal notranslate"><span class="pre">layer_1</span></code> and repeats the same “dot multiply” process with <code class="docutils literal notranslate"><span class="pre">weights_2</span></code>.</p>
<p>The final output returns 10 scores for each of the 0-9 digit labels. The network model ends with a size 10 layer — a 10-dimensional vector.</p>
</li>
<li><p><em>Forward propagation, backpropagation, training loop</em>:</p>
<p>In the beginning of model training, your network randomly initializes the weights and feeds the input data forward through the hidden and output layers. This process is the forward pass or forward propagation.</p>
<p>Then, the network propagates the “signal” from the loss function back through the hidden layer and adjusts the weights values with the help of the learning rate parameter (more on that later).</p>
</li>
</ul>
<blockquote>
<div><p><strong>Note:</strong> In more technical terms, you:</p>
<ol class="arabic simple">
<li><p>Measure the error by comparing the real label of an image (the truth) with the prediction of the model.</p></li>
<li><p>Differentiate the loss function.</p></li>
<li><p>Ingest the <a class="reference external" href="https://en.wikipedia.org/wiki/Gradient">gradients</a> with the respect to the output, and backpropagate them with the respect to the inputs through the layer(s).</p></li>
</ol>
<p>Since the network contains tensor operations and weight matrices, backpropagation uses the <a class="reference external" href="https://en.wikipedia.org/wiki/Chain_rule">chain rule</a>.</p>
<p>With each iteration (epoch) of the neural network training, this forward and backward propagation cycle adjusts the weights, which is reflected in the accuracy and error metrics. As you train the model, your goal is to minimize the error and maximize the accuracy on the training data, where the model learns from, as well as the test data, where you evaluate the model.</p>
</div></blockquote>
</section>
<section id="compose-the-model-and-begin-training-and-testing-it">
<h3>Compose the model and begin training and testing it<a class="headerlink" href="#compose-the-model-and-begin-training-and-testing-it" title="Link to this heading">#</a></h3>
<p>Having covered the main deep learning concepts and the neural network architecture, let’s write the code.</p>
<p><strong>1.</strong> We’ll start by creating a new random number generator, providing a seed
for reproducibility:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">seed</span> <span class="o">=</span> <span class="mi">884736743</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>2.</strong> For the hidden layer, define the ReLU activation function for forward propagation and ReLU’s derivative that will be used during backpropagation:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define ReLU that returns the input if it&#39;s positive and 0 otherwise.</span>
<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span>


<span class="c1"># Set up a derivative of the ReLU function that returns 1 for a positive input</span>
<span class="c1"># and 0 otherwise.</span>
<span class="k">def</span> <span class="nf">relu2deriv</span><span class="p">(</span><span class="n">output</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">output</span> <span class="o">&gt;=</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<p><strong>3.</strong> Set certain default values of <a class="reference external" href="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)">hyperparameters</a>, such as:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Learning_rate"><em>Learning rate</em></a>: <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> — helps limit the magnitude of weight updates to prevent them from overcorrecting.</p></li>
<li><p><em>Epochs (iterations)</em>: <code class="docutils literal notranslate"><span class="pre">epochs</span></code> — the number of complete passes — forward and backward propagations — of the data through the network. This parameter can positively or negatively affect the results. The higher the iterations, the longer the learning process may take. Because this is a computationally intensive task, we have chosen a very low number of epochs (20). To get meaningful results, you should choose a much larger number.</p></li>
<li><p><em>Size of the hidden (middle) layer in a network</em>: <code class="docutils literal notranslate"><span class="pre">hidden_size</span></code> — different sizes of the hidden layer can affect the results during training and testing.</p></li>
<li><p><em>Size of the input:</em> <code class="docutils literal notranslate"><span class="pre">pixels_per_image</span></code> — you have established that the image input is 784 (28x28) (in pixels).</p></li>
<li><p><em>Number of labels</em>: <code class="docutils literal notranslate"><span class="pre">num_labels</span></code> — indicates the output number for the output layer where the predictions occur for 10 (0 to 9) handwritten digit labels.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.005</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">pixels_per_image</span> <span class="o">=</span> <span class="mi">784</span>
<span class="n">num_labels</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
</div>
</div>
</div>
<p><strong>4.</strong> Initialize the weight vectors that will be used in the hidden and output layers with random values:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weights_1</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">pixels_per_image</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.1</span>
<span class="n">weights_2</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.1</span>
</pre></div>
</div>
</div>
</div>
<p><strong>5.</strong> Set up the neural network’s learning experiment with a training loop and start the training process.
Note that the model is evaluated against the test set at each epoch to track
its performance over the training epochs.</p>
<p>Start the training process:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># To store training and test set losses and accurate predictions</span>
<span class="c1"># for visualization.</span>
<span class="n">store_training_loss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">store_training_accurate_pred</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">store_test_loss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">store_test_accurate_pred</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># This is a training loop.</span>
<span class="c1"># Run the learning experiment for a defined number of epochs (iterations).</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>

    <span class="c1">#################</span>
    <span class="c1"># Training step #</span>
    <span class="c1">#################</span>

    <span class="c1"># Set the initial loss/error and the number of accurate predictions to zero.</span>
    <span class="n">training_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">training_accurate_predictions</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># For all images in the training set, perform a forward pass</span>
    <span class="c1"># and backpropagation and adjust the weights accordingly.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_images</span><span class="p">)):</span>
        <span class="c1"># Forward propagation/forward pass:</span>
        <span class="c1"># 1. The input layer:</span>
        <span class="c1">#    Initialize the training image data as inputs.</span>
        <span class="n">layer_0</span> <span class="o">=</span> <span class="n">training_images</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="c1"># 2. The hidden layer:</span>
        <span class="c1">#    Take in the training image data into the middle layer by</span>
        <span class="c1">#    matrix-multiplying it by randomly initialized weights.</span>
        <span class="n">layer_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_0</span><span class="p">,</span> <span class="n">weights_1</span><span class="p">)</span>
        <span class="c1"># 3. Pass the hidden layer&#39;s output through the ReLU activation function.</span>
        <span class="n">layer_1</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">layer_1</span><span class="p">)</span>
        <span class="c1"># 4. Define the dropout function for regularization.</span>
        <span class="n">dropout_mask</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">layer_1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="c1"># 5. Apply dropout to the hidden layer&#39;s output.</span>
        <span class="n">layer_1</span> <span class="o">*=</span> <span class="n">dropout_mask</span> <span class="o">*</span> <span class="mi">2</span>
        <span class="c1"># 6. The output layer:</span>
        <span class="c1">#    Ingest the output of the middle layer into the the final layer</span>
        <span class="c1">#    by matrix-multiplying it by randomly initialized weights.</span>
        <span class="c1">#    Produce a 10-dimension vector with 10 scores.</span>
        <span class="n">layer_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer_1</span><span class="p">,</span> <span class="n">weights_2</span><span class="p">)</span>

        <span class="c1"># Backpropagation/backward pass:</span>
        <span class="c1"># 1. Measure the training error (loss function) between the actual</span>
        <span class="c1">#    image labels (the truth) and the prediction by the model.</span>
        <span class="n">training_loss</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">training_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">layer_2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="c1"># 2. Increment the accurate prediction count.</span>
        <span class="n">training_accurate_predictions</span> <span class="o">+=</span> <span class="nb">int</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">layer_2</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">training_labels</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="c1"># 3. Differentiate the loss function/error.</span>
        <span class="n">layer_2_delta</span> <span class="o">=</span> <span class="n">training_labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">layer_2</span>
        <span class="c1"># 4. Propagate the gradients of the loss function back through the hidden layer.</span>
        <span class="n">layer_1_delta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">weights_2</span><span class="p">,</span> <span class="n">layer_2_delta</span><span class="p">)</span> <span class="o">*</span> <span class="n">relu2deriv</span><span class="p">(</span><span class="n">layer_1</span><span class="p">)</span>
        <span class="c1"># 5. Apply the dropout to the gradients.</span>
        <span class="n">layer_1_delta</span> <span class="o">*=</span> <span class="n">dropout_mask</span>
        <span class="c1"># 6. Update the weights for the middle and input layers</span>
        <span class="c1">#    by multiplying them by the learning rate and the gradients.</span>
        <span class="n">weights_1</span> <span class="o">+=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">layer_0</span><span class="p">,</span> <span class="n">layer_1_delta</span><span class="p">)</span>
        <span class="n">weights_2</span> <span class="o">+=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">layer_1</span><span class="p">,</span> <span class="n">layer_2_delta</span><span class="p">)</span>

    <span class="c1"># Store training set losses and accurate predictions.</span>
    <span class="n">store_training_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">training_loss</span><span class="p">)</span>
    <span class="n">store_training_accurate_pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">training_accurate_predictions</span><span class="p">)</span>

    <span class="c1">###################</span>
    <span class="c1"># Evaluation step #</span>
    <span class="c1">###################</span>

    <span class="c1"># Evaluate model performance on the test set at each epoch.</span>

    <span class="c1"># Unlike the training step, the weights are not modified for each image</span>
    <span class="c1"># (or batch). Therefore the model can be applied to the test images in a</span>
    <span class="c1"># vectorized manner, eliminating the need to loop over each image</span>
    <span class="c1"># individually:</span>

    <span class="n">results</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">test_images</span> <span class="o">@</span> <span class="n">weights_1</span><span class="p">)</span> <span class="o">@</span> <span class="n">weights_2</span>

    <span class="c1"># Measure the error between the actual label (truth) and prediction values.</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">test_labels</span> <span class="o">-</span> <span class="n">results</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># Measure prediction accuracy on test set</span>
    <span class="n">test_accurate_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test_labels</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Store test set losses and accurate predictions.</span>
    <span class="n">store_test_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_loss</span><span class="p">)</span>
    <span class="n">store_test_accurate_pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_accurate_predictions</span><span class="p">)</span>

    <span class="c1"># Summarize error and accuracy metrics at each epoch</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;  Training set error: </span><span class="si">{</span><span class="n">training_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">training_images</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;  Training set accuracy: </span><span class="si">{</span><span class="n">training_accurate_predictions</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">training_images</span><span class="p">)</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;  Test set error: </span><span class="si">{</span><span class="n">test_loss</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">test_images</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;  Test set accuracy: </span><span class="si">{</span><span class="n">test_accurate_predictions</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="n">test_images</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 0
  Training set error: 0.898
  Training set accuracy: 0.397
  Test set error: 0.680
  Test set accuracy: 0.582
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 1
  Training set error: 0.656
  Training set accuracy: 0.633
  Test set error: 0.607
  Test set accuracy: 0.641
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 2
  Training set error: 0.592
  Training set accuracy: 0.68
  Test set error: 0.569
  Test set accuracy: 0.679
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 3
  Training set error: 0.556
  Training set accuracy: 0.7
  Test set error: 0.541
  Test set accuracy: 0.708
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 4
  Training set error: 0.534
  Training set accuracy: 0.732
  Test set error: 0.526
  Test set accuracy: 0.729
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 5
  Training set error: 0.515
  Training set accuracy: 0.715
  Test set error: 0.500
  Test set accuracy: 0.739
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 6
  Training set error: 0.495
  Training set accuracy: 0.748
  Test set error: 0.487
  Test set accuracy: 0.753
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 7
  Training set error: 0.483
  Training set accuracy: 0.769
  Test set error: 0.486
  Test set accuracy: 0.747
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 8
  Training set error: 0.473
  Training set accuracy: 0.776
  Test set error: 0.473
  Test set accuracy: 0.752
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 9
  Training set error: 0.460
  Training set accuracy: 0.788
  Test set error: 0.462
  Test set accuracy: 0.762
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 10
  Training set error: 0.465
  Training set accuracy: 0.769
  Test set error: 0.462
  Test set accuracy: 0.767
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 11
  Training set error: 0.443
  Training set accuracy: 0.801
  Test set error: 0.456
  Test set accuracy: 0.775
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 12
  Training set error: 0.448
  Training set accuracy: 0.795
  Test set error: 0.455
  Test set accuracy: 0.772
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 13
  Training set error: 0.438
  Training set accuracy: 0.787
  Test set error: 0.453
  Test set accuracy: 0.778
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 14
  Training set error: 0.446
  Training set accuracy: 0.791
  Test set error: 0.450
  Test set accuracy: 0.779
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 15
  Training set error: 0.441
  Training set accuracy: 0.788
  Test set error: 0.452
  Test set accuracy: 0.772
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 16
  Training set error: 0.437
  Training set accuracy: 0.786
  Test set error: 0.453
  Test set accuracy: 0.772
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 17
  Training set error: 0.436
  Training set accuracy: 0.794
  Test set error: 0.449
  Test set accuracy: 0.778
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 18
  Training set error: 0.433
  Training set accuracy: 0.801
  Test set error: 0.450
  Test set accuracy: 0.774
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 19
  Training set error: 0.429
  Training set accuracy: 0.785
  Test set error: 0.436
  Test set accuracy: 0.784
</pre></div>
</div>
</div>
</div>
<p>The training process may take many minutes, depending on a number of factors, such as the processing power of the machine you are running the experiment on and the number of epochs. To reduce the waiting time, you can change the epoch (iteration) variable from 100 to a lower number, reset the runtime (which will reset the weights), and run the notebook cells again.</p>
<p>After executing the cell above, you can visualize the training and test set errors and accuracy for an instance of this training process.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">epoch_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Starting from 1</span>

<span class="c1"># The training set metrics.</span>
<span class="n">training_metrics</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">store_training_accurate_pred</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_images</span><span class="p">),</span>
    <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">store_training_loss</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_images</span><span class="p">),</span>
<span class="p">}</span>

<span class="c1"># The test set metrics.</span>
<span class="n">test_metrics</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">store_test_accurate_pred</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_images</span><span class="p">),</span>
    <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">store_test_loss</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_images</span><span class="p">),</span>
<span class="p">}</span>

<span class="c1"># Display the plots.</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">title</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
    <span class="n">axes</span><span class="p">,</span> <span class="p">(</span><span class="n">training_metrics</span><span class="p">,</span> <span class="n">test_metrics</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;Training set&quot;</span><span class="p">,</span> <span class="s2">&quot;Test set&quot;</span><span class="p">)</span>
<span class="p">):</span>
    <span class="c1"># Plot the metrics</span>
    <span class="k">for</span> <span class="n">metric</span><span class="p">,</span> <span class="n">values</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_range</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">metric</span><span class="o">.</span><span class="n">capitalize</span><span class="p">())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epochs&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f92177c52c22930337aed1a565db8ba8da22c82a0ecb59225b187b03b5d99101.png" src="../_images/f92177c52c22930337aed1a565db8ba8da22c82a0ecb59225b187b03b5d99101.png" />
</div>
</div>
<p><em>The training and testing error is shown above in the left and right
plots, respectively. As the number of Epochs increases, the total error
decreases and the accuracy increases.</em></p>
<p>The accuracy rates that your model reaches during training and testing may be somewhat plausible but you may also find the error rates to be quite high.</p>
<p>To reduce the error during training and testing, you can consider changing the simple loss function to, for example, categorical <a class="reference external" href="https://en.wikipedia.org/wiki/Cross_entropy">cross-entropy</a>. Other possible solutions are discussed below.</p>
</section>
</section>
<section id="next-steps">
<h2>Next steps<a class="headerlink" href="#next-steps" title="Link to this heading">#</a></h2>
<p>You have learned how to build and train a simple feed-forward neural network from scratch using just NumPy to classify handwritten MNIST digits.</p>
<p>To further enhance and optimize your neural network model, you can consider one of a mixture of the following:</p>
<ul class="simple">
<li><p>Increase the training sample size from 1,000 to a higher number (up to 60,000).</p></li>
<li><p>Use <a class="reference external" href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">mini-batches and reduce the learning rate</a>.</p></li>
<li><p>Alter the architecture by introducing more hidden layers to make the network <a class="reference external" href="https://en.wikipedia.org/wiki/Deep_learning">deeper</a>.</p></li>
<li><p>Combine the <a class="reference external" href="https://en.wikipedia.org/wiki/Cross_entropy">cross-entropy</a> loss function with a <a class="reference external" href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a> activation function in the last layer.</p></li>
<li><p>Introduce convolutional layers: replace the feedforward network with a <a class="reference external" href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a> architecture.</p></li>
<li><p>Use a higher epoch size to train longer and add more regularization techniques, such as <a class="reference external" href="https://en.wikipedia.org/wiki/Early_stopping">early stopping</a>, to prevent <a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a>.</p></li>
<li><p>Introduce a <a class="reference external" href="https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets">validation set</a> for an unbiased valuation of the model fit.</p></li>
<li><p>Apply <a class="reference external" href="https://en.wikipedia.org/wiki/Batch_normalization">batch normalization</a> for faster and more stable training.</p></li>
<li><p>Tune other parameters, such as the learning rate and hidden layer size.</p></li>
</ul>
<p>Building a neural network from scratch with NumPy is a great way to learn more about NumPy and about deep learning. However, for real-world applications you should use specialized frameworks — such as <a class="reference external" href="https://pytorch.org/">PyTorch</a>, <a class="reference external" href="https://github.com/google/jax">JAX</a>, <a class="reference external" href="https://www.tensorflow.org/guide/tf_numpy">TensorFlow</a> or <a class="reference external" href="https://mxnet.apache.org">MXNet</a> — that provide NumPy-like APIs, have built-in <a class="reference external" href="https://en.wikipedia.org/wiki/Automatic_differentiation">automatic differentiation</a> and GPU support, and are designed for high-performance numerical computing and machine learning.</p>
<p>Finally, when developing a machine learning model, you should think about potential ethical issues and apply practices to avoid or mitigate those:</p>
<ul class="simple">
<li><p>Document a trained model with a Model Card - see the <a class="reference external" href="https://doi.org/10.1145/3287560.3287596">Model Cards for Model Reporting paper</a> by Margaret Mitchell et al..</p></li>
<li><p>Document a dataset with a Datasheet - see the <a class="reference external" href="https://arxiv.org/abs/1803.09010">Datasheets for Datasets paper</a>) by Timnit Gebru et al..</p></li>
<li><p>Consider the impact of your model - who is affected by it, who does it benefit - see <a class="reference external" href="https://www.nature.com/articles/d41586-020-02003-2">the article</a> and <a class="reference external" href="https://slideslive.com/38923453/the-values-of-machine-learning">talk</a> by Pratyusha Kalluri.</p></li>
<li><p>For more resources, see <a class="reference external" href="https://www.fast.ai/2018/09/24/ai-ethics-resources/">this blog post by Rachel Thomas</a> and the <a class="reference external" href="https://www.radicalai.org/">Radical AI podcast</a>.</p></li>
</ul>
<p>(Credit to <a class="reference external" href="https://github.com/hsjeong5/MNIST-for-Numpy">hsjeong5</a> for demonstrating how to download MNIST without the use of external libraries.)</p>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="mooreslaw-tutorial.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Determining Moore’s Law with real data in NumPy</p>
      </div>
    </a>
    <a class="right-next"
       href="tutorial-x-ray-image-processing.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">X-ray image processing</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites">Prerequisites</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#table-of-contents">Table of contents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-mnist-dataset">1. Load the MNIST dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocess-the-data">2. Preprocess the data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convert-the-image-data-to-the-floating-point-format">Convert the image data to the floating-point format</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#convert-the-labels-to-floating-point-through-categorical-one-hot-encoding">Convert the labels to floating point through categorical/one-hot encoding</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#build-and-train-a-small-neural-network-from-scratch">3. Build and train a small neural network from scratch</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-network-building-blocks-with-numpy">Neural network building blocks with NumPy</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-architecture-and-training-summary">Model architecture and training summary</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#compose-the-model-and-begin-training-and-testing-it">Compose the model and begin training and testing it</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next steps</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By the NumPy community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2020-2024, the NumPy community.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>